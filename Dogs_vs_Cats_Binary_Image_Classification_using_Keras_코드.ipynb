{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle Challenge : Dogs-vs-Cats - Binary Image Classification using Keras 코드.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HE-JTmjLApKN",
        "tbb1Zhe5tyO8",
        "EiKWhwVE2Utm",
        "T-3yx8um7usX",
        "voZTC5W_8dVq"
      ],
      "authorship_tag": "ABX9TyOhacw4f0teKymzljnFaRH0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4nchez/Colab-Jupiter/blob/master/Dogs_vs_Cats_Binary_Image_Classification_using_Keras_%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m83NRwewjUD",
        "colab_type": "text"
      },
      "source": [
        "# Kaggle Challenge : Dogs-vs-Cats - Binary Image Classification using Keras\n",
        "해당 포스트는 [Kaggle  Dogs-vs-Cats challenge](https://www.kaggle.com/c/dogs-vs-cats) 해결하기위해 만들었으며, 여러 가지 자료들을 참고하여 만든 포스트 입니다.\n",
        "\n",
        "\n",
        "*   개발 환경 : google colab, Python3, Tensorflow, Keras\n",
        "*   실험 모델 : VGG16(Transfer Learning)\n",
        "*   실험에 쓰인 데이터 : Kaggle Dogs vs Cats challenge\n",
        "*   Test {개: 1,000, 고양이: 1,000} (총 2,000개)\n",
        "*   Training {개: 5,000, 고양이: 5,000} (총 10,000개)\n",
        "*   Validation {개: 2,500, 고양이: 2,500} (총 5,000개)\n",
        "*   IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 150, 150, 3, 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvzEUULo3wfu",
        "colab_type": "text"
      },
      "source": [
        "GPU 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4yDQ-Wwwk5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQtVueKT9Z4x",
        "colab_type": "text"
      },
      "source": [
        "구글 드라이브 연동 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXnjXPZTn4Dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KTB9Rt6n5Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "MODEL_SAVE_DIR = \"/content/drive/My Drive/Colab Notebooks/model_states\" #실험에 쓴 모델을 저장할 드라이브 경로\n",
        "IMAGES_ZIP_DIR = \"/content/drive/My Drive/Colab Notebooks/data/cats_vs_dogs\" #구글 드라이브에 저장되어 있는 데이터셋(이미지)\n",
        "import sys\n",
        "sys.path.append('./drive/My Drive/Colab Notebooks')\n",
        "import kr_helper_funcs as kru"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE-JTmjLApKN",
        "colab_type": "text"
      },
      "source": [
        "## Kaggle  Dogs-vs-Cats challenge Dataset\n",
        "Kaggle train.zip 에는 개와 고양이의 이미지 25,000 개 (고양이 색상 이미지 12,500 개 및 다양한 크기의 개 색상 이미지 12,500 개)가 포함되어 있습니다.\n",
        "\n",
        "train Data 중 별도의 프로그램을 사용하여 고양이와 개에 개에 각각 5,000개의 훈련 이미지, 고양이와 개에 대한 2,500개의 평가 이미지, 고양이와 개에 개에 각각 1,000개의 테스트 이미지로 구성된 작은 데이터 세트를 만들었습니다. 그런 다음 이미지 Dataset.zip 파일을 Google 드라이브에 업로드했습니다.\n",
        "\n",
        "zip 파일 cats_vs_dogs_images_small.zip은 내 Google 드라이브의 IMAGES_ZIP_DIR에서 사용할 수 있습니다. 아래 코드 셀은 로컬로 다운로드하고 /tmp 폴더에 이미지 압축을 풉니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ2LtU_aEZA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "print('Using Tensorflow version ', tf.__version__)\n",
        "print('Using keras version ', keras.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        "plt.style.use('seaborn')\n",
        " \n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "# tf.set_random_seed(seed)\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # ignore all warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohb1Hf6FyTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, MaxPooling2D, \n",
        "                                     Flatten, Dense, Dropout)\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea0g4CxrAmbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "import zipfile\n",
        " \n",
        "#!cp $(IMAGES_ZIP_DIR/images_small.zip\" /tmp\n",
        "source_file = os.path.join(IMAGES_ZIP_DIR, 'cats_vs_dogs_images_small.zip')\n",
        "local_zip = '/tmp/cats_vs_dogs_images_small.zip'\n",
        " \n",
        "print(\"Copying from drive %s to %s...\" % (source_file, local_zip), flush=True)\n",
        "shutil.copyfile(source_file, local_zip)\n",
        " \n",
        "assert os.path.exists(local_zip)\n",
        " \n",
        "print('Extracting all images...', flush=True)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        " \n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbb1Zhe5tyO8",
        "colab_type": "text"
      },
      "source": [
        "## 실험에 쓰일 데이터 파일 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leOe8BLVSZl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_root = \"/tmp\" # /content/drive/My Drive/img\n",
        "assert os.path.exists(images_root), \"%s folder does not exist!\" % images_root\n",
        " \n",
        "train_root = os.path.join(images_root,'training')\n",
        "train_root_cat = os.path.join(train_root,'cat')\n",
        "train_root_dog = os.path.join(train_root,'dog')\n",
        " \n",
        "eval_root = os.path.join(images_root,'validation')\n",
        "eval_root_cat = os.path.join(eval_root,'cat')\n",
        "eval_root_dog = os.path.join(eval_root,'dog')\n",
        " \n",
        "test_root = os.path.join(images_root,'test')\n",
        "test_root_cat = os.path.join(test_root,'cat')\n",
        "test_root_dog = os.path.join(test_root,'dog')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTL2Tfh3jxCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 150, 150, 3, 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wMEZewGL2kw0",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "eval_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')\n",
        " \n",
        "eval_generator = eval_datagen.flow_from_directory(\n",
        "    eval_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')\n",
        " \n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nA_rvSOe2kw2",
        "colab": {}
      },
      "source": [
        "train_steps = train_generator.n // BATCH_SIZE\n",
        "val_steps = eval_generator.n // BATCH_SIZE\n",
        "test_steps = test_generator.n // BATCH_SIZE\n",
        "train_steps, val_steps, test_steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiKWhwVE2Utm",
        "colab_type": "text"
      },
      "source": [
        "# 기본 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q0e9SrkM2kwu",
        "colab": {}
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = relu\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "# for layer in model.layers:\n",
        "#     if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      # layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4),\n",
        "                  loss='binary_crossentropy',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cq_UdcKD2kwy",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrWUlGFk2YUG",
        "colab": {}
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rBVRlLmn2YUI",
        "colab": {}
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "agbd40QM2YUK",
        "colab": {}
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTzUsW51wkfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-3yx8um7usX",
        "colab_type": "text"
      },
      "source": [
        "# mse 인 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j5fgtKwO79qJ",
        "colab": {}
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = relu\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "# for layer in model.layers:\n",
        "#     if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      # layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4),\n",
        "                  loss='mse',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bo_otoFV79qN",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NiD-J7-I79qP",
        "colab": {}
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yLU_aOTk79qQ",
        "colab": {}
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mWRhVLU79qS",
        "colab": {}
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ocS1y0Elwn82",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "voZTC5W_8dVq"
      },
      "source": [
        "# 활성함수가 sigmoid 이며 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tDjG0kwE8dVr",
        "colab": {}
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4),\n",
        "                  loss='binary_crossentropy',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "otZ2ft-V8dVu",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S98GxzEA8dVw",
        "colab": {}
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "InSvEYEK8dVz",
        "colab": {}
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7Ix6bBk8dV1",
        "colab": {}
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ANUv8VKDwolf",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbCMhPkxhezL",
        "colab_type": "text"
      },
      "source": [
        "# 활성함수가 sigmoid이며 mse 인 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZMrJonrkYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4),\n",
        "                  loss='mse',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC95Tb90tQ20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Pw9I-Za6My",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBQkhHKHQ3i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSXUGOLZ81OS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J35wCUzwwo_7",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}