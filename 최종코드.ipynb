{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "최종코드.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzoxCbP5CrZba+OKrX0DZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4nchez/Colab-Jupiter/blob/master/%EC%B5%9C%EC%A2%85%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m83NRwewjUD"
      },
      "source": [
        "# Kaggle Challenge : Dogs-vs-Cats - Binary Image Classification using Keras\n",
        "해당 포스트는 [Kaggle  Dogs-vs-Cats challenge](https://www.kaggle.com/c/dogs-vs-cats) 해결하기위해 만들었으며, 여러 가지 자료들을 참고하여 만든 포스트 입니다.\n",
        "\n",
        "\n",
        "*   개발 환경 : google colab, Python3, Tensorflow, Keras\n",
        "*   실험 모델 : VGG16(Transfer Learning)\n",
        "*   실험에 쓰인 데이터 : Kaggle Dogs vs Cats challenge\n",
        "*   Test {개: 1,000, 고양이: 1,000} (총 2,000개)\n",
        "*   Training {개: 5,000, 고양이: 5,000} (총 10,000개)\n",
        "*   Validation {개: 2,500, 고양이: 2,500} (총 5,000개)\n",
        "*   IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 150, 150, 3, 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD8EP4SF4BEg",
        "outputId": "e7645f33-95f0-4ad5-abc0-74a383218246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct  8 11:12:59 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbIAb6555KJr"
      },
      "source": [
        "실험에 필요한 파일 다운 & /content 에 압축풀기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrMMQwrLyYOG",
        "outputId": "42f05480-14c7-4615-9af4-8a88a310494f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "!wget https://github.com/4nchez/Dataset/raw/main/cats_vs_dogs_images_small.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-08 11:12:59--  https://github.com/4nchez/Dataset/raw/main/cats_vs_dogs_images_small.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/4nchez/Dataset/main/cats_vs_dogs_images_small.zip [following]\n",
            "--2020-10-08 11:12:59--  https://media.githubusercontent.com/media/4nchez/Dataset/main/cats_vs_dogs_images_small.zip\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548537342 (523M) [application/zip]\n",
            "Saving to: ‘cats_vs_dogs_images_small.zip’\n",
            "\n",
            "cats_vs_dogs_images 100%[===================>] 523.12M   287MB/s    in 1.8s    \n",
            "\n",
            "2020-10-08 11:13:01 (287 MB/s) - ‘cats_vs_dogs_images_small.zip’ saved [548537342/548537342]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CpUXvp3zMAD",
        "outputId": "e831b073-367d-4675-dbb7-2bf80d758513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os, shutil\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/cats_vs_dogs_images_small.zip'\n",
        " \n",
        "print('Extracting all images...', flush=True)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        " \n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting all images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbb1Zhe5tyO8"
      },
      "source": [
        "## 실험에 쓰일 데이터 파일 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ2LtU_aEZA9",
        "outputId": "6e9a096a-f47b-40ad-b28c-2c629d7a2a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import sys, os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "print('Using Tensorflow version ', tf.__version__)\n",
        "print('Using keras version ', keras.__version__)\n",
        " \n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "# tf.set_random_seed(seed)\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # ignore all warnings"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Tensorflow version  2.3.0\n",
            "Using keras version  2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_MJbxKm6WV8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, MaxPooling2D, \n",
        "                                     Flatten, Dense, Dropout)\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leOe8BLVSZl1"
      },
      "source": [
        "images_root = \"/content\"\n",
        "assert os.path.exists(images_root), \"%s folder does not exist!\" % images_root\n",
        " \n",
        "train_root = os.path.join(images_root,'training')\n",
        "train_root_cat = os.path.join(train_root,'cat')\n",
        "train_root_dog = os.path.join(train_root,'dog')\n",
        " \n",
        "eval_root = os.path.join(images_root,'validation')\n",
        "eval_root_cat = os.path.join(eval_root,'cat')\n",
        "eval_root_dog = os.path.join(eval_root,'dog')\n",
        " \n",
        "test_root = os.path.join(images_root,'test')\n",
        "test_root_cat = os.path.join(test_root,'cat')\n",
        "test_root_dog = os.path.join(test_root,'dog')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTL2Tfh3jxCT"
      },
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 224, 224, 3, 32"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMEZewGL2kw0",
        "outputId": "061999ca-390a-45aa-d156-307a25f1e78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "eval_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')\n",
        " \n",
        "eval_generator = eval_datagen.flow_from_directory(\n",
        "    eval_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')\n",
        " \n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA_rvSOe2kw2",
        "outputId": "4728fc85-a6d6-4541-b41f-68f02d90c861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_steps = train_generator.n // BATCH_SIZE\n",
        "val_steps = eval_generator.n // BATCH_SIZE\n",
        "test_steps = test_generator.n // BATCH_SIZE\n",
        "train_steps, val_steps, test_steps"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 156, 62)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7EirR3hJC_o"
      },
      "source": [
        "# Default VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRLcSK62GFWH",
        "outputId": "2e8e3652-d6c1-4090-c1ec-c9d751bb39e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vgg_base = keras.applications.VGG16(include_top=True, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "x = Dense(1, activation='sigmoid', name='predictions')(vgg_base.layers[-2].output)\n",
        "vgg_base.trainable = False\n",
        "model = Model(vgg_base.input,x)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='binary_crossentropy',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1)                 4097      \n",
            "=================================================================\n",
            "Total params: 134,264,641\n",
            "Trainable params: 4,097\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnerMzbBJBO_",
        "outputId": "f9c559af-0e40-4a89-a292-9532d80b8333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-24-9a0d8f8a328f>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/50\n",
            "253/312 [=======================>......] - ETA: 7s - loss: 0.6024 - acc: 0.7223"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5J3hKz0JlEH"
      },
      "source": [
        "def show_plots(history, plot_title=None, fig_size=None):\n",
        "    \"\"\" Useful function to view plot of loss values & accuracies across the various epochs\n",
        "        Works with the history object returned by the train_model(...) call \"\"\"\n",
        "    assert type(history) is dict\n",
        "\n",
        "    # NOTE: the history object should always have loss & acc (for training data), but MAY have\n",
        "    # val_loss & val_acc for validation data\n",
        "    loss_vals = history['loss']\n",
        "    val_loss_vals = history['val_loss'] if 'val_loss' in history.keys() else None\n",
        "    epochs = range(1, len(history['acc']) + 1)\n",
        "\n",
        "    f, ax = plt.subplots(nrows=1, ncols=2, figsize=((16, 4) if fig_size is None else fig_size))\n",
        "\n",
        "    # plot losses on ax[0]\n",
        "    ax[0].plot(epochs, loss_vals, color='navy', marker='o', linestyle=' ', label='Training Loss')\n",
        "    if val_loss_vals is not None:\n",
        "        ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n",
        "        ax[0].set_title('Training & Validation Loss')\n",
        "        ax[0].legend(loc='best')\n",
        "    else:\n",
        "        ax[0].set_title('Training Loss')\n",
        "\n",
        "    ax[0].set_xlabel('Epochs')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].grid(True)\n",
        "\n",
        "    # plot accuracies\n",
        "    acc_vals = history['acc']\n",
        "    val_acc_vals = history['val_acc'] if 'val_acc' in history.keys() else None\n",
        "\n",
        "    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n",
        "    if val_acc_vals is not None:\n",
        "        ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n",
        "        ax[1].set_title('Training & Validation Accuracy')\n",
        "        ax[1].legend(loc='best')\n",
        "    else:\n",
        "        ax[1].set_title('Training Accuracy')\n",
        "\n",
        "    ax[1].set_xlabel('Epochs')\n",
        "    ax[1].set_ylabel('Accuracy')\n",
        "    ax[1].grid(True)\n",
        "\n",
        "    if plot_title is not None:\n",
        "        plt.suptitle(plot_title)\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # delete locals from heap before exiting (to save some memory!)\n",
        "    del loss_vals, epochs, acc_vals\n",
        "    if val_loss_vals is not None:\n",
        "        del val_loss_vals\n",
        "    if val_acc_vals is not None:\n",
        "        del val_acc_vals\n",
        "def save_keras_model(model, base_file_name, save_dir=os.path.join('.','keras_models')):\n",
        "    \"\"\" save the model structure to JSON & weights to HD5 \"\"\"    \n",
        "    # check if save_dir exists, else create it\n",
        "    if not os.path.exists(save_dir):\n",
        "        try:\n",
        "            os.mkdir(save_dir)\n",
        "        except OSError as err:\n",
        "            print(\"Unable to create folder {} to save Keras model. Can't continue!\".format(save_dir))\n",
        "            raise err\n",
        "            \n",
        "    # model structure is saved to $(save_dir)/base_file_name.json\n",
        "    # weights are saved to $(save_dir)/base_file_name.h5\n",
        "    model_json = model.to_json()\n",
        "    json_file_path = os.path.join(save_dir, (base_file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(save_dir, (base_file_name + \".h5\"))            \n",
        "\n",
        "    with open(json_file_path, \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\\n\",\n",
        "    model.save_weights(h5_file_path)\n",
        "    print(\"Saved model to files %s and %s\" % (json_file_path, h5_file_path))\n",
        "\n",
        "def load_keras_model(base_file_name, load_dir=os.path.join('.', 'keras_models')):\n",
        "    \"\"\" loads model structure & weights from previously saved state \"\"\"\n",
        "    # model structure is loaded $(load_dir)/base_file_name.json\n",
        "    # weights are loaded from $(load_dir)/base_file_name.h5\n",
        "\n",
        "    from tensorflow.keras.models import model_from_json\n",
        "\n",
        "    # load model from save_path\n",
        "    loaded_model = None\n",
        "    json_file_path = os.path.join(load_dir, (base_file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(load_dir, (base_file_name + \".h5\"))\n",
        "\n",
        "    if os.path.exists(json_file_path) and os.path.exists(h5_file_path):\n",
        "        with open(json_file_path, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            loaded_model = model_from_json(loaded_model_json)\n",
        "            loaded_model.load_weights(h5_file_path)\n",
        "        print(\"Loaded model from files %s and %s\" % (json_file_path, h5_file_path))\n",
        "    else:\n",
        "        msg = \"Model file(s) not found in %s! Expecting to find %s and %s in this directory.\" % (\n",
        "            load_dir, (base_file_name + \".json\"), (base_file_name + \".h5\"))\n",
        "        raise IOError(msg)\n",
        "    return loaded_model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVhbOUA3JBPC"
      },
      "source": [
        "show_plots(hist.history, plot_title='Using VGG16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnAGCBMVJBPE"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCBCwktuJBPG"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "MODEL_SAVE_DIR='/content'\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/파일명.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/파일명.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "save_keras_model(model, '파일명', MODEL_SAVE_DIR)\n",
        "del vgg_base\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}