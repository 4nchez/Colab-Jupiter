{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hugginface_XLM-RoBERTa.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7SMV28mAkQap",
        "h_U3uMySBCIV",
        "XgjMzosCDD35",
        "qv7fQYah4X-p",
        "FK-T-NuCG96f"
      ],
      "authorship_tag": "ABX9TyND46s5qkE9W93wYWB7qGUV"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da7883af466148669ebace676901e458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fad3f90313e49819d8d30e02ee17288",
              "IPY_MODEL_53ea3db507bd45b4af32cc97e3fc44a3"
            ],
            "layout": "IPY_MODEL_495645e2af8a4c4284c87c9aa87b0f35"
          }
        },
        "0fad3f90313e49819d8d30e02ee17288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_481bba62987a47908b6acc091d982a59",
            "max": 512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_001c238e272f4212ae9abad7d225e6c5",
            "value": 512
          }
        },
        "53ea3db507bd45b4af32cc97e3fc44a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74f686e6a8324550ae8c6f00f6704c0a",
            "placeholder": "​",
            "style": "IPY_MODEL_87e7827924274439ae6e759dacbc2807",
            "value": " 512/512 [00:00&lt;00:00, 1.58kB/s]"
          }
        },
        "495645e2af8a4c4284c87c9aa87b0f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "481bba62987a47908b6acc091d982a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "001c238e272f4212ae9abad7d225e6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "74f686e6a8324550ae8c6f00f6704c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e7827924274439ae6e759dacbc2807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be222f93403b4a649c0530f8cb7fb26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff9bbf1fcbf24efe821cd4a148bffaf3",
              "IPY_MODEL_23220261044c4abdb6dc21d639cd98ac"
            ],
            "layout": "IPY_MODEL_11dc7f8183d94586bc452718ae06a8f1"
          }
        },
        "ff9bbf1fcbf24efe821cd4a148bffaf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7ae9df81b974ce6b6bbade2de01d0f4",
            "max": 1115590446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6022f9c57e44d5b896f7e33c4ebf5ae",
            "value": 1115590446
          }
        },
        "23220261044c4abdb6dc21d639cd98ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1328900aa4d4c468f1290db70d6a35f",
            "placeholder": "​",
            "style": "IPY_MODEL_f83c7dec106749eaaf302c7e8533a94b",
            "value": " 1.12G/1.12G [00:47&lt;00:00, 23.4MB/s]"
          }
        },
        "11dc7f8183d94586bc452718ae06a8f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ae9df81b974ce6b6bbade2de01d0f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6022f9c57e44d5b896f7e33c4ebf5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "e1328900aa4d4c468f1290db70d6a35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83c7dec106749eaaf302c7e8533a94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd-7Y1qmDvfa"
      },
      "source": [
        "import os\r\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPNP7X89hdwp"
      },
      "source": [
        "# **huggingface model custom**\r\n",
        "\r\n",
        "저자 : 4nchez<br>\r\n",
        "모델 : XLM-RoBERTa<br>\r\n",
        "데이터 : nsmc<br>\r\n",
        "필요한 라이브러리(중요한건 bold함)<br>\r\n",
        "-> pandas, numpy, random, time, datetime, **transformers**, **pytorch**, **tensorflw**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SMV28mAkQap"
      },
      "source": [
        "## **Import library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dbcUfZPegh0",
        "outputId": "57441f56-86de-4433-9136-ef536c2a8d63"
      },
      "source": [
        "!pip install transformers sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=47180b7280de3aaa082d4008e351a0140890810ece489751cba211de12df6d32\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6RpQD_djqvx"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import random, time, datetime\r\n",
        "\r\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, BertModel\r\n",
        "from transformers import XLMRobertaConfig, XLMRobertaModel, XLMRobertaTokenizer\r\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.utils.prune as prune\r\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\r\n",
        "from torch.utils.data import TensorDataset, random_split\r\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_U3uMySBCIV"
      },
      "source": [
        "## **데이터 로드**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImBtAkSyTW1r",
        "outputId": "be14e322-ba93-439e-d9a4-f82fdf56d490"
      },
      "source": [
        "# 네이버 영화리뷰 감정분석 데이터 다운로드\n",
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 23.55 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LPEdb2tWfIU",
        "outputId": "eaa86b0b-456b-4b70-fad0-c7071056a776"
      },
      "source": [
        "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
        "train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
        "test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "(50000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cl0j7TZBoeL"
      },
      "source": [
        "훈련셋 150,000개와 테스트셋 50,000개의 데이터가 존재합니다.\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgjMzosCDD35"
      },
      "source": [
        "## **데이터 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNSq6kvPUxFf"
      },
      "source": [
        "**Train_set : validation_set = 9:1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud33ybZMI-cG"
      },
      "source": [
        "def Make_sentence(tokenizer, sentences):\r\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\r\n",
        "  input_ids = []\r\n",
        "  attention_masks = []\r\n",
        "\r\n",
        "  # For every sentence...\r\n",
        "  for sent in sentences:\r\n",
        "      # `encode_plus` will:\r\n",
        "      #   (1) Tokenize the sentence.\r\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\r\n",
        "      #   (3) Append the `[SEP]` token to the end.\r\n",
        "      #   (4) Map tokens to their IDs.\r\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\r\n",
        "      #   (6) Create attention masks for [PAD] tokens.\r\n",
        "      encoded_dict = tokenizer.encode_plus(\r\n",
        "                          sent,                      # Sentence to encode.\r\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\r\n",
        "                          max_length = 128,           # Pad & truncate all sentences.\r\n",
        "                          pad_to_max_length = True,\r\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\r\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\r\n",
        "                    )\r\n",
        "      \r\n",
        "      # Add the encoded sentence to the list.    \r\n",
        "      input_ids.append(encoded_dict['input_ids'])\r\n",
        "      \r\n",
        "      # And its attention mask (simply differentiates padding from non-padding).\r\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "      \r\n",
        "  # input_ids = torch.cat(input_ids, dim=0)\r\n",
        "  # attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMHKU2G6Xbu6"
      },
      "source": [
        "# xlm-roberta-base\r\n",
        "# !wget https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model\r\n",
        "# xlm-roberta-large\r\n",
        "# !wget https://huggingface.co/xlm-roberta-large/resolve/main/sentencepiece.bpe.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caCnynD5TjbH",
        "outputId": "13f442d0-08e3-4f6f-d242-d8d558a2089a"
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\r\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=False)\r\n",
        "# tokenizer = XLMRobertaTokenizer('sentencepiece.bpe.model', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59e1086b8ced4b69ae8539fd78fdec82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN-LZ3CSL6Ef",
        "outputId": "f644e56d-fc15-4eb0-96da-db100c96d72e"
      },
      "source": [
        "# print(train.isnull().any())\r\n",
        "# train[train['document'].isnull()]\r\n",
        "print(train.shape)\r\n",
        "print(\"train null value : \" ,train.isnull().sum())\r\n",
        "train_set=train.dropna()\r\n",
        "sentences = train_set['document'].values\r\n",
        "labels = train_set['label'].values\r\n",
        "print(len(sentences))\r\n",
        "print(len(labels))\r\n",
        "\r\n",
        "input_ids, attention_masks = Make_sentence(tokenizer, sentences)\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "# Print sentence 0, now as a list of IDs.\r\n",
        "print('Original: ', sentences[0])\r\n",
        "print('Token IDs:', input_ids[0])\r\n",
        "print('Token IDs:', attention_masks[0])\r\n",
        "print('Labels :', labels[0])\r\n",
        "\r\n",
        "# Combine the training inputs into a TensorDataset.\r\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "\r\n",
        "# Create a 90-10 train-validation split.\r\n",
        "\r\n",
        "# Calculate the number of samples to include in each set.\r\n",
        "train_size = int(0.9 * len(dataset))\r\n",
        "val_size = len(dataset) - train_size\r\n",
        "\r\n",
        "# Divide the dataset by randomly selecting samples.\r\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\r\n",
        "\r\n",
        "print('{:>5,} training samples'.format(train_size))\r\n",
        "print('{:>5,} validation samples'.format(val_size))\r\n",
        "\r\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \r\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \r\n",
        "# size of 16 or 32.\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Create the DataLoaders for our training and validation sets.\r\n",
        "# We'll take training samples in random order. \r\n",
        "train_dataloader = DataLoader(\r\n",
        "            train_dataset,  # The training samples.\r\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\r\n",
        "            batch_size = batch_size # Trains with this batch size.\r\n",
        "        )\r\n",
        "\r\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\r\n",
        "validation_dataloader = DataLoader(\r\n",
        "            val_dataset, # The validation samples.\r\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\r\n",
        "            batch_size = batch_size # Evaluate with this batch size.\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "train null value :  id          0\n",
            "document    5\n",
            "label       0\n",
            "dtype: int64\n",
            "149995\n",
            "149995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  아 더빙.. 진짜 짜증나네요 목소리\n",
            "Token IDs: tensor([     0,   7159,   6116, 101895,      5,      5, 113621,      6,  74280,\n",
            "         18128,   3497,  25861, 209932,      2,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1])\n",
            "Token IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Labels : tensor(0)\n",
            "134,995 training samples\n",
            "15,000 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yceLyWmmUnuP"
      },
      "source": [
        "**Test_set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AstYEbxsPzOP",
        "outputId": "59e7914c-31fe-4757-a162-761672fc96fe"
      },
      "source": [
        "print(test.shape)\r\n",
        "print(test.isnull().sum())\r\n",
        "test_set=test.dropna()\r\n",
        "print(test_set.shape)\r\n",
        "sentences = test_set['document'].values\r\n",
        "labels = test_set['label'].values\r\n",
        "print(len(sentences))\r\n",
        "print(len(labels))\r\n",
        "\r\n",
        "input_ids, attention_masks = Make_sentence(tokenizer, sentences)\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "# Print sentence 0, now as a list of IDs.\r\n",
        "print('Original: ', sentences[0])\r\n",
        "print('Token IDs:', input_ids[0])\r\n",
        "print('Token IDs:', attention_masks[0])\r\n",
        "print('Labels :', labels[0])\r\n",
        "\r\n",
        "# 배치 사이즈\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n",
        "test_data = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3)\n",
            "id          0\n",
            "document    3\n",
            "label       0\n",
            "dtype: int64\n",
            "(49997, 3)\n",
            "49997\n",
            "49997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  굳 ㅋ\n",
            "Token IDs: tensor([     0,      6, 198249,      6, 204615,      2,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1])\n",
            "Token IDs: tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Labels : tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv7fQYah4X-p"
      },
      "source": [
        "## **모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "816M52s44X-q",
        "outputId": "6c8a353e-5efd-4a45-f0f9-2ea9bc901a32"
      },
      "source": [
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q19okEoL4X-q",
        "outputId": "3d79747b-b2dc-4fe9-c0cc-0479e68e0d12"
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzBwMmyQ4X-q"
      },
      "source": [
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.num_labels = 2\n",
        "          # from_pretrained 사용시 히든 사이즈 못바꿈!!\n",
        "          self.config = XLMRobertaConfig.from_pretrained('xlm-roberta-base', output_hidden_states=True, \n",
        "                                                        #  num_hidden_layers=12, num_attention_heads=12,\n",
        "                                                        #  hidden_size=768, intermediate_size=768*4, # 768, 768*4\n",
        "                                                   hidden_dropout_prob=0.1, attention_probs_dropout_prob=0.1)\n",
        "          self.roberta = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\", config=self.config)\n",
        "          # self.config = XLMRobertaConfig(\n",
        "          #     attention_probs_dropout_prob= 0.1, hidden_dropout_prob=0.1,\n",
        "          #     bos_token_id=0, pad_token_id=1, eos_token_id=2,\n",
        "          #     gradient_checkpointing=False, hidden_act='gelu',\n",
        "          #     hidden_size=768, intermediate_size=768*4, # 768, 768*4\n",
        "          #     initializer_range=0.02, layer_norm_eps=1e-05, max_position_embeddings=514,\n",
        "          #     num_attention_heads=2, num_hidden_layers=2,\n",
        "          #     output_past=True, position_embedding_type=\"absolute\",\n",
        "          #     type_vocab_size=1, vocab_size=250002)\n",
        "          # self.bert = XLMRobertaModel(self.config)\n",
        "          ### New layers:\n",
        "          # self.linear1 = nn.Linear(768, 768)\n",
        "          self.lstm = nn.LSTM(input_size=768,\n",
        "                            hidden_size=128,\n",
        "                            num_layers=1,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True,\n",
        "                            )\n",
        "          self.dropout = nn.Dropout(0.1)\n",
        "          self.linear2 = nn.Linear(128, self.num_labels)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None,\n",
        "                token_type_ids=None, position_ids=None, head_mask=None,\n",
        "                inputs_embeds=None, labels=None, output_attentions=None,\n",
        "                output_hidden_states=None, return_dict=None,):\n",
        "          outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
        "                              token_type_ids=token_type_ids, position_ids=position_ids,\n",
        "                              head_mask=head_mask,inputs_embeds=inputs_embeds,\n",
        "                              output_attentions=output_attentions, output_hidden_states=output_hidden_states,\n",
        "                              return_dict=return_dict,)\n",
        "          pooled_output = outputs[0]\n",
        "          # return outputs\n",
        "          lstm_output = self.lstm(pooled_output)\n",
        "          lstm_out, (ht, ct) = self.lstm(pooled_output)\n",
        "          # lstm_out, _ = self.lstm(pooled_output)\n",
        "          # tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "          logits= self.linear2(ht[-1])\n",
        "\n",
        "          loss = None\n",
        "          if labels is not None:\n",
        "              if self.num_labels == 1:\n",
        "                  #  We are doing regression\n",
        "                  loss_fct = MSELoss()\n",
        "                  loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "              else:\n",
        "                  loss_fct = CrossEntropyLoss()\n",
        "                  loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "          if not return_dict:\n",
        "              output = (logits,) + outputs[2:]\n",
        "              return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "          return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm_27HJfccec"
      },
      "source": [
        "# model = CustomBERTModel().to(device)\r\n",
        "# # model = CustomBERTModel()\r\n",
        "# print(model.config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da7883af466148669ebace676901e458",
            "0fad3f90313e49819d8d30e02ee17288",
            "53ea3db507bd45b4af32cc97e3fc44a3",
            "495645e2af8a4c4284c87c9aa87b0f35",
            "481bba62987a47908b6acc091d982a59",
            "001c238e272f4212ae9abad7d225e6c5",
            "74f686e6a8324550ae8c6f00f6704c0a",
            "87e7827924274439ae6e759dacbc2807",
            "be222f93403b4a649c0530f8cb7fb26c",
            "ff9bbf1fcbf24efe821cd4a148bffaf3",
            "23220261044c4abdb6dc21d639cd98ac",
            "11dc7f8183d94586bc452718ae06a8f1",
            "c7ae9df81b974ce6b6bbade2de01d0f4",
            "d6022f9c57e44d5b896f7e33c4ebf5ae",
            "e1328900aa4d4c468f1290db70d6a35f",
            "f83c7dec106749eaaf302c7e8533a94b"
          ]
        },
        "id": "jrM8PZY6KjEF",
        "outputId": "b5c28c8c-4291-4165-f9d5-6c111a2b37d8"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification\r\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=2)\r\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da7883af466148669ebace676901e458",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be222f93403b4a649c0530f8cb7fb26c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeKwNmjw1TbJ",
        "outputId": "d8d0ad43-6397-4af8-9ea6-02f721c4564a"
      },
      "source": [
        "sum(p.numel() for p in model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "278045186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoWBHX-90YWR"
      },
      "source": [
        "# sum(p.numel() for p in model2.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75_YZSK44X-r"
      },
      "source": [
        "# # Get all of the model's parameters as a list of tuples.\r\n",
        "# params = list(model.named_parameters())\r\n",
        "\r\n",
        "# print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\r\n",
        "\r\n",
        "# print('==== Embedding Layer ====\\n')\r\n",
        "\r\n",
        "# for p in params[0:5]:\r\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "\r\n",
        "# print('\\n==== First Transformer ====\\n')\r\n",
        "\r\n",
        "# for p in params[5:21]:\r\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "\r\n",
        "# print('\\n==== Output Layer ====\\n')\r\n",
        "\r\n",
        "# for p in params[-4:]:\r\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "winopImj4X-r"
      },
      "source": [
        "parameters_to_prune = ()\r\n",
        "# for i in range(12):\r\n",
        "#     parameters_to_prune += (\r\n",
        "#         (model.bert.encoder.layer[i].attention.self.key, 'weight'),\r\n",
        "#         (model.bert.encoder.layer[i].attention.self.query, 'weight'),\r\n",
        "#         (model.bert.encoder.layer[i].attention.self.value, 'weight'),\r\n",
        "#     )\r\n",
        "\r\n",
        "# prune.global_unstructured(\r\n",
        "#     parameters_to_prune,\r\n",
        "#     pruning_method=prune.L1Unstructured,\r\n",
        "#     amount=0.2,\r\n",
        "# )\r\n",
        "for i in range(12):\r\n",
        "    parameters_to_prune += (\r\n",
        "        (model.roberta.encoder.layer[i].attention.self.key, 'weight'),\r\n",
        "        (model.roberta.encoder.layer[i].attention.self.query, 'weight'),\r\n",
        "        (model.roberta.encoder.layer[i].attention.self.value, 'weight'),\r\n",
        "    )\r\n",
        "\r\n",
        "prune.global_unstructured(\r\n",
        "    parameters_to_prune,\r\n",
        "    pruning_method=prune.L1Unstructured,\r\n",
        "    amount=0.2,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADYNSPc1eqLF",
        "outputId": "39fd3c9b-8a8c-4090-c41b-b82d55a90e1f"
      },
      "source": [
        "for i in range(12):\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(model.roberta.encoder.layer[i].attention.self.key.weight == 0))\r\n",
        "            / float(model.roberta.encoder.layer[i].attention.self.key.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(model.roberta.encoder.layer[i].attention.self.query.weight == 0))\r\n",
        "            / float(model.roberta.encoder.layer[i].attention.self.query.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(model.roberta.encoder.layer[i].attention.self.value.weight == 0))\r\n",
        "            / float(model.roberta.encoder.layer[i].attention.self.value.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print()\r\n",
        "\r\n",
        "    \r\n",
        "numerator, denominator = 0, 0\r\n",
        "for i in range(12):\r\n",
        "    numerator += torch.sum(model.roberta.encoder.layer[i].attention.self.key.weight == 0)\r\n",
        "    numerator += torch.sum(model.roberta.encoder.layer[i].attention.self.query.weight == 0)\r\n",
        "    numerator += torch.sum(model.roberta.encoder.layer[i].attention.self.value.weight == 0)\r\n",
        "\r\n",
        "    denominator += model.roberta.encoder.layer[i].attention.self.key.weight.nelement()\r\n",
        "    denominator += model.roberta.encoder.layer[i].attention.self.query.weight.nelement()\r\n",
        "    denominator += model.roberta.encoder.layer[i].attention.self.value.weight.nelement()\r\n",
        "    \r\n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity in Layer 1-th key weight: 8.77%\n",
            "Sparsity in Layer 1-th query weightt: 9.43%\n",
            "Sparsity in Layer 1-th value weight: 30.25%\n",
            "\n",
            "Sparsity in Layer 2-th key weight: 13.05%\n",
            "Sparsity in Layer 2-th query weightt: 12.83%\n",
            "Sparsity in Layer 2-th value weight: 32.48%\n",
            "\n",
            "Sparsity in Layer 3-th key weight: 16.20%\n",
            "Sparsity in Layer 3-th query weightt: 16.05%\n",
            "Sparsity in Layer 3-th value weight: 30.37%\n",
            "\n",
            "Sparsity in Layer 4-th key weight: 18.34%\n",
            "Sparsity in Layer 4-th query weightt: 18.03%\n",
            "Sparsity in Layer 4-th value weight: 25.54%\n",
            "\n",
            "Sparsity in Layer 5-th key weight: 17.15%\n",
            "Sparsity in Layer 5-th query weightt: 16.99%\n",
            "Sparsity in Layer 5-th value weight: 25.25%\n",
            "\n",
            "Sparsity in Layer 6-th key weight: 19.17%\n",
            "Sparsity in Layer 6-th query weightt: 18.73%\n",
            "Sparsity in Layer 6-th value weight: 24.63%\n",
            "\n",
            "Sparsity in Layer 7-th key weight: 16.95%\n",
            "Sparsity in Layer 7-th query weightt: 16.50%\n",
            "Sparsity in Layer 7-th value weight: 27.09%\n",
            "\n",
            "Sparsity in Layer 8-th key weight: 18.73%\n",
            "Sparsity in Layer 8-th query weightt: 18.23%\n",
            "Sparsity in Layer 8-th value weight: 27.98%\n",
            "\n",
            "Sparsity in Layer 9-th key weight: 17.95%\n",
            "Sparsity in Layer 9-th query weightt: 17.28%\n",
            "Sparsity in Layer 9-th value weight: 27.48%\n",
            "\n",
            "Sparsity in Layer 10-th key weight: 17.00%\n",
            "Sparsity in Layer 10-th query weightt: 16.14%\n",
            "Sparsity in Layer 10-th value weight: 29.15%\n",
            "\n",
            "Sparsity in Layer 11-th key weight: 15.68%\n",
            "Sparsity in Layer 11-th query weightt: 15.31%\n",
            "Sparsity in Layer 11-th value weight: 29.99%\n",
            "\n",
            "Sparsity in Layer 12-th key weight: 14.40%\n",
            "Sparsity in Layer 12-th query weightt: 14.96%\n",
            "Sparsity in Layer 12-th value weight: 25.94%\n",
            "\n",
            "Global sparsity: 20.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_Yl5S14X-r"
      },
      "source": [
        "# for i in range(12):\r\n",
        "#     print(\r\n",
        "#         \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\r\n",
        "#             i+1,\r\n",
        "#             100. * float(torch.sum(model.bert.encoder.layer[i].attention.self.key.weight == 0))\r\n",
        "#             / float(model.bert.encoder.layer[i].attention.self.key.weight.nelement())\r\n",
        "#         )\r\n",
        "#     )\r\n",
        "#     print(\r\n",
        "#         \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\r\n",
        "#             i+1,\r\n",
        "#             100. * float(torch.sum(model.bert.encoder.layer[i].attention.self.query.weight == 0))\r\n",
        "#             / float(model.bert.encoder.layer[i].attention.self.query.weight.nelement())\r\n",
        "#         )\r\n",
        "#     )\r\n",
        "#     print(\r\n",
        "#         \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\r\n",
        "#             i+1,\r\n",
        "#             100. * float(torch.sum(model.bert.encoder.layer[i].attention.self.value.weight == 0))\r\n",
        "#             / float(model.bert.encoder.layer[i].attention.self.value.weight.nelement())\r\n",
        "#         )\r\n",
        "#     )\r\n",
        "#     print()\r\n",
        "\r\n",
        "    \r\n",
        "# numerator, denominator = 0, 0\r\n",
        "# for i in range(12):\r\n",
        "#     numerator += torch.sum(model.bert.encoder.layer[i].attention.self.key.weight == 0)\r\n",
        "#     numerator += torch.sum(model.bert.encoder.layer[i].attention.self.query.weight == 0)\r\n",
        "#     numerator += torch.sum(model.bert.encoder.layer[i].attention.self.value.weight == 0)\r\n",
        "\r\n",
        "#     denominator += model.bert.encoder.layer[i].attention.self.key.weight.nelement()\r\n",
        "#     denominator += model.bert.encoder.layer[i].attention.self.query.weight.nelement()\r\n",
        "#     denominator += model.bert.encoder.layer[i].attention.self.value.weight.nelement()\r\n",
        "    \r\n",
        "# print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtTajjdCeJta"
      },
      "source": [
        "## **학습**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8kvqU9J4X-s"
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 4\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMQS5-UYgGu7"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    \r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZpAZfxqgIdc"
      },
      "source": [
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "StGnfni4eNVC",
        "outputId": "082003d3-ac7a-454b-ed48-843507b49f86"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        " \n",
        "seed_val = 42\n",
        " \n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "criterion = CrossEntropyLoss()\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "for epoch_i in range(0, epochs):\n",
        "    #               Training\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        " \n",
        "    t0 = time.time()\n",
        " \n",
        "    total_train_loss = 0\n",
        " \n",
        "    model.train()\n",
        " \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        " \n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels         \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        " \n",
        "        model.zero_grad()        \n",
        " \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        # break\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        " \n",
        "        loss.backward()\n",
        " \n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        " \n",
        "        optimizer.step()\n",
        " \n",
        "        scheduler.step()\n",
        " \n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        " \n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    #               Validation\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        " \n",
        "    t0 = time.time()\n",
        "    \n",
        "    model.eval()\n",
        " \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        " \n",
        "    for batch in validation_dataloader:\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "            \n",
        "        total_eval_loss += criterion(logits, b_labels)\n",
        " \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        " \n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Accuracy: {0:.4f}\".format(avg_val_accuracy))\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        " \n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        " \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        " \n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:25.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:12:49.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:19:14.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:25:39.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:32:03.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:38:28.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:44:52.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:51:17.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:54:05\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.8852\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:01:47\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:25.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:12:49.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:19:14.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:25:39.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:32:03.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:38:28.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:44:53.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:51:17.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:54:05\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.8874\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:01:46\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:25.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:12:49.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:19:14.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:25:38.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:32:03.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:38:27.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:44:52.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:51:16.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:54:04\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.8945\n",
            "  Validation Loss: 0.28\n",
            "  Validation took: 0:01:46\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:24.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:12:49.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:19:14.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:25:38.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:32:03.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:38:27.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:44:52.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:51:17.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:54:05\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.8975\n",
            "  Validation Loss: 0.31\n",
            "  Validation took: 0:01:47\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:43:26 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "hj5uhQ8deQXK",
        "outputId": "3ece876e-a323-4090-f6a1-253a8057afd6"
      },
      "source": [
        "import pandas as pd\n",
        " \n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 4)\n",
        " \n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        " \n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        " \n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        " \n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.3382</td>\n",
              "      <td>tensor(0.2908, device='cuda:0')</td>\n",
              "      <td>0.8852</td>\n",
              "      <td>0:54:05</td>\n",
              "      <td>0:01:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.2479</td>\n",
              "      <td>tensor(0.2904, device='cuda:0')</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0:54:05</td>\n",
              "      <td>0:01:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.2004</td>\n",
              "      <td>tensor(0.2849, device='cuda:0')</td>\n",
              "      <td>0.8945</td>\n",
              "      <td>0:54:04</td>\n",
              "      <td>0:01:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.1649</td>\n",
              "      <td>tensor(0.3064, device='cuda:0')</td>\n",
              "      <td>0.8975</td>\n",
              "      <td>0:54:05</td>\n",
              "      <td>0:01:47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  ... Validation Time\n",
              "epoch                 ...                \n",
              "1             0.3382  ...         0:01:47\n",
              "2             0.2479  ...         0:01:46\n",
              "3             0.2004  ...         0:01:46\n",
              "4             0.1649  ...         0:01:47\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "V3ExG6UNeS-D",
        "outputId": "d5082904-a3d8-4b1d-bfa5-b827410e7f62"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        " \n",
        "import seaborn as sns\n",
        " \n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        " \n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        " \n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        " \n",
        "# Label the plot.\n",
        "plt.title(\"Training Loss & Validation Acc\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "# plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvoAAAGaCAYAAAB+A+cSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVxUVf/A8c8MMOyLsm8uoYAKrpialpob7htk7pqZZplZPZnl86g9j/1SKzMre9JcMnMFBfetsjLL7SlT0RK3EFRc2JcZmPn9QYwMMyAoMIDf9+tVOOfee+6ZYa5+z7nfc65Cp9PpEEIIIYQQQtQqSnM3QAghhBBCCFHxJNAXQgghhBCiFpJAXwghhBBCiFpIAn0hhBBCCCFqIQn0hRBCCCGEqIUk0BdCCCGEEKIWkkBfCFHrJSQkEBQUxJIlS+67jjfeeIOgoKAKbJWoboKCgnjjjTcMyp588klGjx5dpuOjo6MJCgril19+qfC2/fLLLwQFBREdHV3hdQshai8J9IUQVS4oKKjM/yUkJJi7udVKUFAQkyZNMnczyi0vL4/ly5cTHh5O8+bN6dSpE1OmTOHEiRNlrmP+/PkEBQWxf//+UvcbNWoUTZo0ISkp6UGbXaXi4uJYsmRJjfnOR0ZGEhQUxJtvvmnupgghSmBp7gYIIR4+CxYsMHh9/PhxNmzYwLBhw2jTpo3Btrp16z7w+Xx9fTl58iQWFhb3Xce///1v5s6d+8BteVgtXryYzz//nE6dOjFu3DhSUlI4dOgQP/30E61bty5THREREaxYsYKoqCi6d+9ucp8rV65w7NgxOnbsiLe39wO3e/fu3Q9cR1nFxcXx8ccf8+ijj+Ln52ewrW3btpw8eRJLy+rxz/Yff/zByZMnqVevHrt27WLWrFnY2dmZu1lCiGKqx98YQoiHysCBAw1e5+fns2HDBlq2bGm0rbiMjAwcHBzKdT6FQoG1tXW521mUlZXVAx3/sNuyZQsBAQEsW7YMpbLgZvLkyZNRq9VlriMgIIBWrVrx/fffc/PmTdzc3Iz2iY6ORqfTERERUSHtVqlUFVLPg1IqlQ/8Ha5Imzdvxt7enoULFzJs2DB27drF0KFDzd0sIUQxkrojhKi2CvOjz5w5w4QJE2jTpg0DBgwACgL+RYsWERkZSbt27QgJCaFHjx689957ZGdnG9RjKke/aNm3337L0KFDCQ0NpVOnTsyfP5+8vDyDOkzl6BeWpaenM3v2bDp06EBoaChPP/00v/32m9H7uXPnDjNnzqRdu3a0atWKMWPGcObMGUaPHs2TTz5ZUR+b/v394x//4LHHHiMkJITu3bvzwQcfGH02KSkpvPPOO3Tv3p3Q0FDatWvHkCFDWL58ucF+W7duJSIigrCwMFq2bEm3bt149dVXuX37dpnao1AosLS01Af5hcobSEdERJCXl0dMTIzRNq1Wy9atW3FxcaFbt25otVqWLl3KyJEj6dixIyEhIXTp0oXZs2dz586dMp2vpBz9jRs3Eh4erv/erVq1Cp1OZ7Tf9evXeffddxk4cCBt27YlNDSUPn368Pnnn5Ofn6/fb8mSJcycOROAMWPG6FPXCucMlJSjn5WVxfvvv0/37t0JCQmhY8eOvP7661y9etVgv6LHR0VF0bdvX0JCQujatSvLli0r02dRSK1WExsbS69evWjZsiVNmzZl8+bNJe6/Z88eRo8eTVhYGC1atKBXr1785z//Mejk6XQ6Nm7cSGRkJK1ataJVq1b079+fxYsXl6ttQghDMqIvhKjWEhMTGTt2LOHh4fTs2ZOsrCygIIDavHkzPXv2pF+/flhaWnLkyBGWL19OXFwcX3zxRZnqP3jwIF9//TVPP/00Q4cO5cCBA6xYsQJnZ2cmT55cpjomTJhA3bp1eeGFF0hJSWHlypU899xzHDhwQH/3Qa1WM378eOLi4hgyZAihoaGcO3eO8ePH4+zsfH8fTgmuXr1KZGQk6enpjBgxgvr163PkyBH++9//cuLECVatWqVPAZk2bRrHjh3j6aefJigoiJycHOLj4zly5AjPPvssUBDkz5gxg7CwMF566SVsbGxISkri4MGD3Lp1q0zpVcOHD9en7zz33HP3/d569+7NvHnziI6OZsKECQbbfvrpJ5KSkhgzZgwqlYrc3Fy++OILevbsSbdu3bC1teX3338nKiqKEydOEBUVdV8j9qtWreL//u//CA4O5pVXXiE7O5sVK1bg6upqtO+5c+fYu3cvPXr0oF69emg0Gn744Qfef/99EhISePvttwHo0aMHycnJbNiwgcmTJ/PII48AUK9evRLbodFomDBhAidOnKBXr16MHz+ey5cvs27dOg4dOkRUVBReXl4Gx6xfv56bN28SERGBk5MTsbGxvPfee3h5edG/f/8yvf8DBw5w584dBg8eDMDgwYOZN28eFy5c0Le70KJFi/jss89o1KgR48aNw93dnStXrrB3715eeukl/ef/j3/8g23bttGiRQsmT56Mo6MjFy5cYM+ePUybNq1M7RJCmKATQggzi4qK0gUGBuqioqIMyrt27aoLDAzUbdy40eiY3NxcnVqtNipftGiRLjAwUPfbb7/py/766y9dYGCg7qOPPjIqa9Gihe6vv/7Sl2u1Wl3fvn11HTt2NKh3xowZusDAQJNls2fPNijfuXOnLjAwULdu3Tp92VdffaULDAzUffrppwb7FpZ37drV6L2YEhgYqHvuuedK3eeVV17RBQYG6r777juD8nfffdfg80xLSzPZ/uJeeOEFXatWrXQajaZMbSxOrVbrZs6cqQsJCdEFBgbqVqxYcV/1FJo5c6bR71in0+mmT5+uCwwM1MXFxel0uoLfZXZ2ttHxGzdu1AUGBup27NhhUB4YGKibMWOGQVnXrl11o0aN0r9OTU3VtWjRQte7d29dVlaWvjwpKUnXsmVLXWBgoO7nn3/Wl2dnZ+u0Wq1RG1577TVdcHCw7vr16/qywuug6PGFfv75Z6NrZMOGDbrAwEDd/PnzDfb99ttvdYGBgbrXXnvN6PiOHTvq0tLS9OVZWVm6du3a6Z566imjc5ZkwoQJuq5du+rf161bt3TNmjXTLViwwGC/3377TRcYGKgbPXq0Licnx2CbVqvVH79jxw59e/Pz8w32K/5aCFE+krojhKjWXFxcGDJkiFG5SqXS583n5eWRmprK7du3eeyxxwBMps6Y0q1bN4OJjwqFgnbt2pGcnExmZmaZ6hg3bpzB6/bt2wNw+fJlfdm3336LhYUFY8aMMdg3MjISR0fHMp2nLLRaLd988w1Nmzalc+fOBtsmTZqEUqnUr1pjbW2NSqXi5MmTpa704ujoSE5ODt99953J9JR7mTNnDrt27SIqKorhw4fz7rvv8vnnnxvs89lnnxEUFMRff/11z/oK8++joqL0ZWlpaezfv5+QkBCCg4OBgt+ljY0NUDAPJC0tjdu3b+t/PydPniz3e/nxxx/Jzs5m5MiR2Nra6stLGhG3sbFBoVAABXd1UlJSuH37Np06dUKr1XLq1Klyt6HQvn37UCqVRqswdenShSZNmnDgwAG0Wq3BtqFDhxp832xtbWnZsiWXLl0q0zmTkpI4dOgQgwYN0r+vunXr0rlzZ2JiYgxS3mJjYwF49dVXjeYXKBQK/fHbtm0DYMaMGUapXcVfCyHKR1J3hBDVmr+/f4mr5axdu5b169dz/vx5o4AmNTW1zPUX5+LiAhTkr9vb25e7jjp16uiPL5SQkICHh4dRfSqVCj8/P9LS0srU3nu5ffs2WVlZNGrUyGibi4sL7u7u+mBapVLx5ptvMm/ePLp160ajRo1o37493bt3p0OHDvrjJk2axNGjR3nhhRdwcXHh0Ucf5YknnqB37973nBh9+vRpNm/ezMsvv0xgYCCzZ88mPz+f999/H41GwwsvvAAUpLh4enoarTZjSuvWrXnkkUfYuXMnb775JtbW1mzbto3c3FyjCaE7d+5k5cqVxMXFodFoDLaV9TtSVGGHqHiKChRMFi4uLy+Pzz//nJiYGC5fvmzUUXqQ33vhd8pU6lejRo2Ii4vjzp07BilFpj5fFxcXg+9qaaKjo9FqtbRu3dqgI9u+fXv279/PwYMH6datG1DQ0VUoFPqOV0kuX76Mu7u7ycnVQogHI4G+EKJaKzpqWtTKlSt599136dSpE2PGjMHDwwMrKyuuX7/OG2+8UeaR59KW3HzQOu5n9LuqDR8+nG7dunHw4EGOHDnCnj17+Oqrr+jTpw+LFi0CoEGDBuzcuZPDhw9z+PBhjhw5wqxZs/joo49Yu3ZtqXnkR48eBQqWh4SCkdy3336bvLw8PvroI/Ly8nj66afZv38/zz77rH6U916GDh3KwoUL2bt3L/379yc6OhobGxuDUfW9e/cyffp0mjdvzptvvom3tzfW1tbk5+fz7LPPVsnv591332XNmjX06dOHyZMnU7duXaysrDh9+jTvvfeeUQe1sj3IErM6nU4/Gbj4/IhCUVFR+kAfDEfuhRBVTwJ9IUSNFBMTg6+vr8FyjQDff/+9GVtVMl9fXw4fPkxmZqbBqL5GoyEhIQEnJ6cKOU/dunWxt7fn/PnzRttSU1NJTk6mSZMmBuUeHh5ERkYSGRlJfn4+r7/+Otu3b2f8+PE0b94cKBj979y5sz4d6ODBgzz33HOsXLmS2bNnl9iewiAvISGBsLAwfdm8efPQarV8+umnbN++HWdnZ8aPH1/m9zlo0CAWLVqkfxrtqVOn6N+/v0FaSkxMDNbW1nz55ZcGHcb4+Pgyn6e4whHxCxcuGNz1KKnemJgY2rZtq+80FSo6Gl6ovAGxv78/P/zwA2lpaUbfn/j4eBwcHPR3lyrCzz//TEJCAmPHjjX57IMdO3bwzTff6Jc+bdCgAd9//z1nz57Vf49MadCgAQcOHChxyVQhxP2T5DchRI2kVCpRKBQGo7J5eXnlXiqwqjz55JPk5+fz5ZdfGpRv3LiR9PT0CjuPUqmka9eunDlzxqjT8/nnn6PVavUPm8rOzjZabtPCwkK/jGhhaoupJTSbNm1qsE9JOnXqhFKpZOnSpQZpKkqlkn//+9/Ur1+fK1eu8Pjjj5ers+Pm5kaXLl34+eef+fjjjwGM1s63sLBAoVAYjJrrdDqWLl1a5vMU17FjR2xsbFi7dq3BZ3ft2jV9rnlRSqXS6M5BVlYWq1atMtq38IFTZU0p6t69O1qt1mi+w8GDBzlz5gxPPvlkhea4b968GQsLCyZPnkx4eLjRf6NHjyYvL4+tW7cC6O+ufPDBByafl1D4uRTut3DhQqM7HDXhrpgQ1ZmM6AshaqTw8HDef/99Jk6cSI8ePcjIyGD79u3V5smhxUVGRrJ+/Xo+/PBDrly5ol9ec/fu3dSvX99o3f7SXL58mU8//dTktnHjxvHKK6/w008/8cILLzBixAjq1avHsWPH2LlzJ23bttUvi3jp0iVGjRpFjx49aNy4MU5OTly4cIF169bh5+enH4GfMGECjo6OhIWF4e3tTVpaGlu2bEGhUNzzAWcBAQFMnTqVxYsX07t3byIiIvDz8+PGjRts376da9eu0apVK6KjowkMDCzXqH5ERAT79+9nz549+Pv7065dO4PtvXr1Ys+ePYwdO5ZBgwaRl5fH/v37jTo35eHs7My0adOYP38+Tz/9NIMGDSI7O5v169fToEEDzpw5Y9SGDRs28PLLL/PYY49x8+ZNoqKi9PNAigoNDUWpVPLZZ5+RmpqKnZ0dfn5+tGjRwmRbBg8ezJYtW1i2bBlXr14lLCyMK1eu8PXXX+Pm5sYrr7xy3++zuLS0NPbt20ebNm1KXE41LCwMV1dXoqKiePbZZ2nevDkTJ05k2bJlDBkyhN69e+Pu7k5CQgJ79uxh06ZNODk50bt3b/bu3cvWrVu5fPkyTz75JE5OTly6dIkff/yR7du3V9j7EOJhUz3/RRRCiHuYMGECOp2OzZs3M2/ePNzd3enduzdDhw6lT58+5m6eEZVKxerVq1mwYAEHDhxg165dNG/enFWrVvHWW2+Rk5NT5rouXrxY4oOEIiMj8fX1ZePGjXz00UfExsaSnp6Op6cnkyZN4vnnn9d3hry8vBg6dCi//PIL+/fvR61W4+npSWRkJBMnTtSnuwwfPpxdu3axYcMGUlNTcXFxoUmTJsyaNUu/gk1ppkyZQrNmzVi9ejVr164lJycHDw8POnbsyNKlS/Hx8WHs2LHMnz8fJyenMj9h9YknnsDDw4MbN24wePBgo9SXvn37kpmZyapVq5g/fz7Ozs507dqVV1991ahTUB7PPPMMdnZ2rFy5kvfffx9vb2+eeeYZHB0defPNNw32nTlzJvb29uzevZsDBw7g7e3NsGHDCA0NNVqtycfHh3feeYdly5Yxd+5cNBoNgwcPLjHQt7Ky4osvvmDp0qXs3LmTffv24ejoSHh4OC+//DLe3t73/R6LK5zs3LNnzxL3USqVdO/enQ0bNnDixAlat27Na6+9RnBwMF999RXLly9Hp9Ph5eXFE088oV8RCeD9998nLCyMzZs388knn6BUKvHz8yM8PLzC3oMQDyOFTu6LCSGE2eTn59O+fXuaN29e5od8CSGEEGUhOfpCCFFFTI3ar1+/nrS0NDp27GiGFgkhhKjNJHVHCCGqyKxZs1Cr1bRq1QqVSsX//vc/tm/fTv369XnqqafM3TwhhBC1jKTuCCFEFdm6dStr167l0qVLZGVl4erqSufOnZk2bZosKyiEEKLCSaAvhBBCCCFELSQ5+kIIIYQQQtRCEugLIYQQQghRC8lk3Ep0504mWm3VZka5ujpw61ZGlZ5TiJpIrhUhykauFSHKxlzXilKpoE4de5PbJNCvRFqtrsoD/cLzCiHuTa4VIcpGrhUhyqa6XSuSuiOEEEIIIUQtJIG+EEIIIYQQtZAE+kIIIYQQQtRCEugLIYQQQghRC0mgL4QQQgghRC0kq+4IIYQQQlSx7OxMMjJSyc/XmLspooLcuKFEq9VWWH0WFlY4ODhja2t66cyykEBfCCGEEKIKaTRq0tPv4OLihpWVNQqFwtxNEhXA0lJJXl7FBPo6nQ6NJpeUlJtYWlphZaW6r3okdUcIIYQQogqlp6fg4OCMSmUjQb4wSaFQoFLZYG/vTEZGyn3XI4G+EEIIIUQVystTY21ta+5miBrAxsYWjUZ938dL6k4tcfj0NaIPxnM7LZe6TtYM6RxAh2Ze5m6WEEIIIYrRavNRKi3M3QxRAyiVFmi1+fd9vAT6tcDh09dYvess6r/zwm6l5bJ611kACfaFEEKIakhSdkRZPOj3RFJ3aoHog/H6IL+QOk9L9MF4M7VICCGEEEKYmwT6tcCttNxylQshhBBC1DQvvvgcL774XJUfW5NJ6k4t4OpkbTKot7ZSotbko7KSPEAhhBBCVI5OncLKtN+mTbF4e/tUcmtEUQqdTqczdyNqq1u3MtBqK//jLZ6jD2ChVJCv1eHv4cCUQSF41rWr9HYIUZO4uzuSnJxu7mYIUe3JtVLxrl27jJdXfXM3o8Ls2bPT4PXGjeu4fj2JqVNfMSh/4omu2Nre/2pDGk3Bw8WsrKyq9Niyqsh19Iu61/dFqVTg6upguk0V3hpR5Qon3BZfdcfexopl204zd9VRnunThLBgDzO3VAghhBC1Ta9efQxef/fdAVJTU4zKi8vJycHGxqbM53mQIL0yA/zqTAL9WqJDMy86NPMyGnmZM/5Rlsac4tOtp+jexo+nnmyEpYVMzRBCCCFE1XnxxefIyMjg9dffZMmSRZw7d5aRI8cwYcIkfvjhO2Jjt/DHH+dIS0vF3d2DPn36M3r0eCwsLAzqAPj4488BOHHiGC+9NJl58xZw8eIFtm6NIi0tldDQFvzjH2/i5+dfIccCREVtZP36tdy6dZOAgABefHE6y5YtNaizOpJAv5ZzdbbhjZGt2fjtefYfS+BCUhrPDwzB1bnsPWghhBBCVG+Fz9O5lZaLazV9nk5Kyh1ef306PXuGEx7eF0/Pgvbt3LkdW1s7hg0biZ2dLcePH2P58s/IzMzkhRem3bPe1au/QKm0YMSIMaSnp7Fu3Rrmzp3FsmWrK+TYLVs2s2jRAlq2bM2wYcNJSkpi5szXcHR0xN29emdLSKD/ELC0UDKieyCBfi6s2BnHnJVHmNi/Kc0D3MzdNCGEEEI8oJryPJ2bN5N5441/0q/fQIPyOXP+g7X13QHIQYMiWLjwHbZs2cTEic+jUqlKrTcvL48VK1ZjaVkQ1jo5ObN48XtcuHCeRx5p9EDHajQali9fSrNmoXz44af6/Ro1asy8eXMk0BfVR1iwB/6eDny65RQfbjpJ3w71GfR4QyyUksojhBBCmNOh35P48WTSfR0bn5hKXr7h4h/qPC0rd8bx/a+J5aqrU3NvOoZ631c77sXGxobw8L5G5UWD/KysTNRqDS1atCImJprLly/RuHFgqfX27TtAH4ADtGjREoDExKv3DPTvdezZs2dITU1lypTBBvv16BHORx99UGrd1YEE+g8Zzzp2vDW6DV/v/4Mdhy8TfzWV5wY0w8XB2txNE0IIIcR9KB7k36vcXNzdPQyC5UIXLsSzbNlSTpw4SmZmpsG2zMyMe9ZbmAJUyNHRCYD09HuvFnWvY69dK+h8Fc/Zt7S0xNu7cjpEFUkC/YeQysqCcb2b0NjPhTV7zjFn5VEmD2hGcP065m6aEEII8VDqGHr/I+n/+PSQyefpuDpZM2Nk6wdtWoUpOnJfKD09nalTn8POzoEJEybj6+uHSqXijz/OsnTpErTaey9XqVSafl5QWVaQf5BjawLJ2XiIdQz1ZtbYMOysLVm4/n9s/+kS2lryxRZCCCEeFkM6B6CyNAzpVJZKhnQOMFOLyu5//ztOamoqb701m6eeGk7Hjo/Ttm07/ci6uXl5FXS+EhL+MijPy8sjKen+Uq2qkgT6Dzk/dwf+OTaMtsEeRH9/gcWbTpKRrTF3s4QQQghRRh2aeTG2dzCuTgVpuK5O1oztHVytJuKWRPn3PMGiI+gajYYtWzaZq0kGgoOb4uzsTGzsFvLy8vTl+/btJj09zYwtKxtJ3RHYWlsyaUAzgvxdWHfgT+asPMLzA0MI8HU2d9OEEEIIUQaFz9OpaUJDm+Po6MS8eXOIiBiGQqFgz56dVJcEAysrK5555jkWLVrIyy9PoWvXbiQlJbFr1zZ8ff1QKBTmbmKpZERfAKBQKOja2o+Zo9qgVCh4d+0J9h39q9bkqAkhhBCi+nF2dmHBgkW4urqxbNlS1q37irCwdkyZ8pK5m6Y3dOgwXn75Na5dS+KTTxbz22//4913P8DBwRGVqnovZqLQSSRXaW7dykCrrdqPt/iTce9HZo6GL7bH8ev5m4QFuTOudxPsbOTmj6hdKuJaEeJhINdKxbt27TJeXvXN3QzxALRaLf369aBz567MmDELAEtLJXl59548XF73+r4olQpcXR1Mb6vw1ogaz97GiqlDQ4nsGsCJP27y9uqjXLkuf8kLIYQQ4uGTm2u8otHu3TtIS0ulVas2ZmhR2ckwrTBJoVDQu119Anyc+SzmFPPWHGdkj0Aeb+5d7fPRhBBCCCEqysmTv7J06RK6dHkSJydn/vjjLDt2xPLIIwF07drd3M0rlVkDfbVazeLFi4mJiSEtLY3g4GCmT59Ohw4dSj0uNjaWzZs3Ex8fT2pqKh4eHrRr144XX3wRX19f/X5JSUls3ryZgwcPcvnyZZRKJYGBgUyZMsXoHEuWLOHjjz82OpebmxuHDh2qmDdcAwX6uzBn/KN8vu00q3ad5c+/UhjVMwhrlel1Z4UQQgghahMfH1/c3NzZvHkDaWmpODk5Ex7el8mTX8TKysrczSuVWQP9N954g7179zJmzBjq16/Pli1bmDhxImvWrKFVq1YlHnf27Fk8PT3p3Lkzzs7OJCYmsnHjRr777jtiY2Nxd3cH4MCBAyxfvpzu3bszePBg8vLyiImJYdy4ccyfP59BgwYZ1f32229jY3P3gQ5F//ywcrJX8cpTLYk9dJFthy5x6Vo6UwaH4O1qb+6mCSGEEEJUKl9fPxYsWGTuZtwXs03GPXnyJJGRkcycOZNx48YBBTlQ/fr1w8PDg7Vr15arvtOnTzNkyBBef/11JkyYAMCff/6Jq6srdevW1e+nVqsZOHAgubm5fPPNN/rywhH9o0eP4uRUMQ9pqKmTcUtz6uItPo89gyZfy7jwYNo19ay0cwlRmWSCoRBlI9dKxZPJuLWTTMYtYvfu3VhZWREZGakvs7a2JiIiguPHj3Pjxo1y1efj4wNAWtrdhxc0btzYIMgHUKlUdO7cmatXr5KTk2NUj06nIyMjQ5aVLEFIQ1fmPvMo/h4O/Df2NGv2nENTCV9qIYQQQgjxYMyWuhMXF0fDhg2xtzdM/2jevDk6nY64uDg8PDxKrSMlJYX8/HwSExP55JNPAO6Z3w+QnJyMnZ0d1tbGa5926dKFrKws7O3t6dWrFzNmzMDFxaUc76z2q+NozevDWxF98AK7j1zhYlIazw8Kwd3F1txNE0IIIYQQfzNboJ+cnIynp3HaR2F+fVlG9Hv16kVKSgoALi4u/Otf/6J9+/alHnP58mX27dtH3759DVaPcXJyYvTo0bRo0QIrKyt+/vlnNmzYwJkzZ9i0aRMqlao8b6/Ws7RQ8tSTjWjs58zyHXHMXXmUCf2a0Kqxu7mbJoQQQgghMGOgn5OTY3KmcuEou6k1S4v7+OOPycrK4uLFi8TGxpKZmVnq/tnZ2UybNg1bW1umT59usG3s2LEGr8PDw2ncuDFvv/02W7du5amnnrpne4orKV+qsrm7O1bZuXq6O9I82JN3vzzKkqjfGdKlEaP7NMHSQh7RIKq/qrxWhKjJ5FqpWDduKLG0lH8na6PK+L0qlcr7vgbNFujb2Nig0WiMygsDfFNpNcW1bdsWgM6dO9OtWzf69++PnZ0do0aNMto3Pz+f6dOnEx8fzxdffHHPtCCA4cOHs3DhQg4fPnxfgX5tnIxrigXw+tMtWXfgPNHfnef388lMHhhCHcfq/Vho8XCTCYZClI1cKxVPq9VWyqRNYV6VNRlXq9WWekm8+Y8AACAASURBVA1Wy8m47u7uJtNzkpOTAcoUiBfl7+9Ps2bN2LZtm8nts2bN4uDBg8yfP59HH320THUqlUo8PT1JTU0tV1seRlaWFozpFcRz/Zty5XoGc1Ye4fSl2+ZulhBCCCHEQ8tsgX5wcDAXL140Srf57bff9NvLKycnh/R04x7P/PnziY6O5s0336RPnz5lrk+j0ZCUlESdOnXK3ZaHVftmXvxzbBiOdio+WP8rMT9erPK7GkIIIYSo2Xbu3EanTmEkJSXqyyIi+jNv3pz7OvZBnThxjE6dwjhx4liF1VkVzBboh4eHo9Fo2LRpk75MrVYTHR1N69at9RN1ExMTiY+PNzj29m3jkeJTp05x9uxZmjVrZlC+fPlyVqxYweTJkxk9enSJ7TFV5xdffEFubi6PP/54ud7bw87HzZ5/jgmjfTMvYn68yKJNv5GWpTZ3s4QQQghRSV5/fTrdu3ciOzu7xH1eeeVFevXqXKZ5mOayf/8eNm782tzNqDBmy9Fv0aIF4eHhvPfeeyQnJ1OvXj22bNlCYmIi//d//6ffb8aMGRw5coRz587py7p27Urv3r0JDAzEzs6O8+fPExUVhb29PVOmTNHvt2/fPhYuXEiDBg145JFHiImJMWhDjx49sLOz09fZp08fAgMDUalU/PLLL+zZs4c2bdrQr1+/Sv40ah9rlQXP9mtCoL8za/f9ydyVR5k8sBmN/WSpUiGEEKK26dGjFz/99AM//niQHj3CjbbfuXOb48eP0rNn7zLNwzTl66+jUCord4z6wIG9/PnnHzz11AiD8pYtW3PgwCGTC8lUZ2YL9AEWLFjAhx9+SExMDKmpqQQFBfH555/Tpk2bUo8bMWIEhw8fZv/+/eTk5ODu7k54eDhTpkzB399fv9/Zs2cBuHTpEq+//rpRPQcOHNAH+v379+fEiRPs3r0bjUaDr68vU6ZMYdKkSVhamvVjqrEUCgWdW/rSwMuJpVtPMX/t/4joEkCvR/0NljYVQgghRM32+ONdsLW1Y//+PSYD/W++2U9+fj49expvKytzLnWuVCrvu4NiTmaNYK2trZkxYwYzZswocZ81a9YYlZW2f1FTp05l6tSpZdr3P//5T5n2E+VX38uRf41ry4qdcWz89jx/JqQwoW8T7GxqVq9YCCGEEKbZ2Njw+OOd+fbb/aSlpeHk5GSwff/+Pbi6uuLvX5/33nuX48ePcP36dWxsbGjdOowXXpiGt7dPqeeIiOhPq1ZteOutOfqyCxfi+fDDhZw69TvOzs4MHDgENzfjZ/r88MN3xMZu4Y8/zpGWloq7uwd9+vRn9OjxWFhYAPDii8/x668nAOjUKQwALy9vNm/exokTx3jppcl89NFntG4dpq/3wIG9fPXVKi5fvoS9vT2PPfY4zz//ksHDVl988TkyMjL417/e5oMPFhAXdxpHRyciI59m5EjD5d0rmgxViyphZ2PJC4ND2HcsgU3fnmfOyqNMGRxCAy+nex8shBBCiFIduXaC2Pjd3MlNoY61CwMCwnnUq3WVtqFHj3D27t3Fd98dYMCAwfrya9eSOHXqJBERTxMXd5pTp07SvXsv3N09SEpKZOvWKKZOncRXX23CxsamzOe7desmL700Ga1Wy6hRY7GxsSU2dovJkfedO7dja2vHsGEjsbOz5fjxYyxf/hmZmZm88MI0AMaOfYbs7GyuX09i6tRXALC1tSvx/Dt3buOdd+bSrFkozz//EjdvXmfTpg3ExZ1m2bIvDdqRlpbKq6++RNeu3ejWrSfffrufpUuX8MgjjejQoWOZ33N5SaAvqoxCoaBnW38e8SlI5XlnzXGGdw+kS0sfSeURQggh7tORayf4+mwUGm3B84nu5Kbw9dkogCoN9tu2bYeLSx32799jEOjv378HnU5Hjx69CAhoRNeu3Q2O69jxCSZPHs933x0gPLxvmc+3du1qUlNTWL58DUFBBas19u7dj+HDBxvtO2fOf7C2vtuJGDQogoUL32HLlk1MnPg8KpWKtm3bEx29idTUFHr1Kn2Vxry8PJYuXUKjRoEsWfJfVCoVlpZKGjcOZs6ct9i2bQsREU/r979x4zqzZ/9Hn9bUr99AIiL6sWNHjAT6onZp5OvMnPFtWbb9DGv2nOPPv1IYEx6EjUq+jkIIIR5OvyQd53DS0fs69mLqFfJ0eQZlGq2GtXGb+SnxSLnq6uDdlnbepc+VLImlpSVPPtmdrVujuHnzJm5ubgDs378XPz9/mjYNMdg/Ly+PzMwM/Pz8cXBw5I8/zpYr0D98+BChoS30QT5AnTp16NGjN1u2bDLYt2iQn5WViVqtoUWLVsTERHP58iUaNw4s13s9e/YMd+7c1ncSCj35ZA8++WQxP/10yCDQd3BwoHv3XvrXVlZWNGnSjMTEq+U6b3lJZCXMwtFOxcuRLdhx+DJbf7jA5evpTBkciq+bvbmbJoQQQtQoxYP8e5VXph49womO3sQ33+zlqadGcOnSRc6f/4Px4ycCkJubw5o1q9i5cxvJyTfQ6e4+aycjI6Nc57p+/RqhoS2MyuvVq29UduFCPMuWLeXEiaNGz3DKzCzfeaEgHcnUuZRKJX5+/ly/nmRQ7uHhaZS94OjoRHz8+XKfuzwk0Bdmo1Qo6P9YAxr5OPHf2NP8e/VRxvYKpkOIl7mbJoQQQlSpdt5t7nskfdahd7iTm2JUXsfahZdbT37QppVLaGgLvL192bdvN089NYJ9+3YD6FNWFi1ayM6d24iMHE5ISCgODg6Agjlz3jQI+itSeno6U6c+h52dAxMmTMbX1w+VSsUff5xl6dIlaLXaSjlvUUqlhcnyynrPhSTQF2bXpEFd5jzzKJ/FnGbZ9jP8kZDCiO6NsbI0fVEIIYQQ4q4BAeEGOfoAVkorBgTc/1KWD6J7956sWbOShIS/OHBgL0FBTfQj34V5+FOnTtfvn5ubW+7RfABPTy8SEv4yKr9y5bLB6//97zipqanMm7eQli3vzlkw/eTcss0Z9PLy1p+raJ06nY6EhL9o2DCgTPVUNrM9GVeIolwcrPnH8Jb0aV+fg78mMu/L49y4k2XuZgkhhBDV3qNerRkRPJQ61gVLOtaxdmFE8NAqX3WnUM+evQH4+ONFJCT8ZbB2vqmR7aioDeTn55f7PB06dOT333/j3Lmz+rI7d+6wb98ug/0KH7JVdPRco9EY5fED2NralqnTERzclDp16rJ162Y0mrsdrG+/PUBy8g0ee6zyJtiWh4zoi2rDQqkkoksAjfyc+WL7GeauOsozfZrQJsjD3E0TQgghqrVHvVqbLbAvrmHDR2jUKJAff/wepVJJt253J6E+9lgn9uzZib29Aw0aNOT06d85duwIzs7O5T7PiBFj2bNnJ6+88gIREU9jbW1DbOwWPD29ycj4U79faGhzHB2dmDdvDhERw1AoFOzZsxNTWTNBQcHs3buLJUs+IDi4Kba2dnTq9ITRfpaWljz//FTeeWcuU6dOonv3niQn32DTpvU88kgA/fsbr/xjDjKiL6qdlo3cmD2uLV517fhkyynWH/iTvPzKz58TQgghRMUoHMVv1aqNfvUdgGnTXqNXrz7s27eLjz/+kJs3b/Lhh5+Uul59Sdzc3Pjoo//SsGEAa9asYtOmdYSH9yEy8mmD/ZydXViwYBGurm4sW7aUdeu+IiysHVOmvGRU58CBQ+nVqzc7d25n7txZfPjhwhLP36dPf+bMmUdubg6ffLKYHTti6dEjnMWLP6s2T9FV6Cp7FsBD7NatDLTaqv143d0dSU5Or9JzVpa8fC0bvjnPgeMJBPg68fzAEOo6lf1BGkKUpjZdK0JUJrlWKt61a5fx8jJeGUbUbJaWSvLyKn5g8l7fF6VSgaurg+ltFd4aISqIpYWSkT0CmTywGQnJmcxZeZTfL9wyd7OEEEIIIWoECfRFtfdoE09mj2uLi4OKDzf+RvT3F6r8TokQQgghRE0jgb6oEbzq2vHWmDA6hnqz/adLvL/hV1Iz1eZulhBCCCFEtSWBvqgxrK0seKZvE8b3CSb+aipzVh7h3JU75m6WEEIIIUS1JIG+qHEeb+7DrDFh2KgsWbjuV3b+fBmtzCkXQgghhDAggb6okfw8HPjX2DDaBLmz+bt4lmw+SUa25t4HCiGEEEI8JCTQFzWWrbUlkwc2Y2SPQE5dvM3clUe5kJhm7mYJIYQQQlQLEuiLGk2hUNCtjR8zR7UB4P++Os6B4wnI4yGEEEJUZ/LvlCiLB/2eSKAvaoVHfJyYPb4tzRrWZe2+P/gs5jTZuXnmbpYQQghhxMLCEo1GVo4T96bRqLGwsLzv4yXQF7WGg60VL0U0J6JLAMfPJfP26mP8dSPD3M0SQgghDDg4uJCSkoxanSsj+8IknU6HWp1LSkoyDg4u913P/XcRhKiGlAoFfdrXJ8DHic9iT/OfL48xqmcgjzf3MXfThBBCCABsbe0BSE29SX6+3H2u6XLz1WRpstHptCgUSuysbLG2UD1wvRYWljg61tF/X+6HQiddyUpz61ZGlT/B1d3dkeTk9Co9Z3WVmqnm89jTxF2+Q6dQb0b2DMTaysLczRLVhFwrQpSNXCtClOzItRN8fTYKjfbuyn9WSitGBA/lUa/WVdIGpVKBq6uD6W1V0gIhzMDZXsWrw1rS/7EGHPo9iXlfHuPa7SxzN0sIIYQQtURs/G6DIB9Ao9UQG7/bTC0yJKk7olZTKhUMfuIRGvk5s2zbGeauOsr43sE82sTT3E0TQgghRA2SqcniakYiVzOukZCRSGJGEndyU0zuW1J5VZNAXzwUQh9xZc74tiyNOcVnMaf5MyGVYU82wtJCbmoJIYQQ4q58bT43sm9yNSPJ4L+U3FT9Pg5W9vg5+GBjYU1Ofq5RHXWs738CbUWSQF88NOo62TBjRGs2fxfP3qN/cSExjecHNcPN2dbcTRNCCCGEGWRoMknMSCKhSECflHmdPG3BJGmlQomXnQeNXQLwdfDCz8EHHwdvnK0dgZJz9AcEhJvl/RQnk3ErkUzGrb6On7vBip1xKBUKnu3XlBaN3MzdJFHF5FoRomzkWhG1gX6UPj2Rq5mFqTfXDEbpHa0c8HXwNvjPy94DS2Xp4+JHrp0gNn43KbkpuFi7MCAgvMom4kLpk3El0K9EEuhXbzfuZPHp1lNcuZ5Bn/b1GfxEQyyUksrzsJBrRYiykWtF1DQZ6sy/R+cL8umvZiSSlHVDP0pvobDAy97DKKh3Ujk+0HnNda2UFuibNXVHrVazePFiYmJiSEtLIzg4mOnTp9OhQ4dSj4uNjWXz5s3Ex8eTmpqKh4cH7dq148UXX8TX19do/02bNrFixQoSEhLw8fFhzJgxjBw50mi/69ev884773Do0CG0Wi3t27dn5syZ+Pv7V9h7FtWHRx073hrdhq/3/8nOny8TfzWVSQOb4eJgbe6mCSGEEOIe8rX5XM9KNsqlT1Wn6fdxVDng5+BD57qN8HPwwdfBG08793uO0tcWZh3Rf+WVV9i7dy9jxoyhfv36bNmyhVOnTrFmzRpatWpV4nELFiwgOTmZ4OBgnJ2dSUxMZOPGjeTn5xMbG4u7u7t+3/Xr1zN79mzCw8Pp2LEjx44dIyYmhhkzZvDMM8/o98vMzGTIkCFkZmYybtw4LC0tWbVqFQqFgq1bt+Ls7Fzu9ycj+jXH4VPXWL3nLDZWFkwa0IwmDeqau0miksm1IkTZyLUiqoMMdaZ+pZuEjCQSC3PpdflA5Y3Sl0d1HNE3W6B/8uRJIiMjmTlzJuPGjQMgNzeXfv364eHhwdq1a8tV3+nTpxkyZAivv/46EyZMACAnJ4fOnTvTpk0bPv30U/2+r732Gt988w0HDx7E0bHgC7Bs2TLef/99oqOjadq0KQDx8fH079+fSZMmMW3atHK/Rwn0a5aryRl8uvUU125nMahTQ/o+1gClQmHuZolKIteKEGUj14qoSqZH6RNJVd/9DjqpHI0C+uowSl8dA32zfSK7d+/GysqKyMhIfZm1tTUREREsWrSIGzdu4OHhUeb6fHx8AEhLu3u75pdffiElJYURI0YY7Dty5Ei2bdvG999/T9++fQHYs2cPLVu21Af5AAEBAXTo0IFdu3bdV6AvahZfdwf+OTaML3efY8sPF/nzaioT+zXF0e7BH2MthBBCCEPp6gyjtJtrRUbpLRUWeNl7Elw30CCod1SZDmqFMbMF+nFxcTRs2BB7e3uD8ubNm6PT6YiLi7tnoJ+SkkJ+fj6JiYl88sknAAb5/WfOnAEgJCTE4LhmzZqhVCo5c+YMffv2RavVcu7cOYYNG2Z0jtDQUA4dOkR2dja2trIMY21no7JkYv+mNPZ3Yd3+P5iz8ijPDwqhkW/5U7eEEEIIUTBKfy3rhlFQn1ZklN5Z5YiPgzdN6gbi8/cylp527lgoLczY8prPbIF+cnIynp7GTyctzK+/cePGPevo1asXKSkFTx5zcXHhX//6F+3btzc4h0qlwsXF8KEFhWWF50hJSUGtVhvk9hdtj06nIzk5mXr16pX9DYoaS6FQ0LWVL494O/HJlt+Zv/YEkV0b0SPMD4Wk8gghhBAlKhylL1y+MiEjkWuZN8gvNkrfREbpq4TZAv2cnBysrKyMyq2tC1Y8yc01fspYcR9//DFZWVlcvHiR2NhYMjMzy3SOwvMUnqPwp0plnKJR2J6cnJx7tqe4kvKlKpu7e9VNPKnN3N0dWdLIncXrT7D+wJ9cvpHBtGGtsLc1/Z0SNY9cK0KUjVwrori8/DwS069zKSWBK6lXuZySwOWUq6Tk3E2hrmPjTH0XX9r4hdLAxZd6zr74OHlhWYtH6avbtWK2QN/GxgaNRmNUXhh0FwbYpWnbti0AnTt3plu3bvTv3x87OztGjRqlP4darTZ5bG5urv4chT9N7VvYHhsbm3u2pziZjFs7TOzbhHruDmz+Lp6X/vqWKYNDqOdZvS5kUX5yrQhRNnKtiDR1uolcesNRem97T4JcGuPn4I1PSaP0GrhzK8sM76BqyGTcItzd3U2m5yQnJwOUayIugL+/P82aNWPbtm36QN/d3R2NRkNKSopB+o5arSYlJUV/DhcXF1Qqlf7cxdujUChMpvWIh4NCoSC8XT0CfJ34LOY0//nyOCN7NOaJFj6SyiOEEKLWyNPmcT0rmYT0RK5mJnE1PYmrmUmkqzP0+zirnPB19KZp3SB9UC+59NWX2QL94OBg1qxZQ2ZmpsGE3N9++02/vbxycnLIzs7Wv27SpAkAp06dolOnTvryU6dOodVq9duVSiWBgYGcOnXKqM6TJ09Sv359mYgraOznwuzxbVm27Qyrd5/jj79SGdMrCGuV/OUmhBCiZklTp+sD+YT0JBIzi43SKy3xtvekWd1gfB298bUvGKV3UNnfo2ZRnZgt0A8PD2fFihVs2rRJv46+Wq0mOjqa1q1b6yfqJiYmkp2dTUBAgP7Y27dvU7eu4QONTp06xdmzZ+nTp4++rH379ri4uPD1118bBPrr1q3Dzs6OJ554Ql/Wq1cvPvjgA86cOaNfYvPChQv8/PPPTJw4scLfv6iZnOxUTI9swfafLhHz40WuXE/n+UEh+LjJX3xCCCGqnzxtHtcyjVe8SdfcHaV3sXbGx8GLZq7B+Np74evog4etm4zS1wJmfTLutGnTOHDgAGPHjqVevXr6J+OuXr2aNm3aADB69GiOHDnCuXPn9Me1aNGC3r17ExgYiJ2dHefPnycqKgorKys2bNhAw4YN9fuuXbuWt99+m/DwcDp16sSxY8fYunUrr732mkEAn5GRweDBg8nOzmb8+PFYWFiwatUqdDodW7dupU6dOuV+f5KjX7udvnSbz2NPo9ZoGRseRPtmXuZukigHuVaEKBu5VmoGnU5HmjqDqxmJhrn0WTfQ6rTA3VH6wpVu/By88bGXUfqKUh1z9M0a6Ofm5vLhhx+ybds2UlNTCQoK4pVXXuGxxx7T72Mq0J8/fz6HDx8mISGBnJwc3N3dad++PVOmTMHf39/oPBs3bmTFihUkJCTg7e3N6NGjGTNmjNF+165d45133uHQoUNotVratWvHW2+9ZbLOspBAv/a7k57LZzGn+DMhlS6tfBnerRFWljICUhPItSJE2ci1Uv1o/h6lTyy2jGWG5u7qgy7WzgbLV/o5eOMuo/SVSgL9h4wE+g+HvHwtW76/wK5frlDf05HnB4fg4SJzOqo7uVaEKBu5VsynYJTexIo3xUbpfew98XXw0Qf1Pg5eOFjJKH1Vq46Bvtly9IWoLSwtlER2bUQjP2e+2B7H3JVHmdC3Ca0DZaUmIYQQZaPR59Ibpt4UH6X3c/AmxK0Jfn8H9TJKL0ojgb4QFaRVY3dmj3fg062n+Dj6d3o96s/QzgFYWijN3TQhhBDVhE6nI1WdxtWMawZB/fWsZP0ovZXSEm97L0Ldmhqk39hb2Zm59aKmkUBfiArk7mLLm6PasP6bP9lz5C/iE9OYPKAZdZ3K/8A1IYQQNZsmX8O1rBskZCT9nU9f8LPoKH0daxd8Hbxp7tYMXwcvfB18cLd1lVF6USEk0BeigllZKhndM4hAPxdW7TrLnJVHmTSgGc0a1r33wUIIIWqcu6P0hrn0hqP0VvjYe9Hcrenf+fRe+Dp4Yyej9KISSaAvRCVp19STep4OfLrlFB9s+JX+HRswoGNDlEp5mq4QQtRUmnwNSVnXi6TeFPzM1GTp9ykcpW/h1gyfwhVv7NxQKiSVU1QtCfRriSPXThAbv5uU3BRcrF0YEBDOo16tzd2sh563qz2zxoSxZu85Yg9d4vzVVJ7r3wwne5W5myaEEKIUhaP0Cel3l6+8mnmNGyZG6Vu4hRTJpfeSUXpRbcjympWoqpbXPHLtBF+fjUKj1ejLrJRWjAgeKsF+NaHT6fjhZBJr9/2BvY0lkweGEOjvYu5mPZSkUyxE+TwMy2tq8jUkZV43TL3JTDIapfdz9MbX3htfRx987b1klF4YqI7La0qgX4mqKtCfdegd7uSmGJVbKiyo5+RPQaKIAoUCFHdfgaLglb5MUXRbwc+ixxaWFPzRoKbS6zJ5brhbY/FzFNZnelvR9hm31/j8927vPeo3WVdZPqvidSm4nZbDtyeukp6loW2wB80D3IzrL97ee7wXw8+68HXJn5XB51y8fqNtpj/n0s5t6nPW/3ZKq7+U70xZPuvC91La9/LY9V9Zdy5aOsVClENtCvR1Oh0pualGufQ3sm8ajtI7eBU8NdbBGz8HH3zsvbCzkuejiNJVx0BfUndqAVNBPkCeLh9LpSXodOgo6HDo0FHQtdP+/VN392fh/3UGr/4+nrt16IrUVWS7vkRX0jbDYwsVlJk6P8b1GbTX9DlKa2+14AVWwK9q+DXO3I0RGq2GNXEb+ebK96gsrLG2VGFtYY21herv/6yL/Sz4s6qE7bJShhDVgzpfw7XM60VWvClIwcnMuztKX9emDr4O3rT0CNWn3rjbusoovag1JNCvBepYu5gM9utYuzCt1XNmaFH1piva8Sm102LYCSm9U1S0E1VC/UWP1Wk5dOoaOw5fwtlexYgejfF1sy/a/THZMdKV0KkydY7C9hq2pYRtJjtUpZ377mdlsv4H6RyW8DkXe2eld+hKqG/7xb2YotVpcbZ2Jjc/l0x1Frfz75CbryY3P5ec/Fz9SF9ZWCotsVaqCjoClqY6CaY6DwU/VcXL/u50WCktJfAQogQljdJfz0rW/y2gUlrh4+BNS48Q/RNkZZRePAwk0K8FBgSEm8zRHxAQbsZWVV+KIqk3RTJDqtygR90I9fVnacwpPtt4ieHdGtOlla8+hUVUvEOJR0rsFD/fYnyJx+Vp88jNV6P+O/jPLfoz7++fWjW5eSa25+eizldzR5NVrExTrrtMJd1BKPNdB0vj/SyV8k+AqFnU+RqSMq8ZBfVZedn6fVxt6uDj4E0rj1D9ijduMkovHlKSo1+JqipHH2SCYU2Wka1h2bYz/H7hFu2aejKmVxC21hKAVYbqNHFdq9Oi0eYZdx4MOgumOw53Ox3G5XnavDK3QalQ3qPjYNg5UJWY1mR4V0ICqtrFHHnHhaP0CUWWr7yaUbDijX6U3kKFr72XPpj3+XvFG1tLGaUX5lEdc/Ql0K9EVRnoF6pNk6YeJlqdjp2HL7Plhwt41rFjyuAQ/NxNX7TiwdT2TnG+Nh+1Vm14t8GgM6C5R+eheKej4M/luftgpbQq8U7D3XkQ97orYZjOZKW0lLtdZlLZ/66o89X6FW8K8+mNR+nrFlm+suA/N9u60qkU1YoE+g8ZCfRFecVdvsN/Y0+Tk5vH6F5BdAz1NneTai25VspOp9OZvvuQf4+7D3lq1KVsL3pn5V4UKO52Av6+s6BSqkymJN1rTkTRuRAyefreKupa0el03MlNMV7xJuum0Sj93YDeBx8HTxmlFzWCBPoPGQn0xf1Izcjlv7GnOXslhcebezOyRyAqKwlGKppcK+an1WlNpCAZ/1ltcu5DyZ2Mck+eLnFCdBnmRJjodKiUVrXq7sP9XCvqfDWJRrn018guNkp/dwnLgp8ySi9qsuoY6EsisBDVjLODNa8+3ZKtP1xkx+HLXLqWzpRBIXjWlSctitpFqVBiY2mDjaVNhdZbOHna1NyHsnQscvPVZGoyjdKaykqBApWFVcmrKZV216HISk3FJ2BX9eTpsqS56XQ6buekkJiZREJ6wUOmrmYkkpx1q9govTdtPJrfXfHGwQvbCv69CyGMyYh+JZIRffGgTsbfZNm2M+RrdTzTpwlhwR7mblKtIdeKKI/CydPGE6ZNdR5M3X0wXKlJ/fdKTeWZPG2hsDDRCTBxh0FpavK06Y5FSZOnS5q43rN+F5xVTlz9O7BPzEwiOy9Hv4+bTV39U2MLfnrjaltHRunFQ6E6juhLoF+JJNAXFeFWag5LY05xITGN7mF+PNW1EZYW8o/mg5Jruc5WxwAAIABJREFURVQH+dr8MkyMLiV1yWAexN3J1uVaulVpZXQH4a+Mq6V2QqwtVH+PzBek3RSuS1/Rd2eEqEmqY6AvqTtCVHOuzja8MbI1G785z/5jCVxMTGPywBBcneUfVCFqOgulBXZK2wp9cFPh5Ol7rqpktDKTRt9pKC3In9thBnVtZJReiJpAAn0hagBLCyUjegQS6O/Cip1xzFl5hIn9m9E8wNXcTRNCVDMKRcEcAZWFFY73WcesQ++U+HA5N1v5e0eImkK640LUIGHBHswe15Y6jjZ8uOk3og7Gk68t+wojQghRFgMCwrFSWhmUyRPXhah5JNAXoobxrGvHrDFteKKFNzsOX+b99b+SmpFr7mYJIWqRR71aMyJ4KHWsXVBQMJJvjidICyEejEzGrUQyGVdUtkO/J7FmzzlsrS2ZNKAZwfXrmLtJNYZcK0KUjVwrQpRNdZyMKyP6QtRgHUO9mTUmDFtrSxau/x87Dl9CK313IYQQQiCBvhA1np+HA/8cG0bbYA+iDl7go80nycjW3PtAIYQQQtRqEugLUQsUpu6M6hnImUu3mbvyCPGJqeZulhBCCCHMSAJ9IWoJhULBk639mDmqDQqFgne/OsG+Y38h03CEEEKIh5ME+kLUMg29nZg9vi2hj7iybv+fLI05TXZuyQ+/EUIIIUTtJIG+ELWQvY0VU4eGEtk1gBPnkpm76ihXrsuqGUIIIcTDxKxPxlWr1SxevJiYmBjS0tIIDg5m+vTpdOjQodTj9u7dy86dOzl58iS3bt3C29ubrl27MmXKFBwd7z4HMDo6mpkzZ5ZYz8KFCxkwYAAAS5Ys4eOPPzbax83NjUOHDt3nOxTCfBQKBb3b1SfAx5mlMaeYt+Y4o3oE8ngLH3M3TQghhBBVwKyB/htvvMHevXsZM2YM9evXZ8uWLUycOJE1a9bQqlWrEo/75z//iYeHBwMHDsTHx4dz586xZs0afvjhB6KiorC2tgagbdu2LFiwwOj41atXc/bsWZMdirfffhsbGxv966J/FqImCvR3Ye74R/lv7GlW7jrLHwkpjOoZhLWVhbmbJoQQQohKZLZA/+TJk+zYsYOZM2cybtw4AAYNGkS/fv147733WLt2bYnHfvTRR7Rr186gLCQkhBkzZrBjxw6GDBkCgL+/P/7+/gb75eTkMHfuXNq3b4+7u7tR3b1798bJyekB350Q1YuTvYpXh7Uk9tBFth26xKVr6UwZFIK3q725myaEEEKISmK2HP3du3djZWVFZGSkvsza2pqIiAiOHz/OjRs3Sjy2eJAP0L17dwDi4+NLPe8333xDZmYm/fv3N7ldp9ORkZEhK5WIWkepVDDo8UeYPqwFqRlq3l59jCNx183dLCGEEEJUErMF+nFxcTRs2BB7e8MRxebNm6PT6YiLiytXfTdv3gSgTp06pe63bds2bGxs6NGjh8ntXbp0oU2bNrRp04aZM2eSkpJSrnYIUd2FNHRlzvi2+Ls78FnMab7aew5NntbczRJCCCFEBTNb6k5ycjKenp5G5YXpNKWN6JuybNkyLCws6NmzZ4n7pKSk8MMPP9C9e3ccHBwMtjk5OTF69GhatGiBlZUVP//8Mxs2bODMmTNs2rQJlUpVrvYIUZ3VdbLh9RGtiDoYz54jf3EhMY0pg0Jwc7E1d9OEEEIIUUHMFujn/H979x4WZZn/D/w9MwwgAnIaFBAQQUAFhoNmeKTUYg0XdTO3g8cwy/qt2bZfK7fdrd3NSi1by83U8rCaCYKEmVpqaGoqKCAJKIdUBHUAAUEOAzO/P4CRYUAHBJ5heL+ua6927nmeee6pbvn05vPcT3U1pFKpznjTjbQ1NTV6f1ZCQgJiYmKwaNEiuLm5tXncgQMHoFQqW23bmTt3rtbr8PBwDBkyBO+++y727NmDp556Su/5NLG3t7z/QV1AJrO6/0FEAF6ZFYyQYU74ZOdZvLMlCa89HYyHhg8QelrdhmuFSD9cK0T6MbS1Ilihb25uDqVSqTPeVOA3Ffz3k5SUhOXLlyMsLAxLliy557EJCQmwsbHB+PHj9frsp59+GitXrsTJkyc7VOgXF1dApereXn+ZzAoKBfdLJ/15DbDE2/NGYl3cefzzy1P43Sg3zJgwGBKxcT9mg2uFSD9cK0T6EWqtiMWiNsNlwX6Sy2SyVttzFAoFAMDR0fG+n5GZmYmXXnoJPj4++PjjjyGRtL1dYEFBAZKSkvD444+3+puE1ojFYvTv3x9lZWV6HU/UUzna9MHy2SEIC3TG96euYOWOc7h1W//fqhEREZHhEazQ9/X1RV5eHiorK7XGU1NTNe/fy5UrVxAVFQU7OzusX78eFhYW9zx+7969UKvVmgdk6UOpVKKwsPC+N/gSGQOpiQRzwn2xcOowXL5RgXe+Oo0Lv5UIPS0iIiLqIMEK/fDwcCiVSkRHR2vGamtrERsbi+DgYM2NugUFBTpbZioUCixYsAAikQibNm2CnZ3dfa+3d+9eODs7IyQkpNX3S0p0C5pNmzahpqYG48aNa89XI+rRQocPwNtzR8DSwhSrd6bg2+N5UHG7WSIioh5HsB59uVyO8PBwrFq1CgqFAm5uboiLi0NBQQFWrFihOW7ZsmU4ffo0srKyNGNRUVG4evUqoqKikJycjOTkZM17bm5uOk/VvXjxIrKysvDCCy9AJBK1Op9HHnkEU6ZMgbe3N0xNTXHq1CkcOHAAISEhiIiI6ORvT2TYnB364u05I7D1QCb2HMvDpfwyLJw6DNYW3H2KiIiopxCs0AeADz/8EGvWrEF8fDzKysrg4+ODL774os3UvUlmZiYAYOPGjTrvTZ8+XafQT0hIAIB7FuxTp07F2bNnsX//fiiVSri4uGDx4sVYtGgRTEwE/dtEJAgzUwmiIoZhiKsNdvxwCe98dQYvRfrBa2A/oadGREREehCp+QjYLsNdd8hYXL5+G//dk47i8mo8GeaJx0a6tvnbsZ6Ca4VIP1wrRPrhrjtE1CO5D7DC3+aNhNzLAd8czsZncem4U627PS4REREZDhb6RKQXC3MTvDzdD3981Aup2UV4Z/MZXL7OlI+IiMhQsdAnIr2JRCI89pAblj0TjLp6Nf69LRk/nbsGdgASEREZHhb6RNRuXgP74R/zR8LXzQZbD2Rhw94LqK6tE3paRERE1AwLfSLqECsLU7z6lBzTx3ng1IUb+OeWJFwrqrz/iURERNQtWOgTUYeJRSJMHeOB12cForJKiX9uOYOT6deFnhYRERGBhT4RdYKhg+zw9/kPYdAAa2zYewFb9mdCWVcv9LSIiIh6NRb6RNQpbK3M8JenA/G7h92QmFKAf29Lxs1bd4SeFhERUa/FQp+IOo1ELMbMMC/86ckAFJdV453NSUjOUgg9LSIiol6JhT4RdbpALwf8fd5IDLDrg8/izmPnoUuoq1cJPS0iIqJehYU+EXUJB5s+eOPZEEwMHoiDZ67igx1nUVJeLfS0iIiIeg0W+kTUZaQmYjz7mDdejByOfEUl/vHVGaTnFgs9LSIiol6BhT4RdbmHhvbH3+aOgI2lKT7elYq4o7lQqfg0XSIioq7EQp+IuoWTfV8snzMCY/ydkHDiN6z+JgVllbVCT4uIiMhosdAnom5jJpVgwRNDMf93vsi+VoZ/fHUaF6+WCj0tIiIio8RCn4i63Ti5M/46ZwTMpRJ8uOMcvv/lMlRqtvIQERF1pk4p9Ovq6nDgwAHs2rULCgX3zCai+3N1tMTf5o1EsI8M0T/lYG1MGiqqlEJPi4iIyGiYtPeEDz/8EKdOncLu3bsBAGq1GvPnz0dSUhLUajVsbGywa9cuuLm5dfpkici49DEzwUuRw3HY1QY7D13CO1+dweLpfvBwshZ6akRERD1euxP9Y8eOYcSIEZrXhw8fxpkzZ/D8889j9erVAIAvvvii82ZIREZNJBJhYshAvPlcCAA1VvwvGYeS86FmKw8REdEDaXeif/36dbi7u2teHzlyBAMHDsTrr78OALh06RISEhI6b4ZE1CsMdrbG3+c/hI17L2D7DxdxKb8Uc8N90ces3X9MERERETqQ6CuVSpiY3P3Be+rUKYwePVrz2tXVlX36RNQhln2k+NOTAfjDhME4k3kT725JQv7NCqGnRURE1CO1u9AfMGAAzp07B6Ahvb969SpGjhypeb+4uBgWFhadN0Mi6lXEIhGeCB2E/3s6CNU1dfjX1iT8nFYo9LSIiIh6nHb/TvyJJ57AunXrUFJSgkuXLsHS0hITJkzQvJ+RkcEbcYnogfm42eIf80di/be/4st9GbiYX4rnJnvDVCoRempEREQ9QrsT/UWLFmH69OlISUmBSCTCBx98AGvrhh0ybt++jcOHDyM0NLTTJ0pEvU8/SzO8/scgRIwehJ/TCvGvrcm4XnJH6GkRERH1CCJ1J25toVKpUFlZCXNzc0il0s762B6ruLgCKlX37hwik1lBobjdrdck6g7nc4uxIeEC6upVmD9lKEb6Oj7Q53GtEOmHa4VIP0KtFbFYBHt7y9bf68wL1dXVwcrKikU+EXU6/8H2+Mf8kXBx6Iv/7knH9h8uoq5eJfS0iIiIDFa7C/3ExESsXbtWa2z79u0IDg5GYGAg/vznP0Op5NMtiajz2VmbY9mzwZg8whWHkvOx4n9nUVRWJfS0iIiIDFK7C/1NmzYhNzdX8zonJwfvvfceHB0dMXr0aOzbtw/bt2/v1EkSETUxkYjx9KQhWDzND9dLKvHOV2eQml0k9LSIiIgMTrsL/dzcXPj5+Wle79u3D2ZmZoiJicHGjRsxZcoU7Nmzp1MnSUTU0ghfR/xt3kjYW5vjk5g07E7MQb2KrTxERERN2l3ol5WVwdbWVvP6xIkTePjhh2Fp2XATwEMPPYT8/Hy9Pqu2thYrV67E2LFjERAQgKeeegonT56873kHDx7Eq6++ikcffRRyuRzh4eH44IMPcPu27g0QPj4+rf7v66+/1jn2xo0bWLJkCUaMGIHg4GAsXrwYV69e1eu7EFH3629rgbdmh2C83BnfnbyMVV+noLSiRuhpERERGYR276Nva2uLgoICAEBFRQXOnz+P1157TfN+XV0d6uvr9fqsN954AwcPHsScOXPg7u6OuLg4LFy4ENu2bUNQUFCb57399ttwdHREZGQknJ2dkZWVhW3btuHYsWPYvXs3zMzMtI4fO3Ysfv/732uNyeVyrdeVlZWYM2cOKisr8eKLL8LExASbN2/GnDlzsGfPHvTr10+v70RE3ctUKsG83/nC27Ufth7Iwj++OoNFvx+Ooe629z+ZiIjIiLW70A8MDMTOnTvh5eWFo0ePor6+HuPHj9e8f/nyZTg63n/bu7S0NHz33Xd48803MW/ePADAtGnTEBERgVWrVt2zz/8///kPRo0apTXm5+eHZcuW4bvvvsOMGTO03hs8eDAiIyPvOZ8dO3bg8uXLiI2NxbBhwwAA48aNw9SpU7F582YsWbLkvt+JiIQz2s8J7v2tsG5POlbtPIdp4wbjiVB3iEUioadGREQkiHa37vzpT3+CSqXCq6++itjYWEybNg1eXl4AALVajR9//BHBwcH3/Zz9+/dDKpVi5syZmjEzMzM8+eSTSE5Oxs2bN9s8t2WRDwCTJk0C0HBzcGuqq6tRU9P2r/QPHDiAwMBATZEPAJ6enggNDcX3339/3+9DRMJzkVni7bkjMGpof8QdzcUn0WmoqOIuYERE1Du1O9H38vLCvn37cPbsWVhZWWHkyJGa98rLyzF37txWC/GWMjIy4OHhgb59+2qNBwQEQK1WIyMjQ6/fDDQpKmrYdaP5/QNNYmJisG3bNqjVanh7e+NPf/oTJk+erHlfpVIhKysLs2bN0jnX398fx48fR1VVFfr06aP3fIhIGOamJlg4dRiGuNrg6x8v4h9fncZLkX7wdGH7HRER9S7tLvQBwMbGBo8++qjOeL9+/TB37ly9PkOhUKB///464zKZDADumei3ZsOGDZBIJHjssce0xoOCgjBlyhQMHDgQhYWF2Lp1K1555RWsXr0aERERAIDS0lLU1tZqrt1yPmq1GgqFAm5ubu2aExEJQyQS4ZEgF3g4WWFdXDre334WTz3ihUkjBkLEVh4iIuolOlToA8CVK1dw6NAhza40rq6umDhxot7FcHV1datP0G26kfZebTYtJSQkICYmBosWLdK5/s6dO7VeT58+HREREVi5ciWeeOIJiEQizbVMTU3bnE91dbXe82nS1uOIu5pMZiXIdYkMjUxmhbWeMqzZeQ5fH7qEy4oKBHs74ptDF1F0qwoOtn0w53dDERbiKvRUiQwaf64Q6cfQ1kqHCv01a9Zgw4YNOrvrrFy5EosWLdLrxlVzc/NWn6DbVHS33DmnLUlJSVi+fDnCwsL0uq6FhQX++Mc/YvXq1cjNzYWnp6fmWrW1tW3Ox9zcXK/5NFdcXAGVSt3u8x6ETGYFhUJ3m1Gi3uyFiKFwd7TEriPZOJFWqBlX3KrC2l0pKL9djdDhAwScIZHh4s8VIv0ItVbEYlGb4XK7C/2YmBh8/vnnCAoKQlRUFIYMGQIAuHTpEjZt2oTPP/8crq6uOjvftCSTyVptz1EoFACgV39+ZmYmXnrpJfj4+ODjjz+GRCLR6zs4OTkBaHgmANDQimRqaqq5dsv5iESiVtt6iKhnEIlECB/lhv2nL6O8UjtgqK1TITYxh4U+EREZnXbvurNjxw7I5XJs27ZN06rj5uaGiRMnYuvWrQgICMD//ve/+36Or68v8vLyUFlZqTWempqqef9erly5gqioKNjZ2WH9+vWwsLDQ+zs0tRvZ2dkBAMRiMby9vZGenq5zbFpaGtzd3XkjLpERaFnkNyku50O2iIjI+LS70M/JycGUKVNgYqL7ywATExNMmTKlzS0umwsPD4dSqUR0dLRmrLa2FrGxsQgODtbcqFtQUKDzeQqFAgsWLIBIJMKmTZs0BXtLJSUlOmO3bt3Cjh07MHDgQAwaNEgz/vjjjyMlJQUXLlzQjOXm5uKXX35BeHj4fb8PERk+e+u2WwJX7TyHpMybqKtXdeOMiIiIuk67W3ekUinu3LnT5vuVlZWt3mTbklwuR3h4OFatWqXZ0SYuLg4FBQVYsWKF5rhly5bh9OnTyMrK0oxFRUXh6tWriIqKQnJyMpKTkzXvubm5aZ6qu337dhw6dAhhYWFwdnbGjRs38M0336CkpASfffaZ1nyeeeYZREdH44UXXsD8+fMhkUiwefNmyGQyzQO9iKhnmzHBE1u+z0Rt3d1iXmoihtzTDnmFt7FuTzqsLaQYG+CM8XInONrq/5tCIiIiQ9PuQt/f3x/ffPMNZs6cCQcHB633iouLsWvXLsjlcr0+68MPP8SaNWsQHx+PsrIy+Pj44IsvvkBISMg9z8vMzAQAbNy4Uee96dOnawr9oKAgnD17FtHR0SgrK4OFhQUCAwOxaNEinWtYWlpi27ZteO+997Bu3TqoVCqMGjUKy5cvb3VvfiLqeZr68GMTc1BSXgM7azPMmOCJ0OEDoFKpkZ5XgsSUa9h/6gr2/XIZwwfZYkKgCwKHOMBE0u5fgBIREQlKpFar27UtzJkzZzBv3jz07dsXf/jDHzRPxc3OzkZsbCwqKyuxefNmjBgxoksm3JNw1x0iw3WvtXLrdg2OpRXgWGoBistrYN3XFGP9nTA+0BmONrxfh3oX/lwh0o8h7rrT7kIfAA4fPox//vOfKCws1Bp3dnbG3/72N4SFhXVoosaGhT6R4dJnrTSk/MVITClAanYxVGo1U37qdfhzhUg/RlPoA4BKpUJ6ejry8/MBNDwwa/jw4di1axe2bt2Kffv2dXzGRoKFPpHhau9aaUr5j6YWoKQx5R8X4IRxcqb8ZNz4c4VIP4ZY6Hf4ybhisRgBAQEICAjQGr916xby8vI6+rFERAbJ1soMvx/jgYjQQUjPK8ZP5wqw75fL+O7kZQz3sMMEuTNTfiIiMigdLvSJiHojsViEAE8HBHg6oKS8Gj+nFeJoWkHDjj2NKf94uTNkTPmJiEhgLPSJiDrIztocvx/rgYjRg3A+t6GXf98vl7Hv5GUM87BDWKAz5F5M+YmISBgs9ImIHpBYLILcywFyL+2U/7O4dPTra4qxTPmJiEgALPSJiDrRvVL+4R52mMCUn4iIuolehf5XX32l9weePXu2w5MhIjIWLVP+Y2mFOJqqnfJPkDvDgSk/ERF1Eb221/T19W3fh4pEyMjI6PCkjAW31yQyXEKsFZVKjbTcYhxNKUBqThGgRmPK7wK5lz1TfjJI/LlCpJ8eu73m1q1bO3VCRES9kVgsQqCXAwJ1Uv7z6GfZuGNPAFN+IiLqHB1+YBbdHxN9IsNlKGulXqXC+dwSJJ67hrTc4oaUf7AdJsiZ8pNhMJS1QmToemyiT0REXUMiFmul/EdTC3AsrZApPxERPTAm+l2IiT6R4TLktVKvUuF8TgkSU7RT/rDGXn6JmCk/dR9DXitEhoSJPhER3ZdELEbgEAcEDnFAcVk1jqU1pPyfxjal/M4YL3eCQz+m/ERE1DYm+l2IiT6R4eppa6VepUJaTsO+/OdzigEAfoPtG/flZ8pPXaenrRUioTDRJyKiDpGIxQgaIkPQEJlOym9jaYqxTPmJiKgFJvpdiIk+keEyhrXSWsrv72mPCXJnBDDlp05iDGuFqDsw0Sciok7TMuVv2LGnAGsbU/5xAc4Yx5SfiKjXYqLfhZjoExkuY10r9SoV0rKLkZjKlJ86h7GuFaLOxkSfiIi6lEQsRpC3DEHeMhSVVeFYaqEm5be1MsO4ACeMC3CGfT9zoadKRERdjIl+F2KiT2S4etNaaUr5f0opQHpus5Q/0BkBnkz56d5601ohehBM9ImIqNu1TPmPNqX8u5nyExEZMyb6XYiJPpHh6u1rpV6lQmp2w4496bnFgAjwH8yUn3T19rVCpC8m+kREZBAkYjGCvWUI9pahqLQKR9N0U/7xcmfYWTPlJyLqqZjodyEm+kSGi2tFV119w778P6Vcw6+5JYAICBhsjwmBLvD3tGPK30txrRDph4k+EREZLBNJy5S/AMdSC5G6O40pPxFRD8REvwsx0ScyXFwr+qmrb+zlT22R8ge5IGCwPcRikdBTpC7GtUKkHyb6RETUo5hIxAjxkSHERwZFaRWONaX8MQ0p/3i5M8YFODHlJyIyQEz0uxATfSLDxbXScZqUP+Uafs1jym/suFaI9MNEv4Xa2lp88skniI+PR3l5OXx9fbF06VKEhobe87yDBw9i3759SEtLQ3FxMZycnPDII49g8eLFsLKy0hxXWFiImJgYJCYm4vLlyxCLxfD29sbixYt1rrF27Vp8+umnOtdycHDA8ePHO+cLExEZgZYp/9HUAvycxpSfiMjQCFrov/HGGzh48CDmzJkDd3d3xMXFYeHChdi2bRuCgoLaPO/tt9+Go6MjIiMj4ezsjKysLGzbtg3Hjh3D7t27YWZmBgA4dOgQNm7ciEmTJmH69Omoq6tDfHw85s2bhw8++ADTpk3T+ex3330X5uZ3fzg1//9ERKRNZtMHf5jgicixHkjNLkJiSgG+/TkP3x7Pg9zTARMCneHPlJ+ISBCCte6kpaVh5syZePPNNzFv3jwAQE1NDSIiIuDo6Ijt27e3ee6pU6cwatQorbE9e/Zg2bJlWLFiBWbMmAEAuHTpEuzt7WFnZ6c5rra2FpGRkaipqcHhw4c1402J/pkzZ2Btbd0p35GtO0SGi2ul6zRP+csqa2FnbYZxAUz5eyquFSL9GGLrjmCbIu/fvx9SqRQzZ87UjJmZmeHJJ59EcnIybt682ea5LYt8AJg0aRIAICcnRzM2ZMgQrSIfAExNTTFhwgRcu3YN1dXVOp+jVqtRUVEB3rpARNQxTSn/ysWj8fJ0PzjZ90X8z3n4y39P4D8xaUjNLur2EISIqDcSrHUnIyMDHh4e6Nu3r9Z4QEAA1Go1MjIy4OjoqPfnFRUVAQBsbW3ve6xCoYCFhYWmxae5sLAw3LlzB3379sXjjz+OZcuWwcbGRu95EBFRg4ZefkeE+DjiZmkVjqUW4FhaIVKyi2BnbYbxAc4YJ3eGrZXun8VERPTgBCv0FQoF+vfvrzMuk8kA4J6Jfms2bNgAiUSCxx577J7HXb58GT/88AOeeOIJiER3e0atra0xe/ZsyOVySKVS/PLLL/jmm29w4cIFREdHw9TUtF3zISKiuxyb9fKnXCpCYmoB9vych/jGXv6wIGf4ebCXn4ioMwlW6FdXV0MqleqMN6XsNTU1en9WQkICYmJisGjRIri5ubV5XFVVFZYsWYI+ffpg6dKlWu/NnTtX63V4eDiGDBmCd999F3v27MFTTz2l93yatNUv1dVkMqv7H0REXCsCcRrQD78b54nrxZU4eOoyfjh9BWui0yCz7YPHRrlj8kNusO/XR+hpUjNcK0T6MbS1Ilihb25uDqVSqTPeVOC31lbTmqSkJCxfvhxhYWFYsmRJm8fV19dj6dKlyMnJwaZNm/RqC3r66aexcuVKnDx5skOFPm/GJTJcXCvCkwD43UhXTA52aUj5U65h+/5M7DiQyZTfgHCtEOnHEG/GFazQl8lkrbbnKBQKANCrEM/MzMRLL70EHx8ffPzxx5BIJG0e+9e//hWJiYlYvXo1HnroIb3mKBaL0b9/f5SVlel1PBERtZ+JRIwRvo4Y4euIm7fu4GhqIX5OK0BKdhHsrc0wTu6McQHs5Sciai/Bdt3x9fVFXl4eKisrtcZTU1M179/LlStXEBUVBTs7O6xfvx4WFhZtHvvBBx8gNjYWb731FqZMmaL3HJVKJQoLC/W6wZeIiB6co60FngzzxKqXx2DxND8MsLPAnmN5+Mu6E1i7Ow1pOcXcsYeISE+CFfrh4eFQKpWIjo7WjNXW1iI2NhbBwcGaG3ULCgq0tswEGlL/BQsWQCTARYTcAAAgAElEQVQSYdOmTTpbaDa3ceNGfPnll3jxxRcxe/bsNo8rKSnRGdu0aRNqamowbty49n49IiJ6AE0p/5//GIT3Fz2Mx0e5IudaGdZEp2LZ5yfw7fE83Lqt/71cRES9kWAPzAKAJUuW4NChQ5g7dy7c3NwQFxeH9PR0bNmyBSEhIQCA2bNn4/Tp08jKytKcFxkZiczMTERFRcHb21vrM93c3DRP1f3hhx/wyiuvYNCgQVi8eLHO9SdPnqz5TYBcLseUKVPg7e0NU1NTnDp1CgcOHEBISAi2bt0KE5P2dzmxR5/IcHGt9Dx19Sqca+zlv/DbLYhFIsi97DEh0AV+Hnbs5e8iXCtE+mGPfgsffvgh1qxZg/j4eJSVlcHHxwdffPGFpshvS2ZmJoCGtL6l6dOnawr9puN+++03/N///Z/OsYcOHdIU+lOnTsXZs2exf/9+KJVKuLi4YPHixVi0aFGHinwiIupcJhIxRvo6YmRjL39iagGOpxXi3KUi2FubY7zcCWPZy09EpCFoom/smOgTGS6uFePQlPL/dO4aMi7fTfnDglwwfBBT/s7AtUKkHyb6REREnah5yn/j1h0cTSnAz+ebpfyBzhjr78SUn4h6JSb6XYiJPpHh4loxXnX1Kpy9qEBiSoEm5Q8c4oAJgc4Y7mEHsYgpf3twrRDph4k+ERFRFzORiPHQ0P54aGh/3Ci5g6OpDSn/2YsKTco/LsAJNpZM+YnIuDHR70JM9IkMF9dK76KsU+HcJd2UPyzQGcOY8t8T1wqRfpjoExERCUBqop3yJ6YW4Oe0hpTfoZ9549N3mfITkXFhot+FmOgTGS6uFWqZ8kvEIgR6NfTyM+W/i2uFSD9M9ImIiAxE85T/elMvf1ohkhtT/vGNKX8/pvxE1EMx0e9CTPSJDBfXCrWmKeX/6dw1ZF4pvZvyBzlj2KDemfJzrRDph4k+ERGRAdNJ+Rv35W9K+Sc07svPlJ+IegIm+l2IiT6R4eJaIX0p65r25W+W8jfuy98bUn6uFSL9MNEnIiLqYaQmYowa1h+jhrVI+bOY8hORYWOi34WY6BMZLq4VehBtpfxhgS4YOsjWqFJ+rhUi/TDRJyIiMgLNU/7C4kocTS3A8fPXkZylgMymYccepvxEJDQm+l2IiT6R4eJaoc6mrKtH8kUFjqYUaFL+oCEOmNDDU36uFSL9MNEnIiIyUlITCR4eNgAPDxuglfInNU/5A5zRr6+p0FMlol6CiX4XYqJPZLi4Vqg7KOvqkZzV8PTdrKvNUv4gFwx17xkpP9cKkX6Y6BMREfUiUhMJHh4+AA8Pb0j5E1MKcPx8IZKyFHC06YPxgc4Y4+/ElJ+IugQT/S7ERJ/IcHGtkFBaTfm9ZZgQ6GyQKT/XCpF+mOgTERH1cm2m/Jk3NSn/WH8nWDPlJ6IHxES/CzHRJzJcXCtkSJR19UhqTPkvNkv5wwKd4Stwys+1QqQfJvpERESkQ2oiQejwAQhtLeW37YMJ8oZefqb8RNQeTPS7EBN9IsPFtUKGTpPyn7uGi/llkIhFCG7s5e/OlJ9rhUg/TPSJiIhIL81T/oKihpT/RHohzjDlJyI9MdHvQkz0iQwX1wr1RMq6eiRlKpCYop3yhwU6w6eLUn6uFSL9MNEnIiKiDpOaSBDqNwChfgNwragSR1um/IHOGOPHlJ+IGjDR70JM9IkMF9cKGYtaZcO+/D+lXMOlxpQ/xEeGCfKGXn7RA6b8XCtE+mGiT0RERJ3KVKqd8iemXMPJ9Os4nXET/W3vPn3X2oIpP1Fvw0S/CzHRJzJcXCtkzGqV9UjKuonElALtlD/QBb5uNu1K+blWiPTDRL+F2tpafPLJJ4iPj0d5eTl8fX2xdOlShIaG3vO8gwcPYt++fUhLS0NxcTGcnJzwyCOPYPHixbCystI5Pjo6Gl9++SXy8/Ph7OyMOXPm4Nlnn9U57saNG3jvvfdw/PhxqFQqPPzww3jzzTfh6uraad+ZiIioq5lKJRjt54TRfk64pqhAYmoBTpy/m/JPCHTBaP8BTPmJjJygif5rr72GgwcPYs6cOXB3d0dcXBzS09Oxbds2BAUFtXneqFGj4OjoiEmTJsHZ2RlZWVnYuXMnBg0ahN27d8PMzExz7M6dO/H3v/8d4eHhGDNmDJKSkhAfH49ly5ZhwYIFmuMqKysxY8YMVFZWYt68eTAxMcHmzZshEomwZ88e9OvXr93fj4k+keHiWqHepinl/ymlANn5ZTCRNO3Lf++Un2uFSD+GmOgLVuinpaVh5syZePPNNzFv3jwAQE1NDSIiIuDo6Ijt27e3ee6pU6cwatQorbE9e/Zg2bJlWLFiBWbMmAEAqK6uxoQJExASEoJ169Zpjn399ddx+PBhJCYman4DsGHDBqxevRqxsbEYNmwYACAnJwdTp07FokWLsGTJknZ/Rxb6RIaLa4V6s2uKisZ9+a/jTk2dJuUf4z8AVi1Sfq4VIv0YYqEv7ua5aOzfvx9SqRQzZ87UjJmZmeHJJ59EcnIybt682ea5LYt8AJg0aRKAhuK8yalTp1BaWopnnnlG69hnn30WlZWVOHr0qGbswIEDCAwM1BT5AODp6YnQ0FB8//337f+CREREBspFZolnJnvjo1fG4PknhsKqryl2HcnGnz87js/j05F5+RZOpBfiL+uO4/d/jsdf1h3HyV+vCz1tImonwXr0MzIy4OHhgb59+2qNBwQEQK1WIyMjA46Ojnp/XlFREQDA1tZWM3bhwgUAgJ+fn9axw4cPh1gsxoULF/DEE09ApVIhKysLs2bN0vlcf39/HD9+HFVVVejTp4/e8yEiIjJ0plIJxvg7YYy/E/IVFY378jf08jdXXF6DLd9nAgBChw8QYqpE1AGCJfoKhaLVQl4mkwHAPRP91mzYsAESiQSPPfaY1jVMTU1hY2OjdWzTWNM1SktLUVtbq7l2y/mo1WooFIp2zYeIiKgnGdiY8q9+ZQz69tHNAWvrVIg+kg1u1kfUcwiW6FdXV0MqleqMN91IW1NTo/dnJSQkICYmBosWLYKbm9t9r9F0naZrNP3V1FR394Gm+VRXV+s9nyZt9Ut1NZlMd+chItLFtULUujtVda2Ol1bU4q+bTuOhYQMwclh/DB9sDxOJYJkhkcExtJ8rghX65ubmUCqVOuNNRXfznXPuJSkpCcuXL0dYWJjODbPm5uaora1t9byamhrNNZr+2tqxTfMxNzfXaz7N8WZcIsPFtULUNjtrMxSX6wZuFuYmsLc2w3fHcxF/NAd9zEzgP9gOci8H+A+2h2Wf1sM1ot7AEG/GFazQl8lkrbbnNLXI6NOfn5mZiZdeegk+Pj74+OOPIZFIdK6hVCpRWlqq1b5TW1uL0tJSzTVsbGxgamraanuOQqGASCRqta2HiIjIGM2Y4Ikt32eitk6lGTM1EePZyd4IHT4A1bV1+DXvFlKzi5CWU4TTGTchEgFDXPpBPsQBgV4OGGBn0a4HcxFR5xOs0Pf19cW2bdtQWVmpdUNuamqq5v17uXLlCqKiomBnZ4f169fDwsJC55ihQ4cCANLT0zF27FjNeHp6OlQqleZ9sVgMb29vpKen63xGWloa3N3deSMuERH1Gk033MYm5qCkvAZ21maYMcFTM25uaoIQHxlCfGRQqdXIKyxHanYRUi4VI/pIDqKP5MDRpg/kXg4I9LLHEFcbtvgQCUCwQj88PBxffvkloqOjNfvo19bWIjY2FsHBwejfvz8AoKCgAFVVVfD09NScq1AosGDBAohEImzatAl2dnatXuPhhx+GjY0NduzYoVXof/3117CwsMD48eM1Y48//jg++ugjXLhwQbPFZm5uLn755RcsXLiws78+ERGRQQsdPgChwwfctx1BLBLB07kfPJ37YcZ4TxSXVSM1pwgp2UU4ci4fPyRdRR8zCfw87BHo5QB/T7b4EHUXQZ+Mu2TJEhw6dAhz586Fm5ub5sm4W7ZsQUhICABg9uzZOH36NLKysjTnRUZGIjMzE1FRUfD29tb6TDc3N62n6m7fvh3vvvsuwsPDMXbsWCQlJWHPnj14/fXXtQr4iooKTJ8+HVVVVZg/fz4kEgk2b94MtVqNPXv2aG3bqS/26BMZLq4VIv08yFqprq3Dhd9uISW7CGk5xSivrNVq8ZF7OsDJni0+ZBwMsUdf0EK/pqYGa9asQUJCAsrKyuDj44PXXnsNo0eP1hzTWqHv4+PT5mdOnz4d77//vtbYrl278OWXXyI/Px9OTk6YPXs25syZo3Pu9evX8d577+H48eNQqVQYNWoUli9fDldX1w59Pxb6RIaLa4VIP521VlRqNX4rvI2U7CKkZhfh6s0KANC0+Mi97OHNFh/qwVjo9zIs9IkMF9cKkX66aq0Ul1UjLacIKdnFyLh8C3X1Krb4UI9miIW+YD36RERE1HvZ9zPHI8ED8UjwQE2LT2p2EVJzinEms2EXHy+Xfgj0coDciy0+RB3BQp+IiIgEZW5qgmBvGYK9ZVotPmnZRYj+KQfRP+VAZmPeuIuPA1t8iPTEQp+IiIgMhlgkwmBnawx2tsaM8YNRUl7dsHVndjF+OleAH5Py0cdMguEe9gj0skeApwNbfIjawEKfiIiIDJad9d0Wn5raelz4raThht6cYiQ1a/GRN7b4OLPFh0iDhT4RERH1CGamEgR5yxDU2OJz+fptpFxq2MUn5qccxDRr8ZF7OcCHLT7Uy7HQJyIioh5HLBLBw8kaHk7WmN7U4pNTjNTsIrb4EDVioU9EREQ9np21OR4JcsEjQS4NLT6XSxp28cm+2+Lj2WwXH7b4UG/AQp+IiIiMipmpBEFDZAgacrfFp+GG3hYtPp4OkA9hiw8ZLxb6REREZLSat/hMG6fd4pOYWoAfk/NhbiqBn4cd5F4OCPC0h5WFqdDTJuoULPSJiIio17hni0+WQtPiI/dseEKvs0NftvhQj8VCn4iIiHqle7X47E7Mxe7EXDj0M9f09fu4scWHehYW+kRERNTrtWzxuXW7RlP0s8WHeioW+kREREQt2FqZISzIBWFBLqhR1iPjt1uND+oqamjxQWOLjxdbfMhwsdAnIiIiugczqQSBQxwQOMRBq8UnNbtYq8VH7uWAQLb4kAFhoU9ERESkp7ZafFKzi3A0tQCHWrT4+Hvaw5otPiQQFvpEREREHdSeFh+5lwNc2OJD3YiFPhEREVEnaNnic+XGbaRcar3FR+5lDx9XW0hN2OJDXYeFPhEREVEnE4tEGDTAGoMGNGvxySlC6qW7LT5mjS0+gWzxoS7CQp+IiIioi9lamSEs0AVhgY0tPpdvaXr7kxtbfAa7WGv27GeLD3UGFvpERERE3chMKkFg4w49arUal2/cRmp2sc6DuuSeDpAPYYsPdRwLfSIiIiKBiJq1+ESO9cCt2zVIy2no6z+WVoBDZ++2+Mg9HRDgxRYf0h8LfSIiIiIDYWtlhgmBLpjQrMUnrfEJvTotPp4OcJGxxYfaJlKr1WqhJ2GsiosroFJ1799emcwKCsXtbr0mUU/EtUKkH64Vw6BWq3HlRkXD1p3ZRfjtesM/E7b4GA6h1opYLIK9vWWr7zHRJyIiIjJwIpEI7gOs4D7A6t4tPoMaHtQV4GkP675s8entWOgTERER9TDNW3xqm+/ik1OM5IuNLT7O1pA33vTLFp/eiYU+ERERUQ9mKpU0PoTLQdPik9rY1x97NBexR3Nhb20OuZc9Ar0c4OPGFp/egoU+ERERkZFo3uLz+8YWn/O5xUi5VISf0wpx+Ow1mEklGO5hB7mXPeSeDmzxMWIs9ImIiIiMlK2VGcbLnTFe7ny3xSenGKnZRTjbosVH7uWAgWzxMSrcdacLcdcdIsPFtUKkH64V46Rp8clp2MUnr7DhnzFbfDqOu+60UFtbi08++QTx8fEoLy+Hr68vli5ditDQ0Huel5aWhtjYWKSlpeHixYtQKpXIysrSOW7t2rX49NNP2/ycHTt2ICQkBADwxhtvIC4uTucYuVyOXbt2tfObERERERkurRafMR4orahBWmPS//N5tvgYC0EL/TfeeAMHDx7EnDlz4O7ujri4OCxcuBDbtm1DUFBQm+clJiYiOjoaPj4+cHV1RW5ubqvHTZ48GW5ubjrjH3/8Me7cuQN/f3+t8T59+uCdd97RGrOzs+vANyMiIiLqOWwstVt8Mq/cQkq2douPR7NdfNji0zMIVuinpaXhu+++w5tvvol58+YBAKZNm4aIiAisWrUK27dvb/Pcp59+GgsXLoS5uTn+/e9/t1no+/r6wtfXV2ussLAQ169fx8yZM2Fqqv1fpiYmJoiMjHywL0ZERETUg5lKJQjwdECApwPUj3nj6s27D+qKO5qLuKO5sLc2Q0Bj0e/rZgOpiUToaVMrBCv09+/fD6lUipkzZ2rGzMzM8OSTT+Ljjz/GzZs34ejo2Oq5Dg4OHb7u3r17oVarMXXq1Fbfr6+vR1VVFSwtW+91IiIiIuotRCIR3Ppbwa1/Q4tPWUWN5mbe4+cLcaR5i4+nPQK8HNCPLT4GQ7BCPyMjAx4eHujbt6/WeEBAANRqNTIyMtos9B9EQkICnJycMHLkSJ33KisrERISgqqqKtjY2GDatGl47bXXYGZm1unzICIiIupp+jVr8VHW1SPjcqlmz/6WLT5yT3u4OlqyxUdAghX6CoUC/fv31xmXyWQAgJs3b3b6NS9duoSsrCxERUXp/Esnk8kQFRWFoUOHQqVS4ciRI9i8eTNycnKwcePGTp8LERERUU8mNZEgwNMeAZ72eK6xxaeh6C9mi4+BEKzQr66uhlQq1RlvSs9ramo6/ZoJCQkA0Grbzp///Get1xEREejfvz82bdqE48ePY8yYMe2+XltbHXU1mcxKkOsS9TRcK0T64VohfTg6WiPEzxkAcKu8GkkZN3D6wnWcSL+OI2evwdxUgkBvGR4aNgAjhvWHrZW5wDPufIa2VgQr9M3NzaFUKnXGmwr8zm6XUavV2Lt3L7y9vXVu0G3LggULsGnTJpw8ebJDhT730ScyXFwrRPrhWqGOChxsh8DBdndbfBr37P8l/ToAwMPJGoFe9pB7ORhFiw/30W9GJpO12p6jUCgAoNP785OTk3Ht2jWd5P5eHBwcIJVKUVZW1qlzISIiIuottFp8Jt9t8UnNKcaeY3mIO5YHO2szyD0bns471J0tPp1FsELf19cX27ZtQ2VlpdYNuampqZr3O1NCQgJEIhEiIiL0Puf69etQKpXcS5+IiIioEzTfxWfqGA+UVdYirfFm3hPp13HkXMMuPsMG2Wpu6O1nyU1ROkqwQj88PBxffvkloqOjNfvo19bWIjY2FsHBwZobdQsKClBVVQVPT88OX0upVGL//v0ICQmBs7Ozzvs1NTVQKpU6W2quW7cOADB27NgOX5uIiIiIWtevrynGyZ0xrnEXn8wrpZo9+89dKgJgfC0+3UmwQl8ulyM8PByrVq2CQqGAm5sb4uLiUFBQgBUrVmiOW7ZsGU6fPo2srCzN2LVr1xAfHw8AOH/+PIC7Rbmvry8effRRrWv9/PPPKC0tbXPvfIVCgenTpyMiIgKDBw/W7Lpz8uRJTJkypdWtOImIiIio80hNJPAfbA//wQ0tPvmKSk3RzxafjhGs0AeADz/8EGvWrEF8fDzKysrg4+ODL774AiEhIfc8Lz8/H5988onWWNPr6dOn6xT6CQkJkEqlCA8Pb/XzrK2tERYWhuPHjyMuLg4qlQqDBg3CG2+8gTlz5jzANyQiIiKi9hKJRHB1tISroyWmjh6kafFJzSnWtPiYSsUYPsiOLT73IFKr1d27LUwvwl13iAwX1wqRfrhWyNC0bPEpKW/YsdHDyQryxj37hWjxMcRdd1jodyEW+kSGi2uFSD9cK2TI1Gq1VotPXkE51ECzFh97DHW37ZYWH0Ms9AVt3SEiIiIi6qhWW3xyipCazRYfgIU+ERERERmJfn1NMS7AGeMCnKGsUyHryq1WdvGxaiz6HeDW37h38WHrThdi6w6R4eJaIdIP1woZA7VajWvNWnxyG1t8bK3MGvv67eHrZgtTacdbfNi6Q0RERETUzUQiEQY6WmKgoyUiRg9CeWUt0nKKkZpdhJO/XsdPjS0+w9ztEDjEAQGe9rAxghYfFvpERERE1KtY9zXF2AAnjA1w0rT4pGYXI6XxKb0AMGiAFQK9Gvbs76ktPmzd6UJs3SEyXFwrRPrhWqHeRKvFJ6cIudeatfh42jc+qEu7xefkr9cRm5iDkvIa2FmbYcYET4QOH9Btc+b2mgJhoU9kuLhWiPTDtUK9WfMWn/TfSlBTWw9TEzGGDbKD3MsedfUqRB/JQW2dSnOOqYkYc3/n223FPnv0iYiIiIjaSafF5+otpF7SbvFpqbZOhdjEnG5N9dvCQp+IiIiI6D6kJmL4edjDz8Mez0wegmtFlfjbptOtHlvc+LReoYmFngARERERUU8iEokwUGYJe+vWd+Zpa7y7sdAnIiIiIuqAGRM8YWqiXU6bmogxY4KnQDPSxtYdIiIiIqIOaOrDF3LXnXthoU9ERERE1EGhwwcgdPgAg9yhiq07RERERERGiIU+EREREZERYqFPRERERGSEWOgTERERERkhFvpEREREREaIhT4RERERkRFioU9EREREZIRY6BMRERERGSEW+kRERERERohPxu1CYrGoV12XqKfhWiHSD9cKkX6EWCv3uqZIrVaru3EuRERERETUDdi6Q0RERERkhFjoExEREREZIRb6RERERERGiIU+EREREZERYqFPRERERGSEWOgTERERERkhFvpEREREREaIhT4RERERkRFioU9EREREZIRY6BMRERERGSEToSdAD+7mzZvYunUrUlNTkZ6ejjt37mDr1q0YNWqU0FMjMhhpaWmIi4vDqVOnUFBQABsbGwQFBeHVV1+Fu7u70NMjMhjnz5/H559/jgsXLqC4uBhWVlbw9fXFyy+/jODgYKGnR2TQNmzYgFWrVsHX1xfx8fFCT4eFvjHIy8vDhg0b4O7uDh8fH5w7d07oKREZnI0bN+Ls2bMIDw+Hj48PFAoFtm/fjmnTpiEmJgaenp5CT5HIIFy9ehX19fWYOXMmZDIZbt++jYSEBDz33HPYsGEDxowZI/QUiQySQqHAf//7X1hYWAg9FQ2RWq1WCz0JejAVFRVQKpWwtbXFjz/+iJdffpmJPlELZ8+ehZ+fH0xNTTVjv/32G6ZOnYonnngC77//voCzIzJsVVVVmDRpEvz8/LB+/Xqhp0NkkN544w0UFBRArVajvLzcIBJ99ugbAUtLS9ja2go9DSKDFhwcrFXkA8CgQYMwZMgQ5OTkCDQrop6hT58+sLOzQ3l5udBTITJIaWlp+Pbbb/Hmm28KPRUtLPSJqNdSq9UoKirifygTtaKiogIlJSXIzc3FRx99hIsXLyI0NFToaREZHLVajX/+85+YNm0ahg4dKvR0tLBHn4h6rW+//RY3btzA0qVLhZ4KkcF56623cODAAQCAVCrFH//4R7z44osCz4rI8OzZswfZ2dn47LPPhJ6KDhb6RNQr5eTk4N1330VISAgiIyOFng6RwXn55Zcxa9YsXL9+HfHx8aitrYVSqdRpgSPqzSoqKrB69Wq88MILcHR0FHo6Oti6Q0S9jkKhwKJFi9CvXz988sknEIv5RyFRSz4+PhgzZgz+8Ic/YNOmTfj1118Nrv+YSGj//e9/IZVKMX/+fKGn0ir+dCOiXuX27dtYuHAhbt++jY0bN0Imkwk9JSKDJ5VKMXHiRBw8eBDV1dVCT4fIINy8eRNbtmzBM888g6KiIuTn5yM/Px81NTVQKpXIz89HWVmZoHNk6w4R9Ro1NTV48cUX8dtvv2Hz5s0YPHiw0FMi6jGqq6uhVqtRWVkJc3NzoadDJLji4mIolUqsWrUKq1at0nl/4sSJWLhwIV5//XUBZteAhT4R9Qr19fV49dVXkZKSgnXr1iEwMFDoKREZpJKSEtjZ2WmNVVRU4MCBA3BycoK9vb1AMyMyLAMHDmz1Btw1a9bgzp07eOuttzBo0KDun1gzLPSNxLp16wBAsx94fHw8kpOTYW1tjeeee07IqREZhPfffx+HDx/GI488gtLSUq0HmfTt2xeTJk0ScHZEhuPVV1+FmZkZgoKCIJPJUFhYiNjYWFy/fh0fffSR0NMjMhhWVlat/uzYsmULJBKJQfxc4ZNxjYSPj0+r4y4uLjh8+HA3z4bI8MyePRunT59u9T2uE6K7YmJiEB8fj+zsbJSXl8PKygqBgYFYsGABHnroIaGnR2TwZs+ebTBPxmWhT0RERERkhLjrDhERERGREWKhT0RERERkhFjoExEREREZIRb6RERERERGiIU+EREREZERYqFPRERERGSEWOgTERERERkhFvpERGRUZs+ejUcffVToaRARCc5E6AkQEZHhO3XqFObMmdPm+xKJBBcuXOjGGRER0f2w0CciIr1FRERg/PjxOuNiMX9BTERkaFjoExGR3oYNG4bIyEihp0FERHpgBENERJ0mPz8fPj4+WLt2Lfbu3YupU6fC398fYWFhWLt2Lerq6nTOyczMxMsvv4xRo0bB398fU6ZMwYYNG1BfX69zrEKhwL/+9S9MnDgRfn5+CA0Nxfz583H8+HGdY2/cuIHXXnsNI0eOhFwux/PPP4+8vLwu+d5ERIaIiT4REemtqqoKJSUlOuOmpqawtLTUvD58+DCuXr2KZ599Fg4ODjh8+DA+/fRTFBQUYMWKFZrjzp8/j9mzZ8PExERz7JEjR7Bq1SpkZmZi9erVmmPz8/Px9NNPo7i4GJGRkfDz80NVVRVSU1Nx4sQJjBkzRnPsnTt38Nxzz0Eul2Pp0qXIz8/H1q1bsXjxYuzduxcSiaSL/g4RERkOFvpERKS3tWvXYu3atTrjYWFhWL9+veZ1ZmYmYmJiMHz4cJTw70UAAAMvSURBVADAc889h1deeQWxsbGYNWsWAgMDAQD//ve/UVtbi507d8LX11dz7Kuvvoq9e/fiySefRGhoKADgnXfewc2bN7Fx40aMGzdO6/oqlUrr9a1bt/D8889j4cKFmjE7OzusXLkSJ06c0DmfiMgYsdAnIiK9zZo1C+Hh4TrjdnZ2Wq9Hjx6tKfIBQCQSISoqCj/++CN++OEHBAYGori4GOfOncPkyZM1RX7TsS+99BL279+PH374AaGhoSgtLcWxY8cwbty4Vov0ljcDi8VinV2CHn74YQDA5cuXWegTUa/AQp+IiPTm7u6O0aNH3/c4T09PnTEvLy8AwNWrVwE0tOI0H29u8ODBEIvFmmOvXLkCtVqNYcOG6TVPR0dHmJmZaY3Z2NgAAEpLS/X6DCKino434xIRkdG5Vw++Wq3uxpkQEQmHhT4REXW6nJwcnbHs7GwAgKurKwBg4MCBWuPN5ebmQqVSaY51c3ODSCRCRkZGV02ZiMjosNAnIqJOd+LECfz666+a12q1Ghs3bgQATJo0CQBgb2+PoKAgHDlyBBcvXtQ69osvvgAATJ48GUBD28348eNx9OhRnDhxQud6TOmJiHSxR5+IiPR24cIFxMfHt/peUwEPAL6+vpg7dy6effZZyGQyHDp0CCdOnEBkZCSCgoI0xy1fvhyzZ8/Gs88+i2eeeQYymQxHjhzBzz//jIiICM2OOwDw9ttv48KFC1i4cCGmTZuG4cOHo6amBqmpqXBxccFf/vKXrvviREQ9EAt9IiLS2969e7F3795W3zt48KCmN/7RRx+Fh4cH1q9fj7y8PNjb22Px4sVYvHix1jn+/v7YuXMn/vOf/+Drr7/GnTt34Orqitdffx0LFizQOtbV1RW7d+/GZ599hqNHjyI+Ph7W1tbw9fXFrFmzuuYLExH1YCI1f99JRESdJD8/HxMnTsQrr7yC//f//p/Q0yEi6tXYo09EREREZIRY6BMRERERGSEW+kRERERERog9+kRERERERoiJPhERERGREWKhT0RERERkhFjoExEREREZIRb6RERERERGiIU+EREREZERYqFPRERERGSE/j8us7rg2Hw9XgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BVbl4Zjatzn"
      },
      "source": [
        "## **테스트셋 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5KHb6RkbHdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01e3a21-12a7-4862-fdd0-7634d589a846"
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        " \n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        " \n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        " \n",
        "pred, real = [], [] #f1-score용 배열\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 300 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        " \n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        " \n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    pred.append(np.argmax(logits, axis=1).flatten())\n",
        "    real.append(label_ids.flatten())\n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        " \n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of  1,563.    Elapsed: 0:01:10.\n",
            "  Batch   600  of  1,563.    Elapsed: 0:02:18.\n",
            "  Batch   900  of  1,563.    Elapsed: 0:03:27.\n",
            "  Batch 1,200  of  1,563.    Elapsed: 0:04:36.\n",
            "  Batch 1,500  of  1,563.    Elapsed: 0:05:44.\n",
            "\n",
            "Accuracy: 0.90056\n",
            "Test took: 0:05:59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlOgXJYrguXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015438d6-1955-4c25-8405-9ab37edf6f46"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "print(classification_report(np.concatenate( real, axis=0 ),np.concatenate( pred, axis=0 ), digits=4))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9069    0.8914    0.8991     24826\n",
            "           1     0.8947    0.9097    0.9021     25171\n",
            "\n",
            "    accuracy                         0.9006     49997\n",
            "   macro avg     0.9008    0.9006    0.9006     49997\n",
            "weighted avg     0.9007    0.9006    0.9006     49997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK-T-NuCG96f"
      },
      "source": [
        "#Test\r\n",
        "\r\n",
        "자바스크립트 30분(밀리초)<br>\r\n",
        "\r\n",
        "function ClickConnect(){\r\n",
        "console.log(\"Working\"); \r\n",
        "document.querySelector(\"colab-toolbar-button\").click() \r\n",
        "}setInterval(ClickConnect, 1800000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6V9CbbqZs9R",
        "outputId": "1a389647-be46-42d0-d8b3-1ffd65e84338"
      },
      "source": [
        "for name, param in model.named_parameters():\r\n",
        "    if param.requires_grad:\r\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l0_reverse\n",
            "lstm.weight_hh_l0_reverse\n",
            "lstm.bias_ih_l0_reverse\n",
            "lstm.bias_hh_l0_reverse\n",
            "linear2.weight\n",
            "linear2.bias\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}