{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Image Classification using Keras.ipynb ",
      "provenance": [],
      "collapsed_sections": [
        "tbb1Zhe5tyO8",
        "T-3yx8um7usX",
        "voZTC5W_8dVq",
        "wbCMhPkxhezL"
      ],
      "authorship_tag": "ABX9TyOpRGcgDAtUtL6FzreUZzjX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4nchez/Colab-Jupiter/blob/master/Binary_Image_Classification_using_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m83NRwewjUD"
      },
      "source": [
        "# Kaggle Challenge : Dogs-vs-Cats - Binary Image Classification using Keras\n",
        "해당 포스트는 [Kaggle  Dogs-vs-Cats challenge](https://www.kaggle.com/c/dogs-vs-cats) 해결하기위해 만들었으며, 여러 가지 자료들을 참고하여 만든 포스트 입니다.\n",
        "\n",
        "\n",
        "*   개발 환경 : google colab, Python3, Tensorflow, Keras\n",
        "*   실험 모델 : VGG16(Transfer Learning)\n",
        "*   실험에 쓰인 데이터 : Kaggle Dogs vs Cats challenge\n",
        "*   Test {개: 1,000, 고양이: 1,000} (총 2,000개)\n",
        "*   Training {개: 5,000, 고양이: 5,000} (총 10,000개)\n",
        "*   Validation {개: 2,500, 고양이: 2,500} (총 5,000개)\n",
        "*   IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 150, 150, 3, 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvzEUULo3wfu"
      },
      "source": [
        "GPU 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4yDQ-Wwwk5I"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQtVueKT9Z4x"
      },
      "source": [
        "구글 드라이브 연동 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXnjXPZTn4Dn"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KTB9Rt6n5Mv"
      },
      "source": [
        "import sys\n",
        "MODEL_SAVE_DIR = \"/content/drive/My Drive/Colab Notebooks/model_states/save\" #실험에 쓴 모델을 저장할 드라이브 경로\n",
        "IMAGES_ZIP_DIR = \"/content/drive/My Drive/Colab Notebooks/data/cats_vs_dogs\" #구글 드라이브에 저장되어 있는 데이터셋(이미지)\n",
        "import sys\n",
        "sys.path.append('./drive/My Drive/Colab Notebooks') #kr_helper_funcs 파일이 존재하는 경로\n",
        "import kr_helper_funcs as kru"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE-JTmjLApKN"
      },
      "source": [
        "## Kaggle  Dogs-vs-Cats challenge Dataset\n",
        "Kaggle train.zip 에는 개와 고양이의 이미지 25,000 개 (고양이 색상 이미지 12,500 개 및 다양한 크기의 개 색상 이미지 12,500 개)가 포함되어 있습니다.\n",
        "\n",
        "train Data 중 별도의 프로그램을 사용하여 고양이와 개에 개에 각각 5,000개의 훈련 이미지, 고양이와 개에 대한 2,500개의 평가 이미지, 고양이와 개에 개에 각각 1,000개의 테스트 이미지로 구성된 작은 데이터 세트를 만들었습니다. 그런 다음 이미지 Dataset.zip 파일을 Google 드라이브에 업로드했습니다.\n",
        "\n",
        "zip 파일 cats_vs_dogs_images_small.zip은 내 Google 드라이브의 IMAGES_ZIP_DIR에서 사용할 수 있습니다. 아래 코드 셀은 로컬로 다운로드하고 /tmp 폴더에 이미지 압축을 풉니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ2LtU_aEZA9"
      },
      "source": [
        "import sys, os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "print('Using Tensorflow version ', tf.__version__)\n",
        "print('Using keras version ', keras.__version__)\n",
        " \n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "# tf.set_random_seed(seed)\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # ignore all warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohb1Hf6FyTO"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, MaxPooling2D, \n",
        "                                     Flatten, Dense, Dropout)\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea0g4CxrAmbA"
      },
      "source": [
        "import os, shutil\n",
        "import zipfile\n",
        " \n",
        "#!cp $(IMAGES_ZIP_DIR/images_small.zip\" /tmp\n",
        "source_file = os.path.join(IMAGES_ZIP_DIR, 'cats_vs_dogs_images_small.zip')\n",
        "local_zip = '/tmp/cats_vs_dogs_images_small.zip'\n",
        " \n",
        "print(\"Copying from drive %s to %s...\" % (source_file, local_zip), flush=True)\n",
        "shutil.copyfile(source_file, local_zip)\n",
        " \n",
        "assert os.path.exists(local_zip)\n",
        " \n",
        "print('Extracting all images...', flush=True)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        " \n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbb1Zhe5tyO8"
      },
      "source": [
        "## 실험에 쓰일 데이터 파일 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leOe8BLVSZl1"
      },
      "source": [
        "images_root = \"/tmp\" # /content/drive/My Drive/img\n",
        "assert os.path.exists(images_root), \"%s folder does not exist!\" % images_root\n",
        " \n",
        "train_root = os.path.join(images_root,'training')\n",
        "train_root_cat = os.path.join(train_root,'cat')\n",
        "train_root_dog = os.path.join(train_root,'dog')\n",
        " \n",
        "eval_root = os.path.join(images_root,'validation')\n",
        "eval_root_cat = os.path.join(eval_root,'cat')\n",
        "eval_root_dog = os.path.join(eval_root,'dog')\n",
        " \n",
        "test_root = os.path.join(images_root,'test')\n",
        "test_root_cat = os.path.join(test_root,'cat')\n",
        "test_root_dog = os.path.join(test_root,'dog')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTL2Tfh3jxCT"
      },
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 150, 150, 3, 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMEZewGL2kw0"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "eval_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')\n",
        " \n",
        "eval_generator = eval_datagen.flow_from_directory(\n",
        "    eval_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')\n",
        " \n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA_rvSOe2kw2"
      },
      "source": [
        "train_steps = train_generator.n // BATCH_SIZE\n",
        "val_steps = eval_generator.n // BATCH_SIZE\n",
        "test_steps = test_generator.n // BATCH_SIZE\n",
        "train_steps, val_steps, test_steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiKWhwVE2Utm"
      },
      "source": [
        "# 기본 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZYbVmb_BnCv"
      },
      "source": [
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "vgg_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7liCfyfuCCwC"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(vgg_base, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0e9SrkM2kwu"
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = relu\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.50),        \n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "# for layer in model.layers:\n",
        "#     if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      # layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='binary_crossentropy',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq_UdcKD2kwy"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrWUlGFk2YUG"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBVRlLmn2YUI"
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agbd40QM2YUK"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1sX3BhEUE9"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_history.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "kru.save_keras_model(model, 'cats_vs_dogs_vgg16', MODEL_SAVE_DIR)\n",
        "del vgg_base\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-3yx8um7usX"
      },
      "source": [
        "# mse 인 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5fgtKwO79qJ"
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = relu\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.50),        \n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "# for layer in model.layers:\n",
        "#     if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      # layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='mse',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo_otoFV79qN"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiD-J7-I79qP"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLU_aOTk79qQ"
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mWRhVLU79qS"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "099XRSSYFJnv"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_mse_history.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_mse_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "kru.save_keras_model(model, 'cats_vs_dogs_vgg16_mse', MODEL_SAVE_DIR)\n",
        "del model, vgg_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voZTC5W_8dVq"
      },
      "source": [
        "# 활성함수가 sigmoid 이며 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDjG0kwE8dVr"
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.50),        \n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='binary_crossentropy',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otZ2ft-V8dVu"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S98GxzEA8dVw"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InSvEYEK8dVz"
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Ix6bBk8dV1"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0l3JzHjFayq"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_sig_history.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_sig_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "kru.save_keras_model(model, 'cats_vs_dogs_vgg16_sig', MODEL_SAVE_DIR)\n",
        "del model, vgg_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbCMhPkxhezL"
      },
      "source": [
        "# 활성함수가 sigmoid이며 mse 인 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZMrJonrkYp"
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.50),        \n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='mse',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC95Tb90tQ20"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Pw9I-Za6My"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBQkhHKHQ3i4"
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSXUGOLZ81OS"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr5uGiowFjTy"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_sig_mse_history.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_sig_mse_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "kru.save_keras_model(model, 'cats_vs_dogs_vgg16_sig_mse', MODEL_SAVE_DIR)\n",
        "del model, vgg_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INnkCGVPbwnY"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWyKAB-Hbxnj"
      },
      "source": [
        "# cats_vs_dogs_vgg16\n",
        "# cats_vs_dogs_vgg16_mse\n",
        "# cats_vs_dogs_vgg16_sig\n",
        "# cats_vs_dogs_vgg16_sig_mse\n",
        "model = kru.load_keras_model('cats_vs_dogs_vgg16',MODEL_SAVE_DIR)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKPm-D0ycOgN"
      },
      "source": [
        "cat_test_files = np.array(os.listdir(test_root_cat))\n",
        "dog_test_files = np.array(os.listdir(test_root_dog))\n",
        "# for _ in range(5): indexes = np.random.permutation(range(len(cat_test_files)))\n",
        "# cat_test_files = cat_test_files[indexes]\n",
        "# dog_test_files = dog_test_files[indexes]\n",
        "for _ in range(5):\n",
        "    np.random.shuffle(cat_test_files)\n",
        "    np.random.shuffle(dog_test_files)\n",
        " \n",
        "test_image_files = []\n",
        "for image in cat_test_files:\n",
        "    test_image_files.append(os.path.join(test_root_cat, image))\n",
        "for image in dog_test_files:\n",
        "    test_image_files.append(os.path.join(test_root_dog, image))\n",
        "test_image_files = np.array(test_image_files)\n",
        "for _ in range(5): indexes = np.random.permutation(range(len(test_image_files)))\n",
        "test_image_files = test_image_files[indexes]\n",
        "test_image_files[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMgkbfDLcPUo"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from tqdm import tqdm\n",
        "predictions = []   # list of tuples (image_path, probab, pred_name, act_name)\n",
        "incorrect_predictions = []  # list of tuples (image_path, probab, actual, prediction)\n",
        " \n",
        "for test_image in tqdm(test_image_files):\n",
        "    img = image.load_img(test_image, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x /= 255.0\n",
        " \n",
        "    images_list = np.vstack([x])\n",
        "    classes = model_xfer.predict(images_list, batch_size=10)\n",
        "    prob = classes[0]\n",
        "    actual_name = (test_image.split(os.path.sep)[-1].split('.')[0]).upper() # == 'CAT' or 'DOG'\n",
        "    pred_name = 'DOG' if (prob >= 0.5) else 'CAT'\n",
        "    is_correct = (actual_name == pred_name)\n",
        "    \n",
        "    predictions.append((test_image, prob, pred_name, actual_name))\n",
        "    if not is_correct:\n",
        "        incorrect_predictions.append((test_image, prob, pred_name, actual_name))\n",
        "    \n",
        "    \n",
        "print(\"Displaying %d incorrect predictions...\" % len(incorrect_predictions))    \n",
        "for item in incorrect_predictions:\n",
        "    test_image, prob, pred_name, actual_name = item\n",
        "    print('%*s - probability: %.4f - predicted %s, is a %s' %\n",
        "            (50, test_image, prob, pred_name, actual_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZcwZG1yaHMN"
      },
      "source": [
        "figure = plt.figure(figsize=(20, 8))\n",
        "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
        "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
        "    # 각각의 이미지를 보여줌\n",
        "    ax.imshow(np.squeeze(x_test[index]))\n",
        "    predict_index = np.argmax(y_hat[index])\n",
        "    true_index = np.argmax(y_test[index])\n",
        "    # 각각의 이미지에 예측레이블 (실제레이블) 표시\n",
        "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
        "                                  fashion_mnist_labels[true_index]),\n",
        "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}