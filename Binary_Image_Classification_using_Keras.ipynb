{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Image Classification using Keras.ipynb ",
      "provenance": [],
      "collapsed_sections": [
        "EiKWhwVE2Utm",
        "T-3yx8um7usX",
        "voZTC5W_8dVq",
        "wbCMhPkxhezL",
        "INnkCGVPbwnY"
      ],
      "authorship_tag": "ABX9TyPBbEFaWYNJ2mi0pnC9BEbe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4nchez/Colab-Jupiter/blob/master/Binary_Image_Classification_using_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m83NRwewjUD"
      },
      "source": [
        "# Kaggle Challenge : Dogs-vs-Cats - Binary Image Classification using Keras\n",
        "해당 포스트는 [Kaggle  Dogs-vs-Cats challenge](https://www.kaggle.com/c/dogs-vs-cats) 해결하기위해 만들었으며, 여러 가지 자료들을 참고하여 만든 포스트 입니다.\n",
        "\n",
        "\n",
        "*   개발 환경 : google colab, Python3, Tensorflow, Keras\n",
        "*   실험 모델 : VGG16(Transfer Learning)\n",
        "*   실험에 쓰인 데이터 : Kaggle Dogs vs Cats challenge\n",
        "*   Test {개: 1,000, 고양이: 1,000} (총 2,000개)\n",
        "*   Training {개: 5,000, 고양이: 5,000} (총 10,000개)\n",
        "*   Validation {개: 2,500, 고양이: 2,500} (총 5,000개)\n",
        "*   IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 150, 150, 3, 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvzEUULo3wfu"
      },
      "source": [
        "GPU 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4yDQ-Wwwk5I",
        "outputId": "48c205a2-5c33-423a-f23b-72d98ad08969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct  7 08:32:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    27W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQtVueKT9Z4x"
      },
      "source": [
        "구글 드라이브 연동 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXnjXPZTn4Dn",
        "outputId": "a48cc094-0ce3-4c66-9f89-338c1e6d49d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KTB9Rt6n5Mv"
      },
      "source": [
        "import sys\n",
        "MODEL_SAVE_DIR = \"/content/drive/My Drive/Colab Notebooks/model_states/save\" #실험에 쓴 모델을 저장할 드라이브 경로\n",
        "IMAGES_ZIP_DIR = \"/content/drive/My Drive/Colab Notebooks/data/cats_vs_dogs\" #구글 드라이브에 저장되어 있는 데이터셋(이미지)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE-JTmjLApKN"
      },
      "source": [
        "## Kaggle  Dogs-vs-Cats challenge Dataset\n",
        "Kaggle train.zip 에는 개와 고양이의 이미지 25,000 개 (고양이 색상 이미지 12,500 개 및 다양한 크기의 개 색상 이미지 12,500 개)가 포함되어 있습니다.\n",
        "\n",
        "train Data 중 별도의 프로그램을 사용하여 고양이와 개에 개에 각각 5,000개의 훈련 이미지, 고양이와 개에 대한 2,500개의 평가 이미지, 고양이와 개에 개에 각각 1,000개의 테스트 이미지로 구성된 작은 데이터 세트를 만들었습니다. 그런 다음 이미지 Dataset.zip 파일을 Google 드라이브에 업로드했습니다.\n",
        "\n",
        "zip 파일 cats_vs_dogs_images_small.zip은 내 Google 드라이브의 IMAGES_ZIP_DIR에서 사용할 수 있습니다. 아래 코드 셀은 로컬로 다운로드하고 /tmp 폴더에 이미지 압축을 풉니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ2LtU_aEZA9",
        "outputId": "37a3105b-3fdb-475e-9f40-c2dc8b2309b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys, os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "print('Using Tensorflow version ', tf.__version__)\n",
        "print('Using keras version ', keras.__version__)\n",
        " \n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "# tf.set_random_seed(seed)\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # ignore all warnings"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Tensorflow version  2.3.0\n",
            "Using keras version  2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohb1Hf6FyTO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, MaxPooling2D, \n",
        "                                     Flatten, Dense, Dropout)\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea0g4CxrAmbA",
        "outputId": "eed5dd0a-7c37-407d-df4a-9a1d31ec0e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os, shutil\n",
        "import zipfile\n",
        " \n",
        "#!cp $(IMAGES_ZIP_DIR/images_small.zip\" /tmp\n",
        "source_file = os.path.join(IMAGES_ZIP_DIR, 'cats_vs_dogs_images_small.zip')\n",
        "local_zip = '/tmp/cats_vs_dogs_images_small.zip'\n",
        " \n",
        "print(\"Copying from drive %s to %s...\" % (source_file, local_zip), flush=True)\n",
        "shutil.copyfile(source_file, local_zip)\n",
        " \n",
        "assert os.path.exists(local_zip)\n",
        " \n",
        "print('Extracting all images...', flush=True)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        " \n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying from drive /content/drive/My Drive/Colab Notebooks/data/cats_vs_dogs/cats_vs_dogs_images_small.zip to /tmp/cats_vs_dogs_images_small.zip...\n",
            "Extracting all images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbb1Zhe5tyO8"
      },
      "source": [
        "## 실험에 쓰일 데이터 파일 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leOe8BLVSZl1"
      },
      "source": [
        "images_root = \"/tmp\" # /content/drive/My Drive/img\n",
        "assert os.path.exists(images_root), \"%s folder does not exist!\" % images_root\n",
        " \n",
        "train_root = os.path.join(images_root,'training')\n",
        "train_root_cat = os.path.join(train_root,'cat')\n",
        "train_root_dog = os.path.join(train_root,'dog')\n",
        " \n",
        "eval_root = os.path.join(images_root,'validation')\n",
        "eval_root_cat = os.path.join(eval_root,'cat')\n",
        "eval_root_dog = os.path.join(eval_root,'dog')\n",
        " \n",
        "test_root = os.path.join(images_root,'test')\n",
        "test_root_cat = os.path.join(test_root,'cat')\n",
        "test_root_dog = os.path.join(test_root,'dog')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTL2Tfh3jxCT"
      },
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, BATCH_SIZE = 224, 224, 3, 32"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMEZewGL2kw0",
        "outputId": "3b87bbfa-ebe2-4b61-d591-d8b854650280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "eval_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')\n",
        " \n",
        "eval_generator = eval_datagen.flow_from_directory(\n",
        "    eval_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')\n",
        " \n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_root,\n",
        "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),  # 이미지 사이즈 변경\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA_rvSOe2kw2",
        "outputId": "311a8a22-7240-450d-a51c-3d9bd6c99cf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_steps = train_generator.n // BATCH_SIZE\n",
        "val_steps = eval_generator.n // BATCH_SIZE\n",
        "test_steps = test_generator.n // BATCH_SIZE\n",
        "train_steps, val_steps, test_steps"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 156, 62)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7EirR3hJC_o"
      },
      "source": [
        "# Default VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRLcSK62GFWH",
        "outputId": "12c8a98a-47a3-4e6c-8d2b-ea16ae52cc65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vgg_base = keras.applications.InceptionV3(include_top=True, weights='imagenet',input_shape=(299, 299, 3))\n",
        "x = Dense(1, activation='sigmoid', name='predictions')(vgg_base.layers[-2].output)\n",
        "vgg_base.trainable = False\n",
        "model = Model(vgg_base.input,x)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='binary_crossentropy',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1)            2049        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 21,804,833\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnerMzbBJBO_",
        "outputId": "0cc32b1f-05cb-43cc-dc36-33c386d54e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=1,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-053c30e40fbb>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "312/312 [==============================] - 55s 178ms/step - loss: 0.2742 - acc: 0.9085 - val_loss: 0.1227 - val_acc: 0.9736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5J3hKz0JlEH"
      },
      "source": [
        "def show_plots(history, plot_title=None, fig_size=None):\n",
        "    \"\"\" Useful function to view plot of loss values & accuracies across the various epochs\n",
        "        Works with the history object returned by the train_model(...) call \"\"\"\n",
        "    assert type(history) is dict\n",
        "\n",
        "    # NOTE: the history object should always have loss & acc (for training data), but MAY have\n",
        "    # val_loss & val_acc for validation data\n",
        "    loss_vals = history['loss']\n",
        "    val_loss_vals = history['val_loss'] if 'val_loss' in history.keys() else None\n",
        "    epochs = range(1, len(history['acc']) + 1)\n",
        "\n",
        "    f, ax = plt.subplots(nrows=1, ncols=2, figsize=((16, 4) if fig_size is None else fig_size))\n",
        "\n",
        "    # plot losses on ax[0]\n",
        "    ax[0].plot(epochs, loss_vals, color='navy', marker='o', linestyle=' ', label='Training Loss')\n",
        "    if val_loss_vals is not None:\n",
        "        ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n",
        "        ax[0].set_title('Training & Validation Loss')\n",
        "        ax[0].legend(loc='best')\n",
        "    else:\n",
        "        ax[0].set_title('Training Loss')\n",
        "\n",
        "    ax[0].set_xlabel('Epochs')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].grid(True)\n",
        "\n",
        "    # plot accuracies\n",
        "    acc_vals = history['acc']\n",
        "    val_acc_vals = history['val_acc'] if 'val_acc' in history.keys() else None\n",
        "\n",
        "    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n",
        "    if val_acc_vals is not None:\n",
        "        ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n",
        "        ax[1].set_title('Training & Validation Accuracy')\n",
        "        ax[1].legend(loc='best')\n",
        "    else:\n",
        "        ax[1].set_title('Training Accuracy')\n",
        "\n",
        "    ax[1].set_xlabel('Epochs')\n",
        "    ax[1].set_ylabel('Accuracy')\n",
        "    ax[1].grid(True)\n",
        "\n",
        "    if plot_title is not None:\n",
        "        plt.suptitle(plot_title)\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # delete locals from heap before exiting (to save some memory!)\n",
        "    del loss_vals, epochs, acc_vals\n",
        "    if val_loss_vals is not None:\n",
        "        del val_loss_vals\n",
        "    if val_acc_vals is not None:\n",
        "        del val_acc_vals\n",
        "def save_keras_model(model, base_file_name, save_dir=os.path.join('.','keras_models')):\n",
        "    \"\"\" save the model structure to JSON & weights to HD5 \"\"\"    \n",
        "    # check if save_dir exists, else create it\n",
        "    if not os.path.exists(save_dir):\n",
        "        try:\n",
        "            os.mkdir(save_dir)\n",
        "        except OSError as err:\n",
        "            print(\"Unable to create folder {} to save Keras model. Can't continue!\".format(save_dir))\n",
        "            raise err\n",
        "            \n",
        "    # model structure is saved to $(save_dir)/base_file_name.json\n",
        "    # weights are saved to $(save_dir)/base_file_name.h5\n",
        "    model_json = model.to_json()\n",
        "    json_file_path = os.path.join(save_dir, (base_file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(save_dir, (base_file_name + \".h5\"))            \n",
        "\n",
        "    with open(json_file_path, \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\\n\",\n",
        "    model.save_weights(h5_file_path)\n",
        "    print(\"Saved model to files %s and %s\" % (json_file_path, h5_file_path))\n",
        "\n",
        "def load_keras_model(base_file_name, load_dir=os.path.join('.', 'keras_models')):\n",
        "    \"\"\" loads model structure & weights from previously saved state \"\"\"\n",
        "    # model structure is loaded $(load_dir)/base_file_name.json\n",
        "    # weights are loaded from $(load_dir)/base_file_name.h5\n",
        "\n",
        "    from tensorflow.keras.models import model_from_json\n",
        "\n",
        "    # load model from save_path\n",
        "    loaded_model = None\n",
        "    json_file_path = os.path.join(load_dir, (base_file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(load_dir, (base_file_name + \".h5\"))\n",
        "\n",
        "    if os.path.exists(json_file_path) and os.path.exists(h5_file_path):\n",
        "        with open(json_file_path, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            loaded_model = model_from_json(loaded_model_json)\n",
        "            loaded_model.load_weights(h5_file_path)\n",
        "        print(\"Loaded model from files %s and %s\" % (json_file_path, h5_file_path))\n",
        "    else:\n",
        "        msg = \"Model file(s) not found in %s! Expecting to find %s and %s in this directory.\" % (\n",
        "            load_dir, (base_file_name + \".json\"), (base_file_name + \".h5\"))\n",
        "        raise IOError(msg)\n",
        "    return loaded_model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVhbOUA3JBPC",
        "outputId": "b77171fe-cbe5-4a55-fc1f-ac6f2c9dd3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "show_plots(hist.history, plot_title='Using VGG16')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAEjCAYAAAAGzp1BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXwV5fn38c9FWCIQEQSpsvtzA4QQCIsrQXwsLgUBqSBYcQGltf7QulBt1Z/LI7U+baVYLSq1WASFKj+oKAUkYItUFgVZK2WRxaqAxMTIkuR6/phJeohZDpCTk5N8369XXp6ZuWfmmjvIzXXmXszdEREREREREUlUteIdgIiIiIiIiMjxUGIrIiIiIiIiCU2JrYiIiIiIiCQ0JbYiIiIiIiKS0JTYioiIiIiISEJTYisiIiIiIiIJTYmtiIhIOcxsnZllxDsOERERKZkSWxERqRHMzM3sjGL7HjazP5V3rrt3dPfMCo6nl5l9bWYNSzj2gZndHn6ua2YPmtmmsPwuM3vLzC4rds5QM/tHWObz8PMPzczC433MbJGZZZnZtlJi+m8z2xpeY4OZnVWRzywiIhIrSmxFRETiwN2XATuBayL3m9m5QAdgWrhrJjAA+AHQGGgHPA1cGXHOT8J9vwS+AzQHbgMuAOqGxb4GJgP3lBSPmd0C3BxetyFwFbDn+J5SRESkcpi7xzsGERGRmDMzB850980R+x4GznD3EWbWFHgJuBAoANYBvd29IHzDeYu7LwjP6QAcAAYCnwA3uPuK8JpdgReBM4C3w2t97O4/KyGm+4FL3f2SiH1PhnEONLNLgTnh9s5SnqsRsBv4gbv/OYp6uBR4wd3bRuyrBWwHRrr7wvKuISIiUtXoja2IiEjgJwRvUJsRvPG8Hyjt29/+wHTgJGA2MBGCbsPAGwQJchOCt64Dy7jny8DFZtYqPL8WcB3wx/D4pcA/SktqQ+cB9YD/LfPpytYy/DnXzHaE3ZH/J4xHRESkylODJSIiEjgMnAq0cffD7v6ul96t6W/uPtfd8wmS09Rwfy+gNjAhvMbrwPul3dDddwCZwPXhrr4ESeqb4XZT4N+F5c2siZntD8fJHogos8fd8yLKLQ3LfWNmF0fx7C3D/14GdAL6AMMIuiaLiIhUeUpsRUSkpsgH6hTbV4cgoYVgfOpm4K9mtsXMxpVxrX9HfM4Fks2sNnAasKtYQryjnLj+yH8S2+uB6e5eGNNegmQbAHff5+4nAd0IEuDCMk3D+xeWOz8st5fo2vpvwv8+6e773X0b8HvgiijOFRERiTsltiIiUlN8ArQttq8dwdhS3D3b3X/i7qcTdDW+y8z6HuU9PgVaFM5EHGpVzjmvAy3NrA8wiP90QwZYCHQ3s5Ylnhl4DzhIMMHUsdoEHOLIrteahENERBKGElsREakpXgV+ZmYtzaxWOInS9whmHcbMrjKzM8KkNIvgDW/BUd7jvfC8282stpkNAHqUdYK7fx3G8Adge+EkVOGxvwKLgFlm1jNc+qcOQZfnwjL7gf8Bfmdm15hZSvh8XYAGheXCfckEb6nNzJLDMcG4e25YP/eG57cERgN/OcrnFxERiQsltiIiUlM8AiwF/gZ8CTwJDHf3teHxM4EFQA5Bgvo7d190NDdw90MEb11vBvYDIwiSw4PlnPpHoA0wpYRjA8Nr/Cm85lZgOPDdiPs+CdwF3At8Fv78HrgvfGaAiwm6HM8FWoef/xpxn9sJnn03wfO/QrA8kIiISJWn5X5ERERiyMz+ATzn7n+IdywiIiLVld7YioiIVCAz621m3wm7It8AdCZYz1ZERERipHb5RUREROQonA28RjC+dQtwjbt/Gt+QREREqje9sRUJmdlb4duVCi1blZlZWzPzwmVCynqu4mWP4V73m9kLxxOvSCJw90nu3tzdG7p7Z3d/s/yzRKo3tbFqY0ViTYmtJDQzy4n4KTCzbyK2hx/Ntdz9cnf/Y/klj67s0TKzJmY2x8yyzGy3md1bTvmNZnZTCfv/28xWlHROaSrqucwsw8x2Frv2/3X3W4732iXca6SZ/a2irysiUtOpjVUbW+yebmb3xeoeIsdLia0ktPCNSEN3b0iwRuX3IvZNLSx3rN+Axsk9QDJwKtAR+Hs55f8I/KCE/ddz5HqYIiIiUVMbC6iNLXQDsI+S6yJmLKB8RaKiPyhSLRV+m2lm95nZv4E/mFljM/uLmX1hZl+Gn1tGnJNpZreEn0ea2d/M7Kmw7FYzu/wYy7YzsyVmlm1mC8zsGTP7UxnhHwY+d/dcd//S3ctrdF8GLjSzNhH37EAwYc00M7vSzD4ws6/MbIeZPVxGvUU+V1L4THvMbAtwZbGyN5rZhvC5tpjZreH+BsBbwGkR3+yfZmYPRz63mfU3s3Vmtj+8b/uIY9vM7G4zWxN+q/6qBetvHhUzO9/MlofXWG5m50ccGxnGnR3+zoaH+88ws8XhOXvM7NWjva+ISHWmNrZmtbHhPa8BfgScaWbpxY6Pioh1vZl1Dfe3MrPXwz8Te81sYri/eKzFu2xnmtnjZvZ3IBc4vbT6iLjGADP7MPw9/MvM+pnZEDNbWazcXWb2v6U9qyQ2JbZSnX0HaEKwNuRogj/vfwi3C9dwnFjG+T2BTUBTgvUuXzQzO4ayrwDvAycDDxN8y1uW5cAwM7u5nHIAuPtOYFGx614PzHX3PcDXBN+wnkTQcI4xs6ujuPQo4CogDUgnaNQifR4ePxG4Efi1mXV196+By4HdEd/s74480czOAqYBY4FmBOtqzjGzuhHFvg/0A9oR/ANiZBQxR96jCfAmMIGg7n8FvGlmJ4eN9ATgcndPAc4HPgxPfZRgbc/GQEvgt0dzXxGRGkJtbM1pYwcRrHE9A5hH8Pa28F5DCOr9B2Gs/YG9ZpZEsP72dqAt0AKYXk6dRLqe4M9VSniNEusjjKEHwRrg9xD8Hi4GtgGzgXaRSX143ZLWC5dqQImtVGcFwEPuftDdv3H3ve7+5/Bb2mzgcaB3Gedvd/fn3T2foLvRqUDzoylrZq2B7sCD7n7I3f9G8BdticzsDGASkAGMs3Bcj5nVM7NDZtaolFP/SNjoWtBlZ3i4D3fPdPeP3L3A3dcQNHZlPXeh7wO/cfcd7r4PeCLyoLu/6e7/8sBigmTwoiiuC3At8Ka7z3f3w8BTwAkECWahCe6+O7z3HKBLlNcudCXwsbu/7O557j4N2Ah8LzxeAJxrZie4+6fuvi7cf5jgH2anufuB8HcmIiJHUhtLjWljbwBeDev/FWComdUJj90CPOnuy8NYN7v7dqAHcBpwj7t/fQzt6Uvuvi5svw+XUx83A5PD5y1w913uvtHdDwKvAiMAzKwjQZL9l6OIQxKIElupzr5w9wOFG2ZW38x+b2bbzewrYAlwUvitYkn+XfjB3XPDjw2PsuxpwL6IfQA7yoj5ZmC2uy8BLgMeCRveXsBqd88q5bzXgVPNrBdBg12f4G0lZtbTzBaFXYGygNsIvvUuz2nFYt0eedDMLjezZWa2z8z2A1dEed3Caxddz90Lwnu1iCjz74jPuZRe91HdI7QdaBF+430tQV18amZvmtk5YZl7AQPeD7txfWvSEBERURsL1b+NNbNWQB+gcEz1/xKMUS7sOt0K+FcJp7Yi+EIiL8qYizvi91hOfZQWAwRfQFwXvuG/HngtTHilGlJiK9WZF9v+CcH6kj3d/USCrioQJDGx8inQxMzqR+xrVUb52kAdAHffStBN6BfAC+F/SxQ26jMJugJdD0x390Ph4VcIvsFu5e6NgOeI7pk/LRZr68IPZlYP+DPBt8DN3f0kgq5OhdctXvfF7SZ4K1p4PQvvtSuKuKJ1xD1CrQvv4e7z3P3/EHzzvxF4Ptz/b3cf5e6nAbcCvwu/5RcRkf9QGxuo7m3s9QT5whwLxlNvIUhsC7sj7wD+q4TzdgCtreSJxb4m+HKg0HdKKFP0jFHUR2kx4O7LgEMEb3evIxgzLdWUElupSVIIxvzsD8dfPhTrG4bdcVYAD5tZXTM7j/90hS3J68C1ZnZ1+C33V8Bqgr+wc8s4D4JvJa8FBnPkTI0pBN9oHwjHoVwXZfivAXeYWUszawyMizhWF6gHfAHkWTCRx2URxz8DTi6jW9drwJVm1jfszvQT4CCwNMrYijMzS478IWj0zjKz68ystpldC3QA/mJmzS2YaKJBeN8cgm51hJNNFE548iVB41pwjHGJiNQUamOrZxt7A/A/BF2VC38GA1eY2ckEXwrcbWbdLHCGBRNtvU+QvI83swZh23xBeM0PgYvNrHX4DD8tJ4by6uNF4MbweWuZWYuIXlgQjKmdCBzW8KLqTYmt1CS/IRhjsgdYBrxdSfcdDpwH7AUeIxjvUWI3GHd/j6BRfAjIIujKlUkwqcQ0M0sr4z5LwnN2uvvyiP0/JOhulQ08SNDgReN5gkkiVgOrCP5BUBhnNnBHeK0vw5hnRxzfSDDOaIsFMzKeVuw5NxGMefktwe/jewTLSBzi2JxP8A+qyJ8sgokmfkJQ9/cCV3kw2Uct4C6Cb7X3EYyHGhNeqzvwDzPLCZ/pv919yzHGJSJSU6iNrWZtbNj1ug3wTNibqfBnNrAZGObuMwjGU78CZAOzgCbheNzvAWcQLBW1k+CLAdx9PsHvaQ2wknLGvEZRH+8TTihF8DtazJE9tl4GzgXKmi1bqgFzL683g4hUJAuWj9no7jH/NltERKQmURsrxZnZCQSzKnd194/jHY/Ejt7YisSYmXU3s/8Ku8f0AwYQfKMpIiIix0FtrERhDLBcSW31V9KAbhGpWN8h6GJ0MkFXnDHu/kF8QxIREakW1MZKqcxsG8EkU9GsLSwJTl2RRUREREREJKHFtCuymfUzs01mttnMxpVw/C4zW29ma8xsYTiLWuGxJ8M1JDeY2YRwqnIRERERERGRI8SsK3I4jfozwP8h6Bqy3Mxmu/v6iGIfAOnunmtmY4AnCaZhPx+4AOgclvsbwaylmaXdr2nTpt62bdsKf46q4uuvv6ZBgwbxDqPKUz2VT3UUHdVTdKpzPa1cuXKPuzeLdxyJTG2zgOopGqqj6KieolOd66mstjmWY2x7AJsLl8kws+kEA/qLElt3XxRRfhnB1OQQrBuZTLBulREspv1ZWTdr27YtK1asqLDgq5rMzEwyMjLiHUaVp3oqn+ooOqqn6FTnejKz7fGOIdGpbRZQPUVDdRQd1VN0qnM9ldU2x7IrcgtgR8T2znBfaW4G3oKidcYWESzs/Ckwz903xChOERERERERSWBVYlZkMxsBpBN0N8bMzgDaAy3DIvPN7CJ3f7fYeaOB0QDNmzcnMzOz0mKubDk5OdX6+SqK6ql8qqPoqJ6io3oSERGRqiCWie0uoFXEdstw3xHM7FLgAaC3ux8Mdw8Elrl7TljmLeA84IjE1t0nAZMA0tPTvbq+cofq3aWgIqmeyqc6io7qKTqqJxEREakKYpnYLgfONLN2BAntUOC6yAJmlgb8Hujn7p9HHPoEGGVmTxCMse0N/CaGsYqIVIjDhw+zc+dODhw4EO9QKkWjRo3YsCGxR4okJyfTsmVL6tSpE+9QRERqpGjbzurQ5lSG6lBPx9I2xyyxdfc8M7sdmAckAZPdfZ2ZPQKscPfZwC+BhsCMcDWfT9y9PzATuAT4iGAiqbfdfU6sYhURqSg7d+4kJSWFtm3bUhNWKcvOziYlJSXeYRwzd2fv3r3s3LmTdu3axTscEZEaKdq2M9HbnMqS6PV0rG1zTMfYuvtcYG6xfQ9GfL60lPPygVtjGZtITTN16kc88MBCPvkki9atP+Txx/syfHineIdV7Rw4cKDGJLXVgZlx8skn88UXX8Q7FBGpoQ58/jm5v/gFBzp2JLlZzVxhTG2nRDrWtjmWsyKLSBUxdepHjB49h+3bs3CH7duzGD16DlOnfhTv0KolNcyJRb8vEYmnf06cSP7HH/PP3/423qHElf4ulkjH8uehSsyKLCKx9cADC8nNPXzEvtzcwzzwwEK9tRUREYmDNzt0oODgwaLt7VOnsn3qVGrVq8eV69fHMTKRxKQ3tiI1wCefZB3Vfklce/fupUuXLnTp0oXvfOc7tGjRomj70KFDZZ67YsUK7rjjjnLvcf7551dIrJmZmVx11VUVci0RkUTTNzOTFv37k5ScDEBScjItBgyg7+LFcY6s5kmktrPQ2LFjadGiBQUFBRV63USmN7YiNUDr1o3Yvv3bSWzr1o3iEI1EOnLsc6PjHvt88skn8+GHHwLw8MMP07BhQ+6+++6i43l5edSuXfJf/enp6aSnp5d7j6VLlx5zfCIiEkg+5RRqN2xI/sGDUKcO+QcPUrthwxo7zvZo1PS2s6CggDfeeINWrVqxePFi+vTpU2HXjlTWc1dFemMrUgM8/nhf6tc/crr0+vXr8PjjfeMUkUDljX0eOXIkt912Gz179uTee+/l/fff57zzziMtLY3zzz+fTZs2AUe+QX344Ye56aabyMjI4PTTT2fChAlF12vYsGFR+SuuuIJrrrmGc845h+HDh+PuAMydO5dzzjmHbt26cccddxzVm9lp06bRqVMnzj33XO677z4A8vPzGTlyJOeeey6dOnXi17/+NQATJkygQ4cOdO7cmaFDhx5/ZYmIVKKDe/bQ5rrrqP/AA7S57joOaiK7clWHtjMjI+O42s7MzEw6duzImDFjmDZtWtH+zz77jIEDB3L++eeTmppalExPmTKFzp07k5qayvXXX1/0fDNnziwxvosuuoj+/fvToUMHAK6++mq6detGx44dmTRpUtE5b7/9Nl27diU1NZW+fftSUFDAmWeeWTTpU0FBAWeccUalTdCYOCm4iByzwm8xK/LbTTl+lTn2eefOnSxdupSkpCS++uor3n33XWrXrs2CBQu4//77+fOf//ytczZu3MiiRYvIzs7m7LPPZsyYMd9aT27NmjWsW7eO0047jQsuuIC///3vpKenc+utt7JkyRLatWvHsGHDoo5z9+7d3HfffaxcuZLGjRtz2WWXMWvWLFq1asWuXbtYu3YtAPv37wdg/PjxbN26lXr16hXtExFJFN2ffRYIkonOYcIhZasObecHH3xwXG3ntGnTGDZsGAMGDOD+++/n8OHD1KlThzvuuIPevXszZcoU6tevT05ODuvWreOxxx5j6dKlNG3alH379pX73KtWrWLt2rVFS+1MnjyZJk2a8M0339C9e3cGDx5MQUEBo0aNKop337591KpVixEjRjB16lTGjh3LggULSE1NpVkl9ULQG1uRGmL48E5s2zaWd97pzbZtY5XUVgGVOfZ5yJAhJCUlAZCVlcWQIUM499xzufPOO1m3bl2J51x55ZXUq1ePpk2bcsopp/DZZ599q0y3bt1o2bIltWrVokuXLmzbto2NGzdy+umnFzWIR5PYLl++nIyMDJo1a0bt2rUZPnw4S5Ys4fTTT2fLli38+Mc/5u233+bEE08EoHPnzgwfPpw//elPCdVdSkREjk11aDt79OhxzG3noUOHmDt3LldffTUnnngiPXv2ZN68eQC88847jBkzBoCkpCQaNWrEO++8w5AhQ2jatCkATZo0Kfe5e/ToccT6sRMmTCA1NZVevXqxY8cOPv74Y5YtW8bFF19cVK7wujfddBNTpkwBgoT4xhtvLPd+FUWJrYhInJQ2xjkWY58bNGhQ9PnnP/85ffr0Ye3atcyZM4cDBw6UeE69evWKPiclJZGXl/etMnXr1i23TEVo3Lgxq1evJiMjg+eee45bbrkFgDfffJMf/ehHrFq1iu7du8fs/iIiUjVUh7YzmjKlmTdvHvv376dTp060bduWv/3tb0d0R45W7dq1iyaeKigoOGKSrMjnzszMZMGCBbz33nusXr2atLS0Up8doFWrVjRv3px33nmH999/n8svv/yoYztWSmxFROIkXmOfs7KyaNGiBQAvvfRShV//7LPPZsuWLWzbtg2AV199Nepze/ToweLFi9mzZw/5+flMmzaN3r17s2fPHgoKChg8eDCPPfYYq1atoqCggB07dtCnTx9+8YtfkJWVRU5OToU/j4iIVB01ve2cNm0aL7zwAtu2bWPbtm1s3bqV+fPnk5ubS9++fXk27N6en59PVlYWl1xyCTNmzGDv3r0ARV2R27Zty8qVKwGYPXs2hw8fLvF+WVlZNG7cmPr167Nx40aWLVsGQK9evViyZAlbt2494roAt9xyCyNGjDjijXdlUGIrIhInw4d3YtKk79GmTSPMoE2bRkya9L2YdxO/9957+elPf0paWlpM3nCecMIJ/O53v6Nfv35069aNlJQUGjUq+Zv0hQsX0rJly6Kfbdu2MX78ePr06UNqairdunVjwIAB7Nq1i4yMDLp06cKIESN44oknyM/PZ8SIEXTq1Im0tDTuuOMOTjrppAp/HhERqTpqctuZm5vL22+/zZVXXlm0r0GDBlx44YXMmTOHp59+mkWLFtGrVy+6devG+vXr6dixIw888AC9e/cmNTWVu+66C4BRo0axePFiUlNTee+99454SxupX79+5OXl0b59e8aNG0evXr0AaNasGZMmTWLQoEGkpqZy7bXXFp3Tv39/cnJyKrUbMoAVzsKV6NLT033FihXxDiNmCmdQk7KpnsqnOorOsdbThg0baN++fcUHVEVlZ2eTkpLyrf05OTk0bNgQd+dHP/oRZ555JnfeeWccIoxOSb83M1vp7uWv4ZBgzKwf8DSQBLzg7uOLHW8DTAaaAfuAEe6+08z6AL+OKHoOMNTdZ5V2L7XNAqqnaNT0Ooq27SytzakuKqrtjHc9rVixgjvvvJN33333uK5ztG2z3tiKiEiFe/755+nSpQsdO3YkKyuLW2+9Nd4hCWBmScAzwOVAB2CYmXUoVuwpYIq7dwYeAZ4AcPdF7t7F3bsAlwC5wF8rLXgRkWquOrSd48ePZ/DgwTzxxBOVfm9NISkiIhXuzjvvrNJvaGuwHsBmd98CYGbTgQHA+ogyHYC7ws+LgJLeyF4DvOXuuTGMVUSkRqkObee4ceMYN25cXO6txFZERKTmaAHsiNjeCfQsVmY1MIigu/JAIMXMTnb3vRFlhgK/KukGZjYaGA3QvHlzMjMzKybyKignJ6daP19FUT2Vr6bXUaNGjcjOzi63XH5+flTlarrqUk8HDhw4qv8vlNiKiIhIpLuBiWY2ElgC7ALyCw+a2alAJ2BeSSe7+yRgEgRjbKvzuMGaPi4yWqqn8tX0OtqwYUNUY0LjPXY0UVSXekpOTiYtLS3q8kpsRUREao5dQKuI7ZbhviLuvpvgjS1m1hAY7O77I4p8H3jD3UteG0JERCQONHmUiIhIzbEcONPM2plZXYIuxbMjC5hZUzMr/PfBTwlmSI40DJgW80hFRESOQkwTWzPrZ2abzGyzmX1rFLGZ3WVm681sjZktDJcYKDzW2sz+amYbwjJtYxmriEh10KdPH+bNO7KH6G9+8xvGjBlT6jkZGRkULslyxRVXsH///m+Vefjhh3nqqafKvPesWbNYv/4/cxA9+OCDLFiw4GjCL1FmZiZXXXXVcV9HwN3zgNsJuhFvAF5z93Vm9oiZ9Q+LZQCbzOyfQHPg8cLzw7a4FbC4EsMWEYmp6th2Fho7diwtWrSgoKCgwq5ZVcUssY1ySYEPgPRwSYGZwJMRx6YAv3T39gSzOH4eq1hFROLpwOef8/dhwzjwxRfHfa1hw4Yxffr0I/ZNnz6dYcOGRXX+3LlzOemkk47p3sUb50ceeYRLL730mK4lsePuc939LHf/L3d/PNz3oLvPDj/PdPczwzK3uPvBiHO3uXsLd6/+/0ISkSpNbWf5CgoKeOONN2jVqhWLF8fu+8i8vLyYXftoxPKNbdGSAu5+CChcUqBIuCZe4VIBywjG+hAmwLXdfX5YLkdLCohIdfXPiRPZt3w5//ztb4/7Wtdccw1vvvkmhw4dAmDbtm3s3r2biy66iDFjxpCenk7Hjh156KGHSjy/bdu27NmzB4DHH3+cs846iwsvvJBNmzYVlXn++efp3r07qampjBgxgtzcXJYuXcrs2bO555576NKlC//6178YOXIkM2fOBGDhwoWkpaXRqVMnbrrpJg4ePFh0v4ceeoiuXbvSqVMnNm7cGPWzTps2jU6dOnHuuedy3333AcFMkCNHjuTcc8+lU6dO/PrXvwZgwoQJdOjQgc6dOzN06NCjrFUREalqErntHDx4cKW0nZmZmXTs2JExY8Ywbdp/RpB89tlnDBw4kNTUVFJTU1m6dCkAU6ZMoXPnzqSmpnL99dcDHBEPQMOGDYuufdFFF9G/f386dAjeXV599dV069aNjh07MmnSpKJz3n77bbp27Upqaip9+/aloKCAM888ky/CLyUKCgo444wziraPVSwnj4pmSYFINwNvhZ/PAvab2etAO2ABMM7d80s7WUSkqln76KN8tWFDqcf3vv8+uBdtb586le1Tp4IZJ/foUeI5J7Zvz7k//3mp12zSpAk9evTgrbfeYsCAAUyfPp3vf//7mBmPP/44TZo0IT8/n759+7JmzRo6d+5c4nVWrlzJ9OnT+fDDD8nLy6Nr165069YNgEGDBjFq1CgA7rnnHl588UV+/OMf079/f6666iquueaaI6514MABRo4cycKFCznrrLP4wQ9+wLPPPsvYsWMBaNq0KatWreJ3v/sdTz31FC+88EKpz1do9+7d3HfffaxcuZLGjRtz2WWXMWvWLFq1asWuXbtYu3YtQFHXsPHjx7N161bq1atXYncxERGpGspqO/Py8shatSrh286f/exnldJ2Tps2jWHDhjFgwADuv/9+Dh8+TJ06dbjjjjvo3bs3b7zxBvn5+eTk5LBu3Toee+wxli5dStOmTdm3b1+p9VVo1apVrF27lnbt2gEwefJkmjRpwjfffEP37t0ZPHgwBQUFjBo1iiVLltCuXTv27dtHrVq1GDFiBFOnTmXs2LEsWLCA1NRUmjVrVu49y1IlZkU2sxFAOtA73FUbuAhIAz4BXgVGAi8WO09r5ckRVE/lUx1F51jrKXItvkOHDpXZPSelUycO7NjB4f37g0bajDonnURyq1alnnfo0KFy1yqndksAACAASURBVKa7+uqrefnll7nkkkt45ZVXmDhxItnZ2UyZMoWXXnqJvLw8/v3vf7Ny5UratWtHfn4+X3/9NdnZ2bg7OTk5zJ8/nyuuuIL8/HzMjH79+nHw4EGys7N5//33efTRR8nKyiInJ4dLL72U7OxsDh8+zDfffFMUX+H2qlWraN26NaeeeirZ2dkMGTKE559/nptvvhl357LLLiM7O5tzzjmHGTNmfOv5cnNzycvLO2L/kiVLuOCCC0hOTuabb75h8ODBLFiwgHvvvZfNmzdz66238t3vfpe+ffuSnZ1Nhw4duPbaa7nyyiu56qqrSEpKOuIeR7tWnoiIxEfjLl34+pNPOPTll1BQALVqUbdxYxq0bn1c1y3sjlyY2L74YpB2vPbaa0yaNIm8vDw+/fRT1q9fX2pi++677zJw4EDq168PQP/+/YuOrV27lp/97Gfs37+fnJwcvvvd75YZz6ZNm2jXrh1nnXUWADfccAPPPPNMUWI7aNAgALp168brr7/+rfMPHTrE3Llz+dWvfkVKSgo9e/Zk3rx5XHXVVbzzzjtMmTIFgKSkJBo1asSUKVMYMmQITZs2BYJkvzw9evQoSmoh6B31xhtvALBjxw4+/vhjvvjiCy6++OKicoXXvemmmxgwYABjx45l8uTJ3HjjjeXerzyxTGzLXVIAwMwuBR4AekeM49kJfOjuW8Iys4BeFEtstVaeFKd6Kp/qKDrHWk+Ra/F1ffTRcsuv+fnP2T5tGrXq1aPg0CFOu+IKOj/yyFHfN9LQoUO5//77+fjjjzlw4AAXX3wxW7duZeLEiSxfvpzGjRszcuRIzIyUlBSSkpJo0KABKSkpmBkNGzYkOTmZevXqFT1L3bp1i7Z/+MMfMmvWLFJTU3nuuedYtmwZKSkp1KlThxNOOKHonMLtBg0akJSUVLS/fv361K5du+h+J598MikpKZx44om4+7fW3ossX+iEE06gTp06RfuSk5OpW7curVu35qOPPmLevHlMmTKFv/zlL0yePJl58+axZMkS5syZw69+9Ss++ugjatf+TxN4tGvliYhIbJT1ZrVwfdbibeep/fodd9s5YMAA7rzzTlatWkVubi7dunVj69atPPXUU0e0nQcOHDim648cObKo7XzppZeO+8vUevXqAUFiWtKX4fPmzWP//v106tQJCL4kPuGEE456MsbatWsXTTxVUFBQ1F0boEGDBkWfMzMzWbBgAe+99x7169cnIyOjzLpq1aoVzZs355133uH9999n6tSpRxVXSWI5xjaaJQXSgN8D/d3982LnnmRmhe+jLwHWIyJSzRzcs4c2113HhX/+M22uu46DFTAJRsOGDenTpw833XRT0cQXX331FQ0aNKBRo0Z89tlnvPXWW2Ve4+KLL2bWrFlFb2DnzJlTdCw7O5tTTz2Vw4cP89prrxXtT0lJKfFt8tlnn822bdvYvHkzAC+//DK9e/f+Vrmj0aNHDxYvXsyePXvIz89n2rRp9O7dmz179lBQUMDgwYN57LHHWLVqFQUFBezYsYM+ffrwi1/8ouhNs4iIJKZEbzsjk7hYtZ3Tpk3jhRdeYNu2bWzbto2tW7cyf/58cnNz6du3L88++ywQzE2RlZXFJZdcwowZM9i7dy9AUVfktm3bsnLlSgBmz57N4cMlL2GelZVF48aNqV+/Phs3bmTZsmUA9OrViyVLlrB169Yjrgtwyy23MGLECIYMGfKtnlTHImZvbN09z8wKlxRIAiYXLikArAhnX/wl0BCYYWYAn7h7f3fPN7O7gYUWHFgJPB+rWEVE4qV72LAAx/1tc6Rhw4YxcODAolkeU1NTSUtL45xzzqFVq1ZccMEFZZ7ftWtXrr32WlJTUznllFPo3r170bFHH32Unj170qxZM9LS0oomsxg6dCijRo1iwoQJR0w0kZyczB/+8AeGDBlCXl4e3bt357bbbjuq51m4cCEtW7Ys2p4xYwbjx4+nT58+uDtXXnklAwYMYPXq1dx4441F3y4/8cQT5OfnM2LECLKysnB37rjjjmOevVJEROIv0dvOnj17FiWzsWg7c3Nzefvtt3nuueeK9jVo0IALL7yQOXPm8PTTTzN69GhefPFFkpKSePbZZznvvPN44IEH6N27N0lJSaSlpfHSSy8xatQoBgwYQGpqKv369TviLW2kfv368dxzz9G+fXvOPvtsevXqBUCzZs2YNGkSgwYNoqCggFNOOYX58+cDQVftG2+8sUK6IQOYRwy+TmTp6eleuJZUdaTuo9FRPZVPdRSd4+mK3L59+4oPqIoq7BaW6Er6vZnZSndPj1NI1YLaZgHVUzRqeh1F23ZWlzYn1hKlnlasWMGdd97Ju+++W+Lxo22bq8TkUSIiIiIiIlIzjB8/nmeffbZCxtYWiuUYWxEREREREZEjjBs3ju3bt3PhhRdW2DWV2IqIVLDqMsSjptDvS0Qk/vR3sUQ6lj8PSmxFRCpQcnIye/fuVQOdINydvXv3kpycHO9QRERqLLWdEulY22aNsRURqUAtW7Zk586dfFEBSw8kggMHDiR8UpicnHzEjMsiIlK5om07q0ObUxmqQz0dS9usxFZEpALVqVOHdu3axTuMSpOZmUlaWlq8wxARkQQWbdupNic6NbWe1BVZREREREREEpoSWxEREREREUloSmxFREREREQkoSmxFRERERERkYSmxFZEREREREQSmhJbERERERERSWhKbEVERERERCShKbEVERERERGRhKbEVkREpAYxs35mtsnMNpvZuBKOtzGzhWa2xswyzaxlxLHWZvZXM9tgZuvNrG1lxi4iIlIaJbYiIiI1hJklAc8AlwMdgGFm1qFYsaeAKe7eGXgEeCLi2BTgl+7eHugBfB77qEVERMqnxFZERKTm6AFsdvct7n4ImA4MKFamA/BO+HlR4fEwAa7t7vMB3D3H3XMrJ2wREZGy1Y53ACIiIlJpWgA7IrZ3Aj2LlVkNDAKeBgYCKWZ2MnAWsN/MXgfaAQuAce6eH3mymY0GRgM0b96czMzMGDxG1ZCTk1Otn6+iqJ7KpzqKjuopOjW1nmKa2JpZP4KGMQl4wd3HFzt+F3ALkAd8Adzk7tsjjp8IrAdmufvtsYxVREREALgbmGhmI4ElwC4gn+DfDBcBacAnwKvASODFyJPdfRIwCSA9Pd0zMjIqKezKl5mZSXV+voqieiqf6ig6qqfo1NR6illX5CjH8XwApIfjeGYCTxY7/ihBoyoiIiLHbxfQKmK7ZbiviLvvdvdB7p4GPBDu20/wdvfDsBtzHjAL6Fo5YYuIiJQtlmNsyx3H4+6LIsbnLCNoYAEws25Ac+CvMYxRRESkJlkOnGlm7cysLjAUmB1ZwMyamlnhvw9+CkyOOPckM2sWbl9C0KtKREQk7mLZFTmacTyRbgbeAggb1P8HjAAuLe0EjeOR4lRP5VMdRUf1FB3VU2Jx9zwzux2YRzBMaLK7rzOzR4AV7j4byACeMDMn6DX1o/DcfDO7G1hoZgasBJ6Px3OIiIgUVyUmjzKzEUA60Dvc9UNgrrvvDNrOkmkcjxSneiqf6ig6qqfoqJ4Sj7vPBeYW2/dgxOeZBMODSjp3PtA5pgGKiIgcg1gmtuWO4wEws0sJxvD0dveD4e7zgIvM7IdAQ6CumeW4+7cWkhcREREREZGaLZaJbdE4HoKEdihwXWQBM0sDfg/0c/eiRd7dfXhEmZEEE0wpqRUREREREZFvidnkUeGMiYXjeDYArxWO4zGz/mGxXxK8kZ1hZh+a2exSLiciIiIiIiJSopiOsY1iHE+pE0NFlHkJeKmiYxMREREREZHqIZbL/YiIiIiIiIjEnBJbERERERERSWhKbEVERERERCShKbEVERERERGRhKbEVkRERERERBKaElsRERERERFJaEpsRUREREREJKEpsRUREREREZGEpsRWREREREREEpoSWxEREREREUloSmxFREREREQkoSmxFRERERERkYSmxFZEREREREQSmhJbERERERERSWhKbEVERERERCShKbEVERERERGRhKbEVkRERERERBJaTBNbM+tnZpvMbLOZjSvh+F1mtt7M1pjZQjNrE+7vYmbvmdm68Ni1sYxTRESkpoiibW4TtslrzCzTzFpGHMs3sw/Dn9mVG7mIiEjpYpbYmlkS8AxwOdABGGZmHYoV+wBId/fOwEzgyXB/LvADd+8I9AN+Y2YnxSpWERGRmiDKtvkpYErYNj8CPBFx7Bt37xL+9K+UoEVERKIQyze2PYDN7r7F3Q8B04EBkQXcfZG754aby4CW4f5/uvvH4efdwOdAsxjGKiIiUhOU2zYTJLzvhJ8XlXBcRESkyqkdw2u3AHZEbO8EepZR/mbgreI7zawHUBf4VwnHRgOjAZo3b05mZuZxhFu15eTkVOvnqyiqp/KpjqKjeoqO6inhRNM2rwYGAU8DA4EUMzvZ3fcCyWa2AsgDxrv7rEqIWUREpFyxTGyjZmYjgHSgd7H9pwIvAze4e0Hx89x9EjAJID093TMyMmIfbJxkZmZSnZ+voqieyqc6io7qKTqqp2rpbmCimY0ElgC7gPzwWBt332VmpwPvmNlH7n7EF8/60lmKUz2VT3UUHdVTdGpqPcUysd0FtIrYbhnuO4KZXQo8APR294MR+08E3gQecPdlMYxTRESkpii3bQ6HAA0CMLOGwGB33x8e2xX+d4uZZQJpFOtRpS+dpTjVU/lUR9FRPUWnptZTLMfYLgfONLN2ZlYXGAocMYOimaUBvwf6u/vnEfvrAm8QTF4xM4YxioiI1CTRtM1Nzazw3wc/BSaH+xubWb3CMsAFwPpKi1xERKQMMUts3T0PuB2YB2wAXnP3dWb2iJkVzqT4S6AhMKPY0gHfBy4GRkYsK9AlVrGKiIjUBFG2zRnAJjP7J9AceDzc3x5YYWarCSaVGu/uSmxFRKRKiOkYW3efC8wttu/BiM+XlnLen4A/xTI2ERGRmiiKtnkmwRJ8xc9bCnSKeYAiIiLHIJZdkUVERERERERiTomtiIiIiIiIJDQltiIiIgnGzL4XMcGTiIhIjadGUUREJPFcC3xsZk+a2TnxDkZERCTelNiKiIgkGHcfwX/WkH3JzN4zs9FmlhLn0EREROJCia2IiEgCcvevCGYvng6cCgwEVpnZj+MamIiISBwosRUREUkwZtbfzN4AMoE6QA93vxxIBX4Sz9hERETiIabr2IqIiEhMDAZ+7e5LIne6e66Z3RynmEREROJGia2IiEjieRj4tHDDzE4Amrv7NndfGLeoRERE4kRdkUVERBLPDKAgYjs/3CciIlIjKbEVERFJPLXd/VDhRvi5bhzjERERiSsltiIiIonnCzPrX7hhZgOAPXGMR0REJK40xlZERCTx3AZMNbOJgAE7gB/ENyQREZH4UWIrIiKSYNz9X0AvM2sYbufEOSQREZG4iiqxNbMGwDfuXmBmZwHnAG+5++GYRiciIiIlMrMrgY5AspkB4O6PxDUoERGROIl2jO0SgoazBfBX4HrgpVgFJSIiIqUzs+eAa4EfE3RFHgK0iWtQIiIicRRtYmvungsMAn7n7kMIviUWERGRyne+u/8A+NLd/wc4DzgrzjGJiIjETdSJrZmdBwwH3gz3JUVxUj8z22Rmm81sXAnH7zKz9Wa2xswWmlmbiGM3mNnH4c8NUcYpIiJSExwI/5trZqcBh4FT4xiPiIhIXEWb2I4Ffgq84e7rzOx0YFFZJ5hZEvAMcDnQARhmZh2KFfsASHf3zsBM4Mnw3CbAQ0BPoAfwkJk1jjJWERGR6m6OmZ0E/BJYBWwDXolrRCIiInEU1eRR7r4YWAxgZrWAPe5+Rzmn9QA2u/uW8LzpwABgfcR1I5PjZcCI8PN3gfnuvi88dz7QD5gWTbwiIiLVVdgOL3T3/cCfzewvQLK7Z8U5NBERkbiJdlbkVwjWzMsHlgMnmtnT7v7LMk5rQbCuXqGdBG9gS3Mz8FYZ57YoIa7RwGiA5s2bk5mZWfaDJLCcnJxq/XwVRfVUPtVRdFRP0VE9Vb5whYJngLRw+yBwML5RiYiIxFe069h2cPevzGw4QfI5DlhJ0AXquJnZCCAd6H0057n7JGASQHp6umdkZFREOFVSZmYm1fn5KorqqXyqo+ionqKjeoqbhWY2GHjd3T3ewYiIiMRbtGNs65hZHeBqYHa4fm15DekuoFXEdstw3xHM7FLgAaB/+K1z1OeKiIjUULcCM4CDZvaVmWWb2VfRnBjFxI5twgkd15hZppm1LHb8RDPbaWYTK+ZRREREjl+0ie3vCSamaAAsCWcvLq8BXQ6caWbtzKwuMBSYHVnAzNLCa/d3988jDs0DLjOzxuGkUZeF+0RERGo8d09x91ruXtfdTwy3TyzvvCgndnwKmBJO7PgI8ESx448SrG8vIiJSZUQ7edQEYELEru1m1qecc/LM7HaChDQJmBzOqPwIsMLdZxN0ZW4IzDAzgE/cvb+77zOzRwmSY4BHCieSEhERqenM7OKS9rt7eQlnuRM7EiS8d4WfFwGzIu7bDWgOvE0whEhERKRKiHbyqEYEy+8UNqSLCb7FLXMGRnefC8wttu/BiM+XlnHuZGByNPGJiIjUMPdEfE4mSFhXApeUc140EzuuBgYBTwMDgRQzOxn4Evh/BCsYlNp+a2JHKU71VD7VUXRUT9GpqfUU7eRRk4G1wPfD7euBPxA0fCIiIlKJ3P17kdtm1gr4TQVd/m5gopmNJOhyvItgVYQfAnPdfWfYy6q02DSxoxxB9VQ+1VF0VE/Rqan1FG1i+1/uPjhi+3/M7MNYBCQiIiJHbSfQPopy5U7O6O67Cb+4NrOGwGB3329m5wEXmdkPCYYR1TWzHHf/1gRUIiIilS3axPYbM7vQ3f8GYGYXAN/ELiwREREpjZn9lv+sTlAL6AKsiuLUookdCRLaocB1xa7dFNjn7gXATwmHBbn78IgyI4F0JbUiIlJVRJvY3gZMCcfaQjDO5obYhCQiIiLlWBHxOQ+Y5u5/L++kKCd2zACeMDMn6Ir8owqPXkREpIJFOyvyaiDVzE4Mt78ys7HAmlgGJyIiIiWaCRxw93wIlvExs/runlveiVFM7DgzvH5Z13gJeOnowxYREYmNaNexBYKE1t0L16+9q8zCIiIiEisLgRMitk8AFsQpFhERkbg7qsS2mNKnRBQREZFYSnb3nMKN8HP9OMYjIiISV8eT2Hr5RURERCQGvjazroUbZtYNTeooIiI1WJljbM0sm5ITWOPILlAiIiJSecYCM8xsN0Gb/B3g2viGJCIiEj9lJrbunlJZgYiIiEh03H25mZ0DnB3u2uTuh+MZk4iISDwdT1dkERERiQMz+xHQwN3XuvtaoKGZ/TDecYmIiMSLElsREZHEM8rd9xduuPuXwKg4xiMiIhJXSmxFREQST5KZFa1OYGZJQN04xiMiIhJXZY6xFRERkSrpbeBVM/t9uH0r8FYc4xEREYkrJbYiIiKJ5z5gNHBbuL2GYGZkERGRGkldkUVERBKMuxcA/wC2AT2AS4AN8YxJREQknvTGVkREJEGY2VnAsPBnD/AqgLv3iWdcIiIi8RbTN7Zm1s/MNpnZZjMbV8Lxi81slZnlmdk1xY49aWbrzGyDmU2InCRDRESkhtpI8Hb2Kne/0N1/C+THOSYREZG4i1liG87Q+AxwOdABGGZmHYoV+wQYCbxS7NzzgQuAzsC5QHegd6xiFRERSRCDgE+BRWb2vJn1BfTFr4iI1HixfGPbA9js7lvc/RAwHRgQWcDdt7n7GqCg2LkOJBMsXVAPqAN8FsNYRUREqjx3n+XuQ4FzgEXAWOAUM3vWzC6Lb3QiIiLxE8sxti2AHRHbO4Ge0Zzo7u+Z2SKCb6UNmOju35oUw8xGE8wKSfPmzcnMzDzemKusnJycav18FUX1VD7VUXRUT9FRPcWHu39N0NvpFTNrDAwhmCn5r3ENTEREJE6q5ORRZnYG0B5oGe6ab2YXufu7keXcfRIwCSA9Pd0zMjIqNc7KlJmZSXV+voqieiqf6ig6qqfoqJ7iz92/JGgLJ8U7FhERkXiJZVfkXUCriO2W4b5oDASWuXuOu+cQLDp/XgXHJyIiIiIiItVALBPb5cCZZtbOzOoCQ4HZUZ77CdDbzGqbWR2CiaO0Pp+IiIiIiIh8S8wSW3fPA24H5hEkpa+5+zoze8TM+gOYWXcz20kwNuj3ZrYuPH0m8C/gI2A1sNrd58QqVhEREREREUlcMR1j6+5zgbnF9j0Y8Xk5/xlHG1kmH7g1lrGJiIiIiIhI9RDLrsgiIiJSxZhZPzPbZGabzWxcCcfbmNlCM1tjZplm1jJi/yoz+9DM1pnZbZUfvYiISMmU2IqIiNQQZpYEPANcDnQAhplZh2LFngKmuHtn4BHgiXD/p8B57t6FYPm+cWZ2WuVELiIiUjYltiIiIjVHD2Czu29x90PAdGBAsTIdgHfCz4sKj7v7IXc/GO6vh/4NISIiVYgaJRERkZqjBbAjYntnuC/SamBQ+HkgkGJmJwOYWSszWxNe4xfuvjvG8YqIiEQlppNHiYiISMK5G5hoZiOBJQRr0OcDuPsOoHPYBXmWmc10988iTzaz0cBogObNm5OZmVmJoVeunJycav18FUX1VD7VUXRUT9GpqfWkxFZERKTm2AW0ithuGe4rEr6FHQRgZg2Bwe6+v3gZM1sLXESwRF/ksUnAJID09HTPyMio4EeoOjIzM6nOz1dRVE/lUx1FR/UUnZpaT+qKLCIiUnMsB840s3ZmVhcYCsyOLGBmTc2s8N8HPwUmh/tbmtkJ4efGwIXApkqLXEREpAxKbEVERGoId88DbgfmARuA19x9nZk9Ymb9w2IZwCYz+yfQHHg83N8e+IeZrQYWA0+5+0eV+gAiIiKlUFdkERGRGsTd5wJzi+17MOLzTIp1Lw73zwc6xzxAERGRY6A3tiIiIiIiIpLQlNiKiIiIiIhIQlNiKyIiIiIiIglNia2IiIiIiIgkNCW2IiIiIiIiktCU2IqIiIiIiEhCU2IrIiIiIiIiCU2JrYiIiIiIiCS0mCa2ZtbPzDaZ2WYzG1fC8YvNbJWZ5ZnZNcWOtTazv5rZBjNbb2ZtYxmriIiIiIiIJKaYJbZmlgQ8A1wOdACGmVmHYsU+AUYCr5RwiSnAL929PdAD+DxWsYqIiIiIiEjiqh3Da/cANrv7FgAzmw4MANYXFnD3beGxgsgTwwS4trvPD8vlxDBOERERERERSWCxTGxbADsitncCPaM89yxgv5m9DrQDFgDj3D0/spCZjQZGAzRv3pzMzMzjjbnKysnJqdbPV1FUT+VTHUVH9RQd1ZOIiIhUBbFMbI9HbeAiII2gu/KrBF2WX4ws5O6TgEkA6enpnpGRUalBVqbMzEyq8/NVFNVT+VRH0VE9RUf1JCIiIlVBLCeP2gW0ithuGe6Lxk7+f3v3HiNXed5x/PuLjQuRQ6DgWBQDpsSR6ghKiCEXCWKZNiGtBAq5AHEbHLW1Gkrbf6hChEQlUivKTSIEpIaoNAWcIoIKguJwkWEhaqF1mnCJQYCxuBhogVBQt05MME//mGM6LGvvsb0zs7Pz/Ugjn3nfc8bPebT2s8+cG9xXVZur6jXgBuC4aY5PkiRJkjQL9LKx3QAsSXJkknnAmcCNu7HtAUkWNO9X0HVtriRJkiRJO/SssW2OtJ4L3Ao8DFxbVRuTXJTkVIAkxyfZAnwa+E6Sjc2224HzgPVJHgQCfLdXsUqSJEmShldPr7GtqnXAugljF3Ytb6BzivJk294OHNPL+CRJkiRJw6+XpyJLkiRJktRzNraSJEmSpKFmYytJkiRJGmo2tpIkSZKkoWZjK0mSJEkaaja2kiSNkCSnJHkkyaYk508yf0SS9UkeSDKWZFEzfmySe5JsbObO6H/0kiRNzsZWkqQRkWQOcBnwcWApcFaSpRNW+wZwZVUdA1wEfKUZ3wp8rqreC5wCXJzkgP5ELknSrtnYSpI0Ok4ANlXV5qp6FbgGOG3COkuBO5rlO3fMV9WjVfVYs/ws8DywoC9RS5I0hbmDDkCSJPXNocDTXe+3AB+YsM79wOnAt4BPAO9IclBV/XzHCklOAOYBj0/8C5KsBlYDLFy4kLGxsemMf0YZHx+f1fs3XczT1MxRO+apnVHNk42tJEnqdh5waZJVwN3AM8D2HZNJDgGuAs6uqtcnblxVlwOXAyxbtqyWL1/eh5AHY2xsjNm8f9PFPE3NHLVjntoZ1TzZ2EqSNDqeAQ7rer+oGXtDc5rx6QBJ5gOfrKqXm/f7AzcDF1TVvX2JWJKkFrzGVpKk0bEBWJLkyCTzgDOBG7tXSHJwkh2/H3wJuKIZnwdcT+fGUtf1MWZJkqZkYytJ0oioqteAc4FbgYeBa6tqY5KLkpzarLYceCTJo8BCYE0z/hngJGBVkvua17H93QNJkibnqciSJI2QqloHrJswdmHX8nXAW47IVtXVwNU9D1CSpD3gEVtJkiRJ0lCzsZUkSZIkDTUbW0mSJEnSUOtpY5vklCSPJNmU5PxJ5k9K8pMkryX51CTz+yfZkuTSXsYpSZIkSRpePWtsk8wBLgM+DiwFzkqydMJqTwGrgO/v5GO+TOfh8JIkSZIkTaqXR2xPADZV1eaqehW4Bjite4WqeqKqHgBen7hxkvfTeczAbT2MUZIkSZI05Hr5uJ9Dgae73m8BPtBmw+bB8N8E/gD4nV2stxpYDbBw4ULGxsb2NNYZb3x8fFbv33QxT1MzR+2Yp3bMkyRJmglm6nNszwHWVdWWJDtdqaouBy4HWLZsWS1fvrw/0Q3A2NgYs3n/pot5mpo5asc8tWOeJEnSTNDLxvYZ4LCu94uasTY+BJyY5BxgPjAvyXhVveUGVJIkSZKk0dbLxnYDsCTJkXQa2jOBz7bZsKpW7lhOsgpYZlMrP6REtwAAC/FJREFUSZIkSZpMz24eVVWvAecCtwIPA9dW1cYkFyU5FSDJ8Um2AJ8GvpNkY6/ikSRJkiTNTj29xraq1gHrJoxd2LW8gc4pyrv6jO8B3+tBeJIkSZKkWaCXj/uRJEmSJKnnbGwlSZIkSUPNxlaSJEmSNNRsbCVJkiRJQ83GVpIkSZI01GxsJUmSJElDzcZWkiRJkjTUbGwlSZIkSUPNxlaSJEmSNNRsbCVJGiFJTknySJJNSc6fZP6IJOuTPJBkLMmirrlbkryc5J/7G7UkSbtmYytJ0ohIMge4DPg4sBQ4K8nSCat9A7iyqo4BLgK+0jX3deAP+xGrJEm7w8ZWkqTRcQKwqao2V9WrwDXAaRPWWQrc0Szf2T1fVeuB/+lHoJIk7Y65gw5AkiT1zaHA013vtwAfmLDO/cDpwLeATwDvSHJQVf28zV+QZDWwGmDhwoWMjY3tbcwz1vj4+Kzev+linqZmjtoxT+2Map5sbCVJUrfzgEuTrALuBp4BtrfduKouBy4HWLZsWS1fvrwHIc4MY2NjzOb9my7maWrmqB3z1M6o5slTkaUR8svnn2frV7/KL194YdChSBqMZ4DDut4vasbeUFXPVtXpVfU+4IJm7OX+hSiNjrVrH2Tx4otZseIuFi++mLVrHxx0SNLQsrGVRsijl17K9sce49Fvf3vQoUgajA3AkiRHJpkHnAnc2L1CkoOT7Pj94EvAFX2OURoJa9c+yOrVN/Hkk69QBU8++QqrV99kcyvtIRtbaQTcvHQpNx11FE+uXQtVPLl2LTcddRQ3L514M1RJs1lVvQacC9wKPAxcW1Ubk1yU5NRmteXAI0keBRYCa3Zsn+RHwA+Ak5NsSfKxvu6ANItccMF6tm791ZvGtm79FRdcsH5AEUnDraeNbYtn5Z2U5CdJXkvyqa7xY5Pck2Rj8xy9M3oZpzTbnTw2xqGnnsqcffcFYM6++3Loaadx8l13DTgySf1WVeuq6j1VdVRVrWnGLqyqG5vl66pqSbPOH1fVtq5tT6yqBVW1X1UtqqpbB7Uf0rB76qlXdmtc0q71rLFt+ay8p4BVwPcnjG8FPldV7wVOAS5OckCvYpVmu33f9S7mzp/P9m3bYJ992L5tG3Pnz2ffBQsGHZokSSPp8MPfuVvjknatl3dFfuNZeQBJdjwr76EdK1TVE83c690bVtWjXcvPJnkeWAB48wppD2178UWO+OxneWHJEhY89hjbvIGUJEkDs2bNyaxefdObTkd++9v3Yc2akwcYlTS8etnYtnlW3pSSnADMAx6fZM5n5elNzNMunHEG/wv8Ynycl1asADBXu+DPUjvmSZL2zMqVRwOda22feuoVDj/8naxZc/Ib45J2z4x+jm2SQ4CrgLOr6vWJ8z4rTxOZp6mZo3bMUzvmSZL23MqVR7Ny5dH+XypNg17ePGrKZ+XtSpL9gZuBC6rq3mmOTZIkSZI0S/SysZ3yWXk706x/PXBlVV3XwxglSZIkSUOuZ41tm2flJTk+yRbg08B3kmxsNv8McBKwKsl9zevYXsUqSZIkSRpePb3GtqrWAesmjF3YtbyBzinKE7e7Gri6l7FJkiRJkmaHXp6KLEmSJElSz6WqBh3DtEjyAvDkoOPooYOBFwcdxBAwT1MzR+2Yp3Zmc56OqKoFgw5imFmb1TBPUzNH7ZindmZznnZam2dNYzvbJflxVS0bdBwznXmamjlqxzy1Y540yvz5b8c8Tc0ctWOe2hnVPHkqsiRJkiRpqNnYSpIkSZKGmo3t8Lh80AEMCfM0NXPUjnlqxzxplPnz3455mpo5asc8tTOSefIaW0mSJEnSUPOIrSRJkiRpqNnYDliSU5I8kmRTkvMnmT8iyfokDyQZS7Koa+7wJLcleTjJQ0kW9zP2ftrLPH0tycYmT5ckSX+j748kVyR5PsnPdjKfZv83NXk6rmvu7CSPNa+z+xd1/+1pnpIcm+Se5mfpgSRn9Dfy/tqbn6dmfv8kW5Jc2p+IpeljbW7H2jw1a3M71uZ2rM1TqCpfA3oBc4DHgd8E5gH3A0snrPMD4OxmeQVwVdfcGPC7zfJ84O2D3qeZlifgw8C/NJ8xB7gHWD7ofepRnk4CjgN+tpP53wN+CAT4IPBvzfivA5ubPw9slg8c9P7MwDy9B1jSLP8G8BxwwKD3Z6blqWv+W8D3gUsHvS++fO3Oy9rc+zxZm980b23euzxZm1vkqWt+Vtdmj9gO1gnApqraXFWvAtcAp01YZylwR7N85475JEuBuVV1O0BVjVfV1v6E3Xd7nCeggH3pFN1fA/YB/qvnEQ9AVd0NvLSLVU4DrqyOe4EDkhwCfAy4vapeqqr/Bm4HTul9xIOxp3mqqker6rHmM54FngcmfUD4bLAXP08keT+wELit95FK087a3I61uQVrczvW5naszbtmYztYhwJPd73f0ox1ux84vVn+BPCOJAfR+Ybq5ST/lOSnSb6eZE7PIx6MPc5TVd1Dp5g+17xuraqHexzvTLWzPLbJ7yiZMh9JTqDzC9njfYxrppk0T0neBnwTOG8gUUl7z9rcjrV5elib27E2tzPStdnGduY7D/hIkp8CHwGeAbYDc4ETm/nj6ZwKtGpAMc4Ek+YpybuB3wIW0fnHviLJiYMLU8Ou+ebzKuDzVfX6oOOZgc4B1lXVlkEHIvWQtbkda7P6wto8pZGozXMHHcCIewY4rOv9ombsDc1pFacDJJkPfLKqXk6yBbivqjY3czfQOZf+7/oReJ/tTZ7+BLi3qsabuR8CHwJ+1I/AZ5id5fEZYPmE8bG+RTXz7PTnLcn+wM3ABc0pPqNsZ3n6EHBiknPoXF84L8l4Vb3lxjLSDGVtbsfaPD2sze1Ym9sZ6drsEdvB2gAsSXJkknnAmcCN3SskObg5fQDgS8AVXdsekGTHdQQrgIf6EPMg7E2enqLzbfHcJPvQ+cZ4VE93uhH4XHPHvA8Cr1TVc8CtwEeTHJjkQOCjzdiomjRPzc/e9XSuXblusCHOCJPmqapWVtXhVbWYztGaK2db4dSsZ21ux9o8PazN7Vib2xnp2uwR2wGqqteSnEvnP6o5wBVVtTHJRcCPq+pGOt/WfSVJAXcDf9Zsuz3JecD6JAH+A/juIPaj1/YmT8B1dH6xeJDOzSpuqaqb+r0P/ZDkH+nk4eDmqMFf07khB1X1t8A6OnfL2wRsBT7fzL2U5Mt0fkkBuKiqdnVjgqG2p3kCPkPnboQHJVnVjK2qqvv6Fnwf7UWepKFmbW7H2tyOtbkda3M71uZdS3Vu/SxJkiRJ0lDyVGRJkiRJ0lCzsZUkSZIkDTUbW0mSJEnSULOxlSRJkiQNNRtbSZIkSdJQs7GVhkyS7Unu63pN23PIkixO8rPp+jxJkkaBtVkaPJ9jKw2fX1TVsYMOQpIkvcHaLA2YR2ylWSLJE0m+luTBJP+e5N3N+OIkdyR5IMn6JIc34wuTXJ/k/ub14eaj5iT5bpKNSW5Lsl+z/l8keaj5nGsGtJuSJA0Na7PUPza20vDZb8LpTmd0zb1SVUcDlwIXN2PfBv6hqo4B1gKXNOOXAHdV1W8DxwEbm/ElwGVV9V7gZeCTzfj5wPuaz/nTXu2cJElDyNosDViqatAxSNoNScarav4k408AK6pqc5J9gP+sqoOSvAgcUlW/asafq6qDk7wALKqqbV2fsRi4vaqWNO+/COxTVX+T5BZgHLgBuKGqxnu8q5IkDQVrszR4HrGVZpfayfLu2Na1vJ3/vxb/94HL6HyDvCGJ1+hLkjQ1a7PUBza20uxyRtef9zTL/wqc2SyvBH7ULK8HvgCQZE6Sd+7sQ5O8DTisqu4Evgi8E3jLN9OSJOktrM1SH/itjjR89ktyX9f7W6pqx2MFDkzyAJ1vds9qxv4c+PskfwW8AHy+Gf9L4PIkf0Tn298vAM/t5O+cA1zdFNgAl1TVy9O2R5IkDTdrszRgXmMrzRLNdTzLqurFQcciSZKszVI/eSqyJEmSJGmoecRWkiRJkjTUPGIrSZIkSRpqNraSJEmSpKFmYytJkiRJGmo2tpIkSZKkoWZjK0mSJEkaaja2kiRJkqSh9n9JtyX4e18EjwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnAGCBMVJBPE",
        "outputId": "5497a08f-6476-40d1-9ed6-9c155ea053ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-8e175f620f5c>:2: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "312/312 [==============================] - 36s 115ms/step - loss: 0.1132 - acc: 0.9780\n",
            "Training data  -> loss: 0.113, acc: 0.978\n",
            "156/156 [==============================] - 18s 115ms/step - loss: 0.1226 - acc: 0.9736\n",
            "Cross-val data -> loss: 0.123, acc: 0.974\n",
            "62/62 [==============================] - 7s 116ms/step - loss: 0.1083 - acc: 0.9819\n",
            "Testing data   -> loss: 0.108, acc: 0.982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCBCwktuJBPG"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/파일명.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/파일명.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "save_keras_model(model, '파일명', MODEL_SAVE_DIR)\n",
        "del vgg_base\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiKWhwVE2Utm"
      },
      "source": [
        "# 기본 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZYbVmb_BnCv"
      },
      "source": [
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "vgg_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7liCfyfuCCwC"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(my_model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0e9SrkM2kwu"
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = relu\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.50),        \n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "# for layer in model.layers:\n",
        "#     if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      # layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='binary_crossentropy',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq_UdcKD2kwy"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrWUlGFk2YUG"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBVRlLmn2YUI"
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agbd40QM2YUK"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1sX3BhEUE9"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_history.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "kru.save_keras_model(model, 'cats_vs_dogs_vgg16', MODEL_SAVE_DIR)\n",
        "del vgg_base\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGe8s3rwJySW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-3yx8um7usX"
      },
      "source": [
        "# mse 인 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5fgtKwO79qJ"
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = relu\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.50),        \n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "# for layer in model.layers:\n",
        "#     if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      # layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='mse',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo_otoFV79qN"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiD-J7-I79qP"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLU_aOTk79qQ"
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mWRhVLU79qS"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "099XRSSYFJnv"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_mse_history.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_mse_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "kru.save_keras_model(model, 'cats_vs_dogs_vgg16_mse', MODEL_SAVE_DIR)\n",
        "del model, vgg_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voZTC5W_8dVq"
      },
      "source": [
        "# 활성함수가 sigmoid 이며 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDjG0kwE8dVr"
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.50),        \n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='binary_crossentropy',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otZ2ft-V8dVu"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S98GxzEA8dVw"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InSvEYEK8dVz"
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Ix6bBk8dV1"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0l3JzHjFayq"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_sig_history.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_sig_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "kru.save_keras_model(model, 'cats_vs_dogs_vgg16_sig', MODEL_SAVE_DIR)\n",
        "del model, vgg_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbCMhPkxhezL"
      },
      "source": [
        "# 활성함수가 sigmoid이며 mse 인 vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAZMrJonrkYp"
      },
      "source": [
        "from keras.activations import softmax, relu, sigmoid\n",
        " \n",
        "vgg_base = keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
        "alpha = 0.00002  # weight decay coefficient\n",
        "for layer in vgg_base.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias)\n",
        "    \n",
        "model = tf.keras.models.Sequential([\n",
        "        vgg_base,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.50),        \n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.20),        \n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),         \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "vgg_base.trainable = False\n",
        "# model_vgg16.layers[-1].activation=None\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "      # layer.add_loss(keras.regularizers.l2(alpha)(layer.kernel))\n",
        "      layer.activation = sigmoid\n",
        "    # if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
        "    #   layer.add_loss(keras.regularizers.l2(alpha)(layer.bias))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999),\n",
        "                  loss='mse',#mse, binary_crossentropy\n",
        "                  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC95Tb90tQ20"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Pw9I-Za6My"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=eval_generator,\n",
        "    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBQkhHKHQ3i4"
      },
      "source": [
        "kru.show_plots(hist.history, plot_title='Using VGG16 model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSXUGOLZ81OS"
      },
      "source": [
        "# 성능 평가\n",
        "loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1)\n",
        "print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(eval_generator, steps=val_steps, verbose=1)\n",
        "print('Cross-val data -> loss: %.3f, acc: %.3f' % (loss, acc))\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n",
        "print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr5uGiowFjTy"
      },
      "source": [
        "import pickle\n",
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(hist.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_sig_mse_history.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = MODEL_SAVE_DIR +'/cats_vs_dogs_vgg16_sig_mse_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "\n",
        "kru.save_keras_model(model, 'cats_vs_dogs_vgg16_sig_mse', MODEL_SAVE_DIR)\n",
        "del model, vgg_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INnkCGVPbwnY"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWyKAB-Hbxnj"
      },
      "source": [
        "# cats_vs_dogs_vgg16\n",
        "# cats_vs_dogs_vgg16_mse\n",
        "# cats_vs_dogs_vgg16_sig\n",
        "# cats_vs_dogs_vgg16_sig_mse\n",
        "model = kru.load_keras_model('cats_vs_dogs_vgg16',MODEL_SAVE_DIR)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKPm-D0ycOgN"
      },
      "source": [
        "cat_test_files = np.array(os.listdir(test_root_cat))\n",
        "dog_test_files = np.array(os.listdir(test_root_dog))\n",
        "# for _ in range(5): indexes = np.random.permutation(range(len(cat_test_files)))\n",
        "# cat_test_files = cat_test_files[indexes]\n",
        "# dog_test_files = dog_test_files[indexes]\n",
        "for _ in range(5):\n",
        "    np.random.shuffle(cat_test_files)\n",
        "    np.random.shuffle(dog_test_files)\n",
        " \n",
        "test_image_files = []\n",
        "for image in cat_test_files:\n",
        "    test_image_files.append(os.path.join(test_root_cat, image))\n",
        "for image in dog_test_files:\n",
        "    test_image_files.append(os.path.join(test_root_dog, image))\n",
        "test_image_files = np.array(test_image_files)\n",
        "for _ in range(5): indexes = np.random.permutation(range(len(test_image_files)))\n",
        "test_image_files = test_image_files[indexes]\n",
        "test_image_files[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMgkbfDLcPUo"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from tqdm import tqdm\n",
        "predictions = []   # list of tuples (image_path, probab, pred_name, act_name)\n",
        "incorrect_predictions = []  # list of tuples (image_path, probab, actual, prediction)\n",
        " \n",
        "for test_image in tqdm(test_image_files):\n",
        "    img = image.load_img(test_image, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x /= 255.0\n",
        " \n",
        "    images_list = np.vstack([x])\n",
        "    classes = model_xfer.predict(images_list, batch_size=10)\n",
        "    prob = classes[0]\n",
        "    actual_name = (test_image.split(os.path.sep)[-1].split('.')[0]).upper() # == 'CAT' or 'DOG'\n",
        "    pred_name = 'DOG' if (prob >= 0.5) else 'CAT'\n",
        "    is_correct = (actual_name == pred_name)\n",
        "    \n",
        "    predictions.append((test_image, prob, pred_name, actual_name))\n",
        "    if not is_correct:\n",
        "        incorrect_predictions.append((test_image, prob, pred_name, actual_name))\n",
        "    \n",
        "    \n",
        "print(\"Displaying %d incorrect predictions...\" % len(incorrect_predictions))    \n",
        "for item in incorrect_predictions:\n",
        "    test_image, prob, pred_name, actual_name = item\n",
        "    print('%*s - probability: %.4f - predicted %s, is a %s' %\n",
        "            (50, test_image, prob, pred_name, actual_name))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}