{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hugginface_models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WftdTF6WiQis",
        "7SMV28mAkQap",
        "h_U3uMySBCIV",
        "XgjMzosCDD35",
        "U7SzL1IBe1Dm",
        "FK-T-NuCG96f"
      ],
      "authorship_tag": "ABX9TyNosqh0ZMh42JO50VFINF+R"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e74540e258904358b5f8a1c27676833d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_67aa2603abe44faab44baed5368b2112",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b55d911bc1444a8ba5992520201a354",
              "IPY_MODEL_7af638a6bc754334ae06e71c0dc6193f"
            ]
          }
        },
        "67aa2603abe44faab44baed5368b2112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b55d911bc1444a8ba5992520201a354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_859bb118b71c48a79e8726c1650296d0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8545df797f9b4b9a9480330091214be5"
          }
        },
        "7af638a6bc754334ae06e71c0dc6193f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa6fc599579e40ba8dce87698e09e7fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:00&lt;00:00, 2.79kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f87e6045a11e4549a58954f1fdc2f349"
          }
        },
        "859bb118b71c48a79e8726c1650296d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8545df797f9b4b9a9480330091214be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa6fc599579e40ba8dce87698e09e7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f87e6045a11e4549a58954f1fdc2f349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0a3c61a56374d48a5365eaec3d277b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ccf9059c9a904eb48b07b1ea76865aa2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7fa22c0a052141f7b28437ac02c2d069",
              "IPY_MODEL_ec8b16cdab4745dcaae3dd29dbcc7c04"
            ]
          }
        },
        "ccf9059c9a904eb48b07b1ea76865aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7fa22c0a052141f7b28437ac02c2d069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f0ac0ed562c498bb3658ee5f15740fa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48f12a46bcee4100aed8e0b1e70f716d"
          }
        },
        "ec8b16cdab4745dcaae3dd29dbcc7c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85abee2c1e344db49070f7eb62640cf9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.12G/1.12G [00:55&lt;00:00, 20.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd0d79ef3a7b417fb82143838ce96343"
          }
        },
        "6f0ac0ed562c498bb3658ee5f15740fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48f12a46bcee4100aed8e0b1e70f716d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85abee2c1e344db49070f7eb62640cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd0d79ef3a7b417fb82143838ce96343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WftdTF6WiQis"
      },
      "source": [
        "#테스트 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpz0mo2Qh_cE"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, BertModel, TFBertModel\r\n",
        "\r\n",
        "#Tokenizer\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\r\n",
        "\r\n",
        "# pytorch 의 경우 : 모델원본\r\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\r\n",
        "model.cuda()\r\n",
        "\r\n",
        "#모델수정\r\n",
        "config = BertConfig.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True, hidden_dropout_prob=0.8, attention_probs_dropout_prob=0.2\r\n",
        "                                    )\r\n",
        "transformer_model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', config=config)\r\n",
        "transformer_model = BertModel.from_pretrained('bert-base-multilingual-cased', config=config)\r\n",
        "transformer_model.cuda()\r\n",
        "\r\n",
        "#TensorFlow의 경우\r\n",
        "model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\r\n",
        "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\r\n",
        "token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\r\n",
        "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\r\n",
        "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\r\n",
        "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\r\n",
        "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\r\n",
        "bert_outputs = bert_outputs[1]\r\n",
        "sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(bert_outputs)\r\n",
        "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\r\n",
        "import tensorflow_addons as tfa\r\n",
        "opt = tfa.optimizers.RectifiedAdam(lr=1.0e-5, weight_decay=0.0025)\r\n",
        "sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcB2BHasXz6w"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\r\n",
        "from transformers import BertModel, BertConfig\r\n",
        "class CustomBERTModel(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "          super(CustomBERTModel, self).__init__()\r\n",
        "          self.num_labels = 2\r\n",
        "          self.config = BertConfig.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True, \r\n",
        "                                                   hidden_dropout_prob=0.3, attention_probs_dropout_prob=0.3)\r\n",
        "          self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\", config=self.config)\r\n",
        "          ### New layers:\r\n",
        "          self.dropout = nn.Dropout(0.3)\r\n",
        "          self.linear2 = nn.Linear(768, self.num_labels)\r\n",
        "\r\n",
        "    def forward(self, input_ids=None, attention_mask=None,\r\n",
        "                token_type_ids=None, position_ids=None, head_mask=None,\r\n",
        "                inputs_embeds=None, labels=None, output_attentions=None,\r\n",
        "                output_hidden_states=None, return_dict=None,):\r\n",
        "          outputs = self.bert(input_ids, attention_mask=attention_mask,\r\n",
        "                              token_type_ids=token_type_ids, position_ids=position_ids,\r\n",
        "                              head_mask=head_mask,inputs_embeds=inputs_embeds,\r\n",
        "                              output_attentions=output_attentions, output_hidden_states=output_hidden_states,\r\n",
        "                              return_dict=return_dict,)\r\n",
        "          pooled_output = outputs[1]\r\n",
        "          pooled_output = self.dropout(pooled_output)\r\n",
        "          logits = self.linear2(pooled_output)\r\n",
        "\r\n",
        "          loss = None\r\n",
        "          if labels is not None:\r\n",
        "              if self.num_labels == 1:\r\n",
        "                  #  We are doing regression\r\n",
        "                  loss_fct = MSELoss()\r\n",
        "                  loss = loss_fct(logits.view(-1), labels.view(-1))\r\n",
        "              else:\r\n",
        "                  loss_fct = CrossEntropyLoss()\r\n",
        "                  loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\r\n",
        "\r\n",
        "          if not return_dict:\r\n",
        "              output = (logits,) + outputs[2:]\r\n",
        "              return ((loss,) + output) if loss is not None else output\r\n",
        "\r\n",
        "          return logits\r\n",
        "\r\n",
        "model = CustomBERTModel()\r\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUuXD1bgiH5T"
      },
      "source": [
        "가지치기 torch.nn.utils.prune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WytXdQ2wiE62"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn.utils.prune as prune\r\n",
        "parameters_to_prune = ()\r\n",
        "for i in range(12):\r\n",
        "    parameters_to_prune += (\r\n",
        "        (transformer_model.encoder.layer[i].attention.self.key, 'weight'),\r\n",
        "        (transformer_model.encoder.layer[i].attention.self.query, 'weight'),\r\n",
        "        (transformer_model.encoder.layer[i].attention.self.value, 'weight'),\r\n",
        "    )\r\n",
        "\r\n",
        "prune.global_unstructured(\r\n",
        "    parameters_to_prune,\r\n",
        "    pruning_method=prune.L1Unstructured,\r\n",
        "    amount=0.2,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj2khhHXiK59"
      },
      "source": [
        "확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrCzDuFfiJjm"
      },
      "source": [
        "for i in range(12):\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(transformer_model.encoder.layer[i].attention.self.key.weight == 0))\r\n",
        "            / float(transformer_model.encoder.layer[i].attention.self.key.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(transformer_model.encoder.layer[i].attention.self.query.weight == 0))\r\n",
        "            / float(transformer_model.encoder.layer[i].attention.self.query.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(transformer_model.encoder.layer[i].attention.self.value.weight == 0))\r\n",
        "            / float(transformer_model.encoder.layer[i].attention.self.value.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print()\r\n",
        "\r\n",
        "    \r\n",
        "numerator, denominator = 0, 0\r\n",
        "for i in range(12):\r\n",
        "    numerator += torch.sum(transformer_model.encoder.layer[i].attention.self.key.weight == 0)\r\n",
        "    numerator += torch.sum(transformer_model.encoder.layer[i].attention.self.query.weight == 0)\r\n",
        "    numerator += torch.sum(transformer_model.encoder.layer[i].attention.self.value.weight == 0)\r\n",
        "\r\n",
        "    denominator += transformer_model.encoder.layer[i].attention.self.key.weight.nelement()\r\n",
        "    denominator += transformer_model.encoder.layer[i].attention.self.query.weight.nelement()\r\n",
        "    denominator += transformer_model.encoder.layer[i].attention.self.value.weight.nelement()\r\n",
        "    \r\n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7esOrxp-5dyL"
      },
      "source": [
        "# **네이버 영화리뷰 감정분석 with Hugging Face BERT**\r\n",
        "\r\n",
        "BERT(Bidirectional Encoder Representations from Transformers)는 구글이 개발한 사전훈련(pre-training) 모델임.\r\n",
        "\r\n",
        "아래의 Chris McCormick의 블로그를 참조하여 나에 맞게 수정함\r\n",
        "\r\n",
        "< BERT Fine-Tuning Tutorial with PyTorch ><br>\r\n",
        "-> https://mccormickml.com/2019/07/22/BERT-fine-tuning\r\n",
        "<br>\r\n",
        "BERT에 대해서 좀 더 자세한 설명은 박상길님과 Jay Alammar의 블로그를 참조하시기 바랍니다.\r\n",
        "\r\n",
        "< BERT 톺아보기 ><br>\r\n",
        "-> http://docs.likejazz.com/bert/\r\n",
        "\r\n",
        "< The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) ><br>\r\n",
        "-> http://jalammar.github.io/illustrated-bert/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPNP7X89hdwp"
      },
      "source": [
        "# **huggingface model custom**\r\n",
        "\r\n",
        "저자 : 4nchez<br>\r\n",
        "모델 : BERT<br>\r\n",
        "데이터 : nsmc<br>\r\n",
        "필요한 라이브러리(중요한건 bold함)<br>\r\n",
        "-> pandas, numpy, random, time, datetime, **transformers**, **pytorch**, **tensorflw**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SMV28mAkQap"
      },
      "source": [
        "## **Import library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dbcUfZPegh0",
        "outputId": "b68f6620-546d-4e2c-c113-cdbc80335ccc"
      },
      "source": [
        "!pip install transformers sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Using cached https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl\n",
            "Collecting sentencepiece\n",
            "  Using cached https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "  Using cached https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz\n",
            "Collecting tokenizers==0.9.4\n",
            "  Using cached https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=7b143da54dfef2176478a3d716d6c6763d243c5375533f3bf452179bd32b8f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, sentencepiece\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6RpQD_djqvx"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import random, time, datetime\r\n",
        "\r\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, BertModel\r\n",
        "from transformers import XLMRobertaConfig, XLMRobertaModel, XLMRobertaTokenizer\r\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.utils.prune as prune\r\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\r\n",
        "from torch.utils.data import TensorDataset, random_split\r\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_U3uMySBCIV"
      },
      "source": [
        "## **데이터 로드**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImBtAkSyTW1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f66778d-c45a-49ec-f843-f5918a7602e7"
      },
      "source": [
        "# 네이버 영화리뷰 감정분석 데이터 다운로드\n",
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 22.41 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LPEdb2tWfIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1800724c-13ec-40a3-9b29-57d9c0248a55"
      },
      "source": [
        "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
        "train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
        "test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "(50000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cl0j7TZBoeL"
      },
      "source": [
        "훈련셋 150,000개와 테스트셋 50,000개의 데이터가 존재합니다.\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgjMzosCDD35"
      },
      "source": [
        "## **데이터 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNSq6kvPUxFf"
      },
      "source": [
        "**Train_set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud33ybZMI-cG"
      },
      "source": [
        "def Make_sentence(tokenizer, sentences):\r\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\r\n",
        "  input_ids = []\r\n",
        "  attention_masks = []\r\n",
        "\r\n",
        "  # For every sentence...\r\n",
        "  for sent in sentences:\r\n",
        "      # `encode_plus` will:\r\n",
        "      #   (1) Tokenize the sentence.\r\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\r\n",
        "      #   (3) Append the `[SEP]` token to the end.\r\n",
        "      #   (4) Map tokens to their IDs.\r\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\r\n",
        "      #   (6) Create attention masks for [PAD] tokens.\r\n",
        "      encoded_dict = tokenizer.encode_plus(\r\n",
        "                          sent,                      # Sentence to encode.\r\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\r\n",
        "                          max_length = 128,           # Pad & truncate all sentences.\r\n",
        "                          pad_to_max_length = True,\r\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\r\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\r\n",
        "                    )\r\n",
        "      \r\n",
        "      # Add the encoded sentence to the list.    \r\n",
        "      input_ids.append(encoded_dict['input_ids'])\r\n",
        "      \r\n",
        "      # And its attention mask (simply differentiates padding from non-padding).\r\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "      \r\n",
        "  # input_ids = torch.cat(input_ids, dim=0)\r\n",
        "  # attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caCnynD5TjbH"
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\r\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN-LZ3CSL6Ef",
        "outputId": "c9ec0e1d-a970-4106-8931-74a32d673cfa"
      },
      "source": [
        "# print(train.isnull().any())\r\n",
        "# train[train['document'].isnull()]\r\n",
        "print(train.shape)\r\n",
        "print(\"train null value : \" ,train.isnull().sum())\r\n",
        "train_set=train.dropna()\r\n",
        "sentences = train_set['document'].values\r\n",
        "labels = train_set['label'].values\r\n",
        "print(len(sentences))\r\n",
        "print(len(labels))\r\n",
        "\r\n",
        "input_ids, attention_masks = Make_sentence(tokenizer, sentences)\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "# Print sentence 0, now as a list of IDs.\r\n",
        "print('Original: ', sentences[0])\r\n",
        "print('Token IDs:', input_ids[0])\r\n",
        "print('Token IDs:', attention_masks[0])\r\n",
        "print('Labels :', labels[0])\r\n",
        "\r\n",
        "# Combine the training inputs into a TensorDataset.\r\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "\r\n",
        "# Create a 90-10 train-validation split.\r\n",
        "\r\n",
        "# Calculate the number of samples to include in each set.\r\n",
        "train_size = int(0.9 * len(dataset))\r\n",
        "val_size = len(dataset) - train_size\r\n",
        "\r\n",
        "# Divide the dataset by randomly selecting samples.\r\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\r\n",
        "\r\n",
        "print('{:>5,} training samples'.format(train_size))\r\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "train null value :  id          0\n",
            "document    5\n",
            "label       0\n",
            "dtype: int64\n",
            "149995\n",
            "149995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  아 더빙.. 진짜 짜증나네요 목소리\n",
            "Token IDs: tensor([     0,   7159,   6116, 101895,      5,      5, 113621,      6,  74280,\n",
            "         18128,   3497,  25861, 209932,      2,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1])\n",
            "Token IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Labels : tensor(0)\n",
            "134,995 training samples\n",
            "15,000 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz3KrIAqby2Z"
      },
      "source": [
        "**9:1로 나누기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdNOHhUENa92"
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \r\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \r\n",
        "# size of 16 or 32.\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Create the DataLoaders for our training and validation sets.\r\n",
        "# We'll take training samples in random order. \r\n",
        "train_dataloader = DataLoader(\r\n",
        "            train_dataset,  # The training samples.\r\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\r\n",
        "            batch_size = batch_size # Trains with this batch size.\r\n",
        "        )\r\n",
        "\r\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\r\n",
        "validation_dataloader = DataLoader(\r\n",
        "            val_dataset, # The validation samples.\r\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\r\n",
        "            batch_size = batch_size # Evaluate with this batch size.\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yceLyWmmUnuP"
      },
      "source": [
        "**Test_set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AstYEbxsPzOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7869bc-6c48-4455-a4dc-255cccb9c25c"
      },
      "source": [
        "print(test.shape)\r\n",
        "print(test.isnull().sum())\r\n",
        "test_set=test.dropna()\r\n",
        "print(test_set.shape)\r\n",
        "sentences = test_set['document'].values\r\n",
        "labels = test_set['label'].values\r\n",
        "print(len(sentences))\r\n",
        "print(len(labels))\r\n",
        "\r\n",
        "input_ids, attention_masks = Make_sentence(tokenizer, sentences)\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "# Print sentence 0, now as a list of IDs.\r\n",
        "print('Original: ', sentences[0])\r\n",
        "print('Token IDs:', input_ids[0])\r\n",
        "print('Token IDs:', attention_masks[0])\r\n",
        "print('Labels :', labels[0])\r\n",
        "\r\n",
        "# 배치 사이즈\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n",
        "test_data = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3)\n",
            "id          0\n",
            "document    3\n",
            "label       0\n",
            "dtype: int64\n",
            "(49997, 3)\n",
            "49997\n",
            "49997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  굳 ㅋ\n",
            "Token IDs: tensor([     0,      6, 198249,      6, 204615,      2,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1])\n",
            "Token IDs: tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Labels : tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv7fQYah4X-p"
      },
      "source": [
        "## **모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "816M52s44X-q",
        "outputId": "426a1211-a348-4f1f-e139-1c5fcf423f9b"
      },
      "source": [
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q19okEoL4X-q",
        "outputId": "5e29cf7e-4d3b-464a-85c9-75532ca6d9e5"
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e74540e258904358b5f8a1c27676833d",
            "67aa2603abe44faab44baed5368b2112",
            "1b55d911bc1444a8ba5992520201a354",
            "7af638a6bc754334ae06e71c0dc6193f",
            "859bb118b71c48a79e8726c1650296d0",
            "8545df797f9b4b9a9480330091214be5",
            "fa6fc599579e40ba8dce87698e09e7fa",
            "f87e6045a11e4549a58954f1fdc2f349",
            "d0a3c61a56374d48a5365eaec3d277b5",
            "ccf9059c9a904eb48b07b1ea76865aa2",
            "7fa22c0a052141f7b28437ac02c2d069",
            "ec8b16cdab4745dcaae3dd29dbcc7c04",
            "6f0ac0ed562c498bb3658ee5f15740fa",
            "48f12a46bcee4100aed8e0b1e70f716d",
            "85abee2c1e344db49070f7eb62640cf9",
            "fd0d79ef3a7b417fb82143838ce96343"
          ]
        },
        "id": "FzBwMmyQ4X-q",
        "outputId": "4a65cbb8-715b-42fc-9c97-a8db8197b36b"
      },
      "source": [
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.num_labels = 2\n",
        "          # self.config = BertConfig.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True, \n",
        "          #                                          hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2)\n",
        "          # self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\", config=self.config)\n",
        "          self.config = XLMRobertaConfig.from_pretrained('xlm-roberta-base', output_hidden_states=True, \n",
        "                                                   hidden_dropout_prob=0.1, attention_probs_dropout_prob=0.1)\n",
        "          self.bert = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\", config=self.config)\n",
        "          ### New layers:\n",
        "          self.linear1 = nn.Linear(768, 768)\n",
        "          self.dropout = nn.Dropout(0.1)\n",
        "          self.linear2 = nn.Linear(768, self.num_labels)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None,\n",
        "                token_type_ids=None, position_ids=None, head_mask=None,\n",
        "                inputs_embeds=None, labels=None, output_attentions=None,\n",
        "                output_hidden_states=None, return_dict=None,):\n",
        "          outputs = self.bert(input_ids, attention_mask=attention_mask,\n",
        "                              token_type_ids=token_type_ids, position_ids=position_ids,\n",
        "                              head_mask=head_mask,inputs_embeds=inputs_embeds,\n",
        "                              output_attentions=output_attentions, output_hidden_states=output_hidden_states,\n",
        "                              return_dict=return_dict,)\n",
        "          pooled_output1 = outputs[1]\n",
        "          pooled_output = self.linear1(pooled_output1)\n",
        "          pooled_output = self.dropout(pooled_output)\n",
        "          logits = self.linear2(pooled_output)\n",
        "\n",
        "          loss = None\n",
        "          if labels is not None:\n",
        "              if self.num_labels == 1:\n",
        "                  #  We are doing regression\n",
        "                  loss_fct = MSELoss()\n",
        "                  loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "              else:\n",
        "                  loss_fct = CrossEntropyLoss()\n",
        "                  loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "          if not return_dict:\n",
        "              output = (logits,) + outputs[2:]\n",
        "              return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "          return logits\n",
        "\n",
        "model = CustomBERTModel().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e74540e258904358b5f8a1c27676833d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0a3c61a56374d48a5365eaec3d277b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CustomBERTModel(\n",
            "  (bert): XLMRobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (linear1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (linear2): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75_YZSK44X-r",
        "outputId": "55c7bda6-d0e7-4b21-ff1a-bd5d5f01486f"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\r\n",
        "params = list(model.named_parameters())\r\n",
        "\r\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\r\n",
        "\r\n",
        "print('==== Embedding Layer ====\\n')\r\n",
        "\r\n",
        "for p in params[0:5]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "\r\n",
        "print('\\n==== First Transformer ====\\n')\r\n",
        "\r\n",
        "for p in params[5:21]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\r\n",
        "\r\n",
        "print('\\n==== Output Layer ====\\n')\r\n",
        "\r\n",
        "for p in params[-4:]:\r\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 203 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (250002, 768)\n",
            "bert.embeddings.position_embeddings.weight                (514, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (1, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "linear1.weight                                            (768, 768)\n",
            "linear1.bias                                                  (768,)\n",
            "linear2.weight                                              (2, 768)\n",
            "linear2.bias                                                    (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "winopImj4X-r"
      },
      "source": [
        "import torch.nn.utils.prune as prune\r\n",
        "parameters_to_prune = ()\r\n",
        "for i in range(12):\r\n",
        "    parameters_to_prune += (\r\n",
        "        (model.bert.encoder.layer[i].attention.self.key, 'weight'),\r\n",
        "        (model.bert.encoder.layer[i].attention.self.query, 'weight'),\r\n",
        "        (model.bert.encoder.layer[i].attention.self.value, 'weight'),\r\n",
        "    )\r\n",
        "\r\n",
        "prune.global_unstructured(\r\n",
        "    parameters_to_prune,\r\n",
        "    pruning_method=prune.L1Unstructured,\r\n",
        "    amount=0.2,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw_Yl5S14X-r",
        "outputId": "b2429f7f-5555-4051-f887-8bbf0d984c06"
      },
      "source": [
        "for i in range(12):\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(model.bert.encoder.layer[i].attention.self.key.weight == 0))\r\n",
        "            / float(model.bert.encoder.layer[i].attention.self.key.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(model.bert.encoder.layer[i].attention.self.query.weight == 0))\r\n",
        "            / float(model.bert.encoder.layer[i].attention.self.query.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print(\r\n",
        "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\r\n",
        "            i+1,\r\n",
        "            100. * float(torch.sum(model.bert.encoder.layer[i].attention.self.value.weight == 0))\r\n",
        "            / float(model.bert.encoder.layer[i].attention.self.value.weight.nelement())\r\n",
        "        )\r\n",
        "    )\r\n",
        "    print()\r\n",
        "\r\n",
        "    \r\n",
        "numerator, denominator = 0, 0\r\n",
        "for i in range(12):\r\n",
        "    numerator += torch.sum(model.bert.encoder.layer[i].attention.self.key.weight == 0)\r\n",
        "    numerator += torch.sum(model.bert.encoder.layer[i].attention.self.query.weight == 0)\r\n",
        "    numerator += torch.sum(model.bert.encoder.layer[i].attention.self.value.weight == 0)\r\n",
        "\r\n",
        "    denominator += model.bert.encoder.layer[i].attention.self.key.weight.nelement()\r\n",
        "    denominator += model.bert.encoder.layer[i].attention.self.query.weight.nelement()\r\n",
        "    denominator += model.bert.encoder.layer[i].attention.self.value.weight.nelement()\r\n",
        "    \r\n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity in Layer 1-th key weight: 8.77%\n",
            "Sparsity in Layer 1-th query weightt: 9.43%\n",
            "Sparsity in Layer 1-th value weight: 30.24%\n",
            "\n",
            "Sparsity in Layer 2-th key weight: 13.04%\n",
            "Sparsity in Layer 2-th query weightt: 12.82%\n",
            "Sparsity in Layer 2-th value weight: 32.48%\n",
            "\n",
            "Sparsity in Layer 3-th key weight: 16.19%\n",
            "Sparsity in Layer 3-th query weightt: 16.04%\n",
            "Sparsity in Layer 3-th value weight: 30.36%\n",
            "\n",
            "Sparsity in Layer 4-th key weight: 18.33%\n",
            "Sparsity in Layer 4-th query weightt: 18.02%\n",
            "Sparsity in Layer 4-th value weight: 25.54%\n",
            "\n",
            "Sparsity in Layer 5-th key weight: 17.14%\n",
            "Sparsity in Layer 5-th query weightt: 16.98%\n",
            "Sparsity in Layer 5-th value weight: 25.25%\n",
            "\n",
            "Sparsity in Layer 6-th key weight: 19.16%\n",
            "Sparsity in Layer 6-th query weightt: 18.73%\n",
            "Sparsity in Layer 6-th value weight: 24.63%\n",
            "\n",
            "Sparsity in Layer 7-th key weight: 16.96%\n",
            "Sparsity in Layer 7-th query weightt: 16.50%\n",
            "Sparsity in Layer 7-th value weight: 27.09%\n",
            "\n",
            "Sparsity in Layer 8-th key weight: 18.73%\n",
            "Sparsity in Layer 8-th query weightt: 18.23%\n",
            "Sparsity in Layer 8-th value weight: 27.99%\n",
            "\n",
            "Sparsity in Layer 9-th key weight: 17.96%\n",
            "Sparsity in Layer 9-th query weightt: 17.28%\n",
            "Sparsity in Layer 9-th value weight: 27.48%\n",
            "\n",
            "Sparsity in Layer 10-th key weight: 17.00%\n",
            "Sparsity in Layer 10-th query weightt: 16.14%\n",
            "Sparsity in Layer 10-th value weight: 29.17%\n",
            "\n",
            "Sparsity in Layer 11-th key weight: 15.69%\n",
            "Sparsity in Layer 11-th query weightt: 15.32%\n",
            "Sparsity in Layer 11-th value weight: 30.00%\n",
            "\n",
            "Sparsity in Layer 12-th key weight: 14.40%\n",
            "Sparsity in Layer 12-th query weightt: 14.96%\n",
            "Sparsity in Layer 12-th value weight: 25.95%\n",
            "\n",
            "Global sparsity: 20.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtTajjdCeJta"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8kvqU9J4X-s"
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 4\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMQS5-UYgGu7"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    \r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZpAZfxqgIdc"
      },
      "source": [
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StGnfni4eNVC",
        "outputId": "cc3dd9e4-0c66-4c49-bedc-4ee2d4c364ca"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        " \n",
        "seed_val = 42\n",
        " \n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        " \n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        " \n",
        "for epoch_i in range(0, epochs):\n",
        "    #               Training\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        " \n",
        "    t0 = time.time()\n",
        " \n",
        "    total_train_loss = 0\n",
        " \n",
        "    model.train()\n",
        " \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        " \n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        " \n",
        "        model.zero_grad()        \n",
        " \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        " \n",
        "        loss.backward()\n",
        " \n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        " \n",
        "        optimizer.step()\n",
        " \n",
        "        scheduler.step()\n",
        " \n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        " \n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    #               Validation\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        " \n",
        "    t0 = time.time()\n",
        "    \n",
        "    model.eval()\n",
        " \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        " \n",
        "    for batch in validation_dataloader:\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "            \n",
        "        # total_eval_loss += logits.item()\n",
        " \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        " \n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    # avg_val_loss = total_eval_loss / len(validation_dataloader)    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    # print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        " \n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            # 'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        " \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        " \n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:10.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:12:24.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:18:39.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:24:54.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:31:08.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:37:23.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:43:38.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:49:52.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:52:36\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.89\n",
            "  Validation took: 0:01:41\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:15.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:12:29.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:18:44.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:24:59.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:31:13.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:37:28.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:43:43.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:49:57.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:52:41\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.90\n",
            "  Validation took: 0:01:41\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:15.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:12:29.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:18:44.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:24:58.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:31:13.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:37:27.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:43:42.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:49:56.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:52:40\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.90\n",
            "  Validation took: 0:01:41\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:14.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:12:29.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:18:43.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:24:58.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:31:12.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:37:27.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:43:41.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:49:56.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:52:40\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.90\n",
            "  Validation took: 0:01:41\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:37:21 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj5uhQ8deQXK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "8e9aca4d-5aab-407a-e0eb-b661f5c07af1"
      },
      "source": [
        "import pandas as pd\n",
        " \n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 4)\n",
        " \n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        " \n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        " \n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        " \n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.3328</td>\n",
              "      <td>0.8897</td>\n",
              "      <td>0:52:36</td>\n",
              "      <td>0:01:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.2447</td>\n",
              "      <td>0.8950</td>\n",
              "      <td>0:52:41</td>\n",
              "      <td>0:01:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.9019</td>\n",
              "      <td>0:52:40</td>\n",
              "      <td>0:01:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.1623</td>\n",
              "      <td>0.9027</td>\n",
              "      <td>0:52:40</td>\n",
              "      <td>0:01:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                            \n",
              "1             0.3328         0.8897       0:52:36         0:01:41\n",
              "2             0.2447         0.8950       0:52:41         0:01:41\n",
              "3             0.1974         0.9019       0:52:40         0:01:41\n",
              "4             0.1623         0.9027       0:52:40         0:01:41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ExG6UNeS-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "2bdcb784-e589-43cb-ef9d-3c4ea285818e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        " \n",
        "import seaborn as sns\n",
        " \n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        " \n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        " \n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Accur.'], 'g-o', label=\"Validation\")\n",
        " \n",
        "# Label the plot.\n",
        "plt.title(\"Training Loss & Validation Acc\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BVbl4Zjatzn"
      },
      "source": [
        "## **테스트셋 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5KHb6RkbHdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8107d4-cc50-4938-c4c8-e0167017decd"
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "pred, real = [], [] #f1-score용 배열\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 300 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    pred.append(np.argmax(logits, axis=1).flatten())\n",
        "    real.append(label_ids.flatten())\n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of  1,563.    Elapsed: 0:01:05.\n",
            "  Batch   600  of  1,563.    Elapsed: 0:02:10.\n",
            "  Batch   900  of  1,563.    Elapsed: 0:03:15.\n",
            "  Batch 1,200  of  1,563.    Elapsed: 0:04:19.\n",
            "  Batch 1,500  of  1,563.    Elapsed: 0:05:24.\n",
            "\n",
            "Accuracy: 0.90039\n",
            "Test took: 0:05:37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlOgXJYrguXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d481da8-fb86-42bc-d41e-5b4c373e7d53"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "print(classification_report(np.concatenate( real, axis=0 ),np.concatenate( pred, axis=0 ), digits=4))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9110    0.8860    0.8983     24826\n",
            "           1     0.8905    0.9147    0.9024     25171\n",
            "\n",
            "    accuracy                         0.9004     49997\n",
            "   macro avg     0.9008    0.9003    0.9004     49997\n",
            "weighted avg     0.9007    0.9004    0.9004     49997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7SzL1IBe1Dm"
      },
      "source": [
        "## **새로운 문장 테스트**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb4v_VfEfGQB"
      },
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    \n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C12NL1Fvgv4E"
      },
      "source": [
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 넣음\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "            \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQezr0tljJlM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e1a015a2-74a3-46bf-b486-70c36c1058cb"
      },
      "source": [
        "logits = test_sentences(['연기는 별로지만 재미 하나는 끝내줌!'])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.1823558  1.5893534]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9MQ0SK0jofN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d8fd2169-9df8-4d3d-acad-0ce8736bbc01"
      },
      "source": [
        "logits = test_sentences(['주연배우가 아깝다. 총체적 난국...'])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.878643  -3.4957294]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5mANMwKkA0D"
      },
      "source": [
        "학습한 모델을 가지고 실제 문장을 넣어봤습니다. 출력 로짓은 소프트맥스가 적용되지 않은 상태입니다. argmax로 더 높은 값의 위치를 라벨로 설정하면 됩니다. 0은 부정, 1은 긍정입니다. 위와 같이 새로운 문장에도 잘 분류를 하고 있습니다.\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK-T-NuCG96f"
      },
      "source": [
        "## Test\r\n",
        "\r\n",
        "자바스크립트 30분<br>\r\n",
        "\r\n",
        "function ClickConnect(){\r\n",
        "console.log(\"Working\"); \r\n",
        "document.querySelector(\"colab-toolbar-button\").click() \r\n",
        "}setInterval(ClickConnect, 1800000)"
      ]
    }
  ]
}